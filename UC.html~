<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
               "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>ULTIMATE COMPUTING</title>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
<meta name="title" content="ULTIMATE COMPUTING"/>
<meta name="generator" content="Org-mode"/>
<meta name="generated" content="2013-02-27 01:14:34 GMT"/>
<meta name="author" content="Txe Llenne"/>
<meta name="description" content=""/>
<meta name="keywords" content=""/>
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  html { font-family: Times, serif; font-size: 12pt; }
  .title  { text-align: center; }
  .todo   { color: red; }
  .done   { color: green; }
  .tag    { background-color: #add8e6; font-weight:normal }
  .target { }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  {margin-left:auto; margin-right:0px;  text-align:right;}
  .left   {margin-left:0px;  margin-right:auto; text-align:left;}
  .center {margin-left:auto; margin-right:auto; text-align:center;}
  p.verse { margin-left: 3% }
  pre {
	border: 1pt solid #AEBDCC;
	background-color: #F3F5F7;
	padding: 5pt;
	font-family: courier, monospace;
        font-size: 90%;
        overflow:auto;
  }
  table { border-collapse: collapse; }
  td, th { vertical-align: top;  }
  th.right  { text-align:center;  }
  th.left   { text-align:center;   }
  th.center { text-align:center; }
  td.right  { text-align:right;  }
  td.left   { text-align:left;   }
  td.center { text-align:center; }
  dt { font-weight: bold; }
  div.figure { padding: 0.5em; }
  div.figure p { text-align: center; }
  div.inlinetask {
    padding:10px;
    border:2px solid gray;
    margin:10px;
    background: #ffffcc;
  }
  textarea { overflow-x: auto; }
  .linenr { font-size:smaller }
  .code-highlighted {background-color:#ffff00;}
  .org-info-js_info-navigation { border-style:none; }
  #org-info-js_console-label { font-size:10px; font-weight:bold;
                               white-space:nowrap; }
  .org-info-js_search-highlight {background-color:#ffff00; color:#000000;
                                 font-weight:bold; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="gzenburn4UC.css" />
<script type="text/javascript">
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>

</head>
<body>

<div id="preamble">

</div>

<div id="content">
<h1 class="title">ULTIMATE COMPUTING</h1>

<p>Biomolecular Consciousness and NanoTechnology
</p><blockquote>

<p>Billionth scale activities in biomolecular assemblies could define life itself, and provide a frontier for the evolution of technology.
</p>
</blockquote>



<div style="text-align: center">
<p>                      <b>Stuart R. Hameroff</b>
</p>
<p>
Department of Anesthesiology
College of Medicine
University of Arizona
Tucson, Arizona, U.S.A
</p>
<p>
Originally published © Elsevier Science Publishers B.V., 1987
</p>
<p>
All Rights Reserved. ISBN: 0 444 70283 0
</p>
<p>
In 2003, this electronic edition was derived from the original 1987 print edition with permission from Elsevier Science Publishing for the use of Stuart R. Hameroff, who retains electronic distribution rights. Apart from some mostly software-related formatting changes (or any uncaught scanning glitches), the main body of this text should be essentially identical to the original.© 2003 Stuart Hameroff
</p>
<p>
Note from S.H.: Beginning in 1972 I had been fascinated by the possible computational capabilities of microtubules within living cells and in 1987 wrote "Ultimate Computing" (with help and guidance from Conrad Schneiker who also provided the prescient information about nanotechnology and quantum references). However several years later I became convinced that classical information processing even down to the level of microtubules within the brain was insufficient to explain consciousness. At that point I read "The Emperor's New Mind" by Roger Penrose and pursued the quantum path, working with Roger to apply his ideas about quantum gravity-mediated quantum computation in the brain to microtubules. It was a hard bound edition of "Ultimate Computing" which piqued Roger's interest.  
</p>
</div>



<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1 Prelude.</a>
<ul>
<li><a href="#sec-1-1">1.1 Acknowledgements</a></li>
<li><a href="#sec-1-2">1.2 Dedication</a></li>
</ul>
</li>
<li><a href="#sec-2">2 Toward Ultimate Computing</a>
<ul>
<li><a href="#sec-2-1">2.1 Mind/Tech: Merger in the Nanoscale</a></li>
<li><a href="#sec-2-2">2.2 Evolution of Technology</a></li>
<li><a href="#sec-2-3">2.3 Collective Intelligence</a>
<ul>
<li><a href="#sec-2-3-1">2.3.1 Parallelism</a></li>
<li><a href="#sec-2-3-2">2.3.2 Connectionism</a></li>
<li><a href="#sec-2-3-3">2.3.3 Cooperativity and Coherence</a></li>
</ul>
</li>
<li><a href="#sec-2-4">2.4 Molecular Computing</a></li>
<li><a href="#sec-2-5">2.5 Dynamic Pattern Representation</a>
<ul>
<li><a href="#sec-2-5-1">2.5.1 Reaction Diffusion Systems</a></li>
<li><a href="#sec-2-5-2">2.5.2 Holograms</a></li>
<li><a href="#sec-2-5-3">2.5.3 Macrons.</a></li>
<li><a href="#sec-2-5-4">2.5.4 Cellular Automata</a></li>
</ul></li>
</ul>
</li>
<li><a href="#sec-3">3 Brain/Mind/Computer</a>
<ul>
<li><a href="#sec-3-1">3.1 Metaphors of Consciousness</a></li>
<li><a href="#sec-3-2">3.2 Historical Perspectives-Consciousness as &hellip;</a>
<ul>
<li><a href="#sec-3-2-1">3.2.1 Consciousness as Particle/Wave Physics</a></li>
<li><a href="#sec-3-2-2">3.2.2 Consciousness as a Property of Protoplasm</a></li>
<li><a href="#sec-3-2-3">3.2.3 Consciousness as Learning</a></li>
<li><a href="#sec-3-2-4">3.2.4 Consciousness as a Metaphysical Imposition</a></li>
<li><a href="#sec-3-2-5">3.2.5 The Helpless Spectator Theory</a></li>
<li><a href="#sec-3-2-6">3.2.6 Emergent Evolution</a></li>
<li><a href="#sec-3-2-7">3.2.7 Behaviorism</a></li>
<li><a href="#sec-3-2-8">3.2.8 Consciousness as Dynamic Activities of the Brain's Reticular Activating System   39</a></li>
<li><a href="#sec-3-2-9">3.2.9 Neural Net Connectionism</a></li>
<li><a href="#sec-3-2-10">3.2.10 Holography</a></li>
<li><a href="#sec-3-2-11">3.2.11 Cytoskeletal Basis of Consciousness</a></li>
</ul></li>
</ul>
</li>
<li><a href="#sec-4">4 Origin and Evolution of Life</a>
<ul>
<li><a href="#sec-4-1">4.1 Soup vs Mud, Chicken vs Egg</a></li>
<li><a href="#sec-4-2">4.2 Prokaryote to Eukaryote-Symbiotic Jump</a></li>
<li><a href="#sec-4-3">4.3 Centrioles-Evolution's Hijackers</a></li>
<li><a href="#sec-4-4">4.4 Biotech Evolution-The Next Symbiosis</a></li>
</ul>
</li>
<li><a href="#sec-5">5 From Brain to Cytoskeleton</a>
<ul>
<li><a href="#sec-5-1">5.1 Nervous System Evolution</a></li>
<li><a href="#sec-5-2">5.2 Nervous System Organization</a>
<ul>
<li><a href="#sec-5-2-1">5.2.1 Architecture</a></li>
<li><a href="#sec-5-2-2">5.2.2 Neuronal Signaling</a></li>
<li><a href="#sec-5-2-3">5.2.3 Interneuronal Synapses</a></li>
</ul>
</li>
<li><a href="#sec-5-3">5.3 Representation of Information</a>
<ul>
<li><a href="#sec-5-3-1">5.3.1 Integration-Sherrington's Reflex Centers</a></li>
<li><a href="#sec-5-3-2">5.3.2 Pulse Logic</a></li>
<li><a href="#sec-5-3-3">5.3.3 Connectionism and Neural Networks</a></li>
<li><a href="#sec-5-3-4">5.3.4 Distributedness</a></li>
<li><a href="#sec-5-3-5">5.3.5 Synaptic Mechanisms of Learning and Memory</a></li>
<li><a href="#sec-5-3-6">5.3.6 Axoplasmic Transport</a></li>
<li><a href="#sec-5-3-7">5.3.7 Parallelism, Collective Cooperativity, and the Grain of the Engram   77</a></li>
</ul>
</li>
<li><a href="#sec-5-4">5.4 Toward Molecular Consciousness</a></li>
</ul>
</li>
<li><a href="#sec-6">6 Cytoskeleton/Cytocomputer</a>
<ul>
<li><a href="#sec-6-1">6.1 The Nature of Cytoplasm</a></li>
<li><a href="#sec-6-2">6.2 Microtubules</a>
<ul>
<li><a href="#sec-6-2-1">6.2.1 Microtubule Structure and Function</a></li>
<li><a href="#sec-6-2-2">6.2.2 Microtubule Assembly and the Generation of Form</a></li>
<li><a href="#sec-6-2-3">6.2.3 Microtubule Organizing Centers (MTOC) and Centrioles. 93</a></li>
<li><a href="#sec-6-2-4">6.2.4 Microtubule Associated Proteins (MAPs)</a></li>
</ul>
</li>
<li><a href="#sec-6-3">6.3 Intermediate Filaments</a></li>
<li><a href="#sec-6-4">6.4 The Cytoplasmic Ground Substance</a>
<ul>
<li><a href="#sec-6-4-1">6.4.1 The Microtrabecular Lattice (MTL)</a></li>
<li><a href="#sec-6-4-2">6.4.2 The Cytomatrix</a></li>
<li><a href="#sec-6-4-3">6.4.3 Cytoplasmic Solid State</a></li>
</ul>
</li>
<li><a href="#sec-6-5">6.5 Cytoskeletal Motility</a>
<ul>
<li><a href="#sec-6-5-1">6.5.1 Cytoplasmic Probing</a></li>
<li><a href="#sec-6-5-2">6.5.2 Bending Sidearms</a></li>
<li><a href="#sec-6-5-3">6.5.3 Ciliary and Collective Movement</a></li>
<li><a href="#sec-6-5-4">6.5.4 Geodesic Tensegrity Gels</a></li>
</ul>
</li>
<li><a href="#sec-6-6">6.6 The Cytoskeleton and Development</a></li>
<li><a href="#sec-6-7">6.7 The Cytoskeleton and Medicine</a></li>
<li><a href="#sec-6-8">6.8 Intelligence in the Cytoskeleton</a></li>
</ul>
</li>
<li><a href="#sec-7">7 Protein Conformational Dynamics</a>
<ul>
<li><a href="#sec-7-1">7.1 Protein Structure</a></li>
<li><a href="#sec-7-2">7.2 Protein Conformation</a></li>
<li><a href="#sec-7-3">7.3 Proteins and Energy</a></li>
<li><a href="#sec-7-4">7.4 Protein Cooperativity-Historical View</a></li>
<li><a href="#sec-7-5">7.5 Living Water and Hydrophobic Interactions</a></li>
<li><a href="#sec-7-6">7.6 Electret, Piezo, and Pyroelectric Effects</a></li>
<li><a href="#sec-7-7">7.7 Solitons/Davydov</a></li>
<li><a href="#sec-7-8">7.8 Coherent Excitations /Fröhlich</a></li>
<li><a href="#sec-7-9">7.9 Massless Bosons, Cytoskeletal Self-Focusing</a></li>
</ul>
</li>
<li><a href="#sec-8">8 Anesthesia: Another Side of Consciousness</a>
<ul>
<li><a href="#sec-8-1">8.1 Levels of Anesthesia/Consciousness</a></li>
<li><a href="#sec-8-2">8.2 Memory. 151</a></li>
<li><a href="#sec-8-3">8.3 Mechanisms of Anesthesia</a></li>
</ul>
</li>
<li><a href="#sec-9">9 Models of Cytoskeletal Computing</a>
<ul>
<li><a href="#sec-9-1">9.1 Energy and Information in Microtubules</a></li>
<li><a href="#sec-9-2">9.2 Cytoskeletal Information Processing</a>
<ul>
<li><a href="#sec-9-2-1">9.2.1 MT Sensory Transduction/Atema</a></li>
<li><a href="#sec-9-2-2">9.2.2 MT Mechano-lonic Transducers/Moran and Varela</a></li>
<li><a href="#sec-9-2-3">9.2.3 Cytomolecular Computing/Conrad and Liberman</a></li>
<li><a href="#sec-9-2-4">9.2.4 MT Signal Processing/DeBrabander</a></li>
<li><a href="#sec-9-2-5">9.2.5 Cytoskeletal String Processors/Barnett</a></li>
<li><a href="#sec-9-2-6">9.2.6 Microtubule "Gradions"/Roth, Pihlaja, Shigenaka</a></li>
<li><a href="#sec-9-2-7">9.2.7 Gyroscopic Centrioles/Bornens</a></li>
<li><a href="#sec-9-2-8">9.2.8 Centriole-MT Signaling/Albrecht-Buehler</a></li>
<li><a href="#sec-9-2-9">9.2.9 Dynamic Tensegrity/Heidemann and Jarosch</a></li>
<li><a href="#sec-9-2-10">9.2.10 Dynamic MT Probing/Kirschner and Mitchison</a></li>
<li><a href="#sec-9-2-11">9.2.11 Sphere Packing Screw Symmetry/Koruga</a></li>
<li><a href="#sec-9-2-12">9.2.12 Cytoskeletal Self-Focusing/Del Giudice</a></li>
<li><a href="#sec-9-2-13">9.2.13 MT Automata, Holography/Hameroff, Watt, Smith</a></li>
</ul>
</li>
<li><a href="#sec-9-3">9.3 The Cytoskeletal Connection</a></li>
</ul>
</li>
<li><a href="#sec-10">10 Viruses/Ambiguous Life Forms</a>
<ul>
<li><a href="#sec-10-1">10.1 What Is the Essence of Living Matter?</a></li>
<li><a href="#sec-10-2">10.2 Virus (Mis)Behavior</a></li>
<li><a href="#sec-10-3">10.3 Virus Structure and Collective Oscillations</a></li>
<li><a href="#sec-10-4">10.4 Nature and Origin of Viruses</a></li>
<li><a href="#sec-10-5">10.5 Domesticated Viruses</a></li>
</ul>
</li>
<li><a href="#sec-11">11 NanoTechnology</a>
<ul>
<li><a href="#sec-11-1">11.1 Early NanoTechnologists</a></li>
<li><a href="#sec-11-2">11.2 Scanning Tunneling Microscopes (STMs)</a></li>
<li><a href="#sec-11-3">11.3 STM/Feynman Machines (FMs)</a></li>
<li><a href="#sec-11-4">11.4 Micro/Nano STM Contest</a></li>
<li><a href="#sec-11-5">11.5 STM/FMs and Molecular Computing</a></li>
<li><a href="#sec-11-6">11.6 STM/FMs and Biomedical Applications</a></li>
<li><a href="#sec-11-7">11.7 Replicating Automata</a></li>
</ul>
</li>
<li><a href="#sec-12">12 The Future of Consciousness</a></li>
<li><a href="#sec-13">13 Bibliography</a>
<ul>
<li><a href="#sec-13-1">13.1 STM References</a></li>
<li><a href="#sec-13-2">13.2 Near-Field Scanning Optical Microscopes</a></li>
<li><a href="#sec-13-3">13.3 Other STM-Related Instruments</a></li>
<li><a href="#sec-13-4">13.4 Replicating Systems References</a></li>
<li><a href="#sec-13-5">13.5 Collective Computing References</a></li>
<li><a href="#sec-13-6">13.6 Quantum Computing References</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> Prelude.</h2>
<div class="outline-text-2" id="text-1">

<p>What is this book, and why has it been written by an anesthesiologist? This book is a view of the co-evolution of consciousness and technology-past, present and future.
</p>
<p>
This book has been written by an anesthesiologist because of a confluence of two fascinations. The first is the nature of consciousness, which anesthesiologists routinely erase and restore in their patients. The second is a fifteen year trail of notions that would not go away. While a third year medical student in 1972, I spent a summer research elective in a cancer laboratory. For some reason I became fascinated and fixated by one particular question. When cells divided, the chromosomes were separated and daughter cell architecture established by wispy strands called mitotic spindles ("microtubules") and cylindrical organelles called centrioles. Somehow, the centrioles and spindles "knew" when to move, where to go, and what to do. The uncanny guidance and orientation mechanism of these tiny biomolecular structures seemed to require some kind of motorized intelligence. At about the same time, electron microscopy techniques were revealing the interior of all living cells to be densely filled with wispy strands, some of which were identical to mitotic spindles. Interconnected in dynamic parallel networks, these structures were thought to serve a purely supportive, or mechanical structural role and were collectively termed the "cytoskeleton."
</p>
<p>
But several factors suggested that the cytoskeleton was more than the
structural "bones" of the cell: they manipulated dynamic activities,
orchestrating complex and highly efficient processes such as cell
growth, mitosis and transport. Another factor was a lack of any other
candidate for "real time" dynamic organization within cells. Long term
blueprints and genetic information clearly resided in DNA and RNA, and
membranes performed dynamic functions at cell surfaces. However, a
mechanism for the moment to moment execution, organization, and
activities within cells remained unknown. Where was the nervous system
within the cell? Was there a biological controller? This book is based
on the premise that the cytoskeleton is the cell's nervous system, the
biological controller/computer. In the brain this implies that the
basic levels of cognition are within nerve cells, that cytoskeletal
filaments are the roots of consciousness. The small size and rapid
conformational activities of cytoskeletal proteins are just beyond the
resolution of current technologies, so their potential dynamics remain
unexplored and a cytoskeletal controlling capability untested. Near
future technologies will be able to function in the nanoscale (nano =
10 ^-9; nanometer = one billionth meter, nanosecond = one billionth second and will hopefully resolve these questions. If indeed cytoskeletal dynamics are the texture of intracellular information processing, these same "nanotechnologies" should enable direct monitoring, decoding and interfacing between biological and technological information devices. This in turn could result in important biomedical applications and perhaps a merger of mind and machine: Ultimate Computing.
</p>
<p>
A thorough consideration of these ideas involves a number of disciplines, all of which are at least tangentially related to anesthesiology. These include biochemistry, cognitive science, computer science, engineering, mathematics, microbiology, molecular biology, pharmacology, philosophy, physics, physiology, and psychology. As an expert in none, but a dabbler in all, I hope true experts in these fields will find my efforts never-the-less interesting.
</p>
<p>
Starting from a cytoskeletal perspective, this book flings metaphors at the truth. Perhaps one or more will land on target, or at least come close.  
</p>
</div>

<div id="outline-container-1-1" class="outline-3">
<h3 id="sec-1-1"><span class="section-number-3">1.1</span> Acknowledgements</h3>
<div class="outline-text-3" id="text-1-1">


<p>
This book is a collective effect of the following people: Ralph Abraham, Ross Adey, Sigma Alpha, Fred Anderson, Amy Barnes, Joanne Barnes, Michel Bornens, Burnell Brown, George Carlson, Forrest Carter, Peter Christiansen, Jim Clegg, John Condeelis, Leonor Cruzeiro, Marc DeBrabander, Yves Engelborghs, Lawrence Fried, Herbert Fröhlich, Kit Grantham, Jamie, Harrison, Lillian, Amy, and the entire Hameroff/Kaplan/Bowman family, Max Headroom, Emery Hetrick, Dixie Holmes, Paul Jablonka, Martha Juarez, Jan Julianus, Ben Kahn, Charles Kiselyak, Djuro Koruga, Julio Kuperman, Teruo Matsumoto, Leo Martin, Kathleen McAuliffe, Claris Nelson, Michio Okuma, Karl Pribram, Mary Quimby, Steen Rasmussen, Conrad Schneiker, Alwyn Scott, Steven Smith, Branko Soucek, Arthur Villa, Rich Watt, Juli Weiss and Arthur Winfree.
</p>
<p>
Most of the artwork was thoughtfully done by scientist/systems engineer/artist Paul Jablonka. Conrad Schneiker supplied most of the material on nanotechnology and replicators for Chapter 10, and compiled the appendices. I am indebted to the Laboratory for Advanced Mathematics and Physics at the Technical University of Denmark and the Danish Camping Union who hosted me, Jamie and Harrison during our sabbatical. I sincerely appreciate the efforts of my colleagues in the Department of Anesthesiology and the College of Medicine, University of Arizona who permitted me time and mental latitude. Thanks to Personal TeX's port of Don Knuth's TeX, plus Leslie Lamport's LaTeX, Textset's DVILASER/PS, Boreland's Turbo Lightning, Adobe Systems' PostScript, Apple's Macintosh and LaserWriter, IBM's PC/AT and its clones, QMS's PS800 laser printer and Xerox's machines and their clones. The ever friendly and competent technical support from Textset, Personal TeX and HDS Systems is also greatly appreciated. [2003 Note: For various reasons, the electronic version of this book was formatted by the often wonderfully convenient but also sometimes obnoxiously troublesome Microsoft Word 2002. While Word 2002 was a great time-saver overall compared to the previous tools, some pretty basic things that previously worked fine out of the box would have required too much additional work to reasonably replicate here. Hence the above-mentioned people, products, and companies should not be held responsible for the ironically sometimes less satisfactory typographical results some 16 years later.]
</p>
<p>
Finally, Jan Julianus and Elsevier North-Holland deserve credit for their instigation and patience.
</p></div>

</div>

<div id="outline-container-1-2" class="outline-3">
<h3 id="sec-1-2"><span class="section-number-3">1.2</span> Dedication</h3>
<div class="outline-text-3" id="text-1-2">


<p>
To H. H., who loved to gamble.
</p></div>
</div>

</div>

<div id="outline-container-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> Toward Ultimate Computing</h2>
<div class="outline-text-2" id="text-2">


</div>

<div id="outline-container-2-1" class="outline-3">
<h3 id="sec-2-1"><span class="section-number-3">2.1</span> Mind/Tech: Merger in the Nanoscale</h3>
<div class="outline-text-3" id="text-2-1">

<p>Biology and technology are both evolving toward more efficient methods of information processing. With a head start of a billion years, biology has evolved human consciousness; technology appears to be catching up rapidly.
</p>
<p>
Ultimate Computing is the common destination for the evolution of
information processing systems in both biology and technology. At this
point it is an extrapolation of converging trajectories, but Ultimate
Computing may soon exist in the nanoscale. Nano = 10 ^-9, one nanometer
is a billionth of a meter, and one nanosecond is a billionth of a
second. Subunits within biological protein assemblies (cytoskeletal
polymers, organelles, membrane proteins, virus coats) are of nanometer
size scale and undergo conformational oscillations in the nanosecond
time scale. Nanoscale excitations, which may be coherent and coupled
to intraprotein dipole shifts, can generate communicative "collective
modes" within protein assemblies and provide a substrate for
biological information processing. Thus the "nanoscale" (Figure 1.1)
may be where living intelligence has evolved. Coincidentally,
nanoscale devices including molecular computers, Feynman machines and
von Neumann replicators are becoming feasible through technologies
such as scanning tunneling microscopy. A nanoscale marriage of
biomolecules and nanotech devices, providing direct communication and
information transfer, could have profound benefits for biomedicine and
our culture in general.
</p>
<div id="Figure-1.1" class="figure">
<p><img src="UC-images/image001.jpg"  alt="UC-images/image001.jpg" /></p>
<p>Figure 1.1 Sizing the Nanoworld. The diameter of each circle is given in nanometers (nm). A) 0.30 nm-a carbon atom, 0.15 nm in diameter. B) 0.50 nm-alanine, an amino acid with 13 atoms including 3 carbons, is about .33 nm in diameter. C) 12 nm-a tubulin dimer protein, the subunit of microtubules, is 8 nm long. It is composed of 2 similar monomers (alpha and beta tubulin), each made of about 440 amino acids. Cross hatching suggests the approximate amount of space available for each amino acid. D) 50 nm-a microtubule, 13 sided tube with an outside cross-sectional diameter of 25 nm. E) 1900 nm-a small 1000 nm diameter nerve axon might contain 100 microtubules (shown) and 1000 smaller filaments (not shown). Microtubules associate in informal clumps of 1 to 5 microtubules each, represented by dots. F) 40,000 nm-a nerve cell grown on the surface of a Motorola 68000 computer chip. The wire thickness is 15,000 nm wide. G) 170,000 nm-a nematode is a small worm of less than 1000 cells, 300 of which are neurons. Nematodes have a brain, teeth, muscles, gut, and sex lives. This one is about 450,000 nm long. H) 5,000,000 nm-one quarter of a human thumbnail with 50 nematodes represented to scale. By Paul Jablonka.</p>
</div>

<p>
Comingling of consciousness and computer technology is a prevalent
dream. Artificial intelligence based on brain/mind organization is a
tentative step in this direction, as is the proposed use of self
assembling protein arrays as switching circuits or "biochips." The
Japanese effort towards the "Sixth Generation Computer" aims to
"integrate biology and technology" by merging research in artificial
intelligence and the functions of living organisms (Corcoran,
1987). By attempting to understand the conditions required to maintain
biological "homeostasis", the Japanese are hoping to embark on a
symbiosis between intelligent biological structures and technological
devices, and even predict an "artificial brain"! One missing
ingredient for such a Mind/Tech merger is an understanding of the
mechanism of consciousness. Most models of brain organization consider
nerve cells and their connections to be the brain's fundamental units
of information processing. However, profoundly complex and intelligent
activities occur within nerve cells. Further, simple organisms like
single cell amoeba and paramecium perform complex tasks without
benefit of brain or nervous system. In this book we view the
cytoskeleton-networks of protein polymers which occupy and organize
the interiors of all living cells (Figure 1.2)-as a highly evolved
information processing system operating at nanoscale
levels. Collective nanoscale activities of the cytoskeleton and
related structures can explain biological organization, information
processing, and consciousness, and be the target for the future
evolution of technology.
</p>

<div id="Figure-1.2" class="figure">
<p><img src="UC-images/image002.jpg"  alt="UC-images/image002.jpg" /></p>
<p>Figure 1.2 Cytoskeleton within cells who have just divided. Intracellular microtubules are visualized by immunostaining. Spherical areas are cell nuclei, adjacent to which are the dense microtubule organizing centers (MTOC). With permission from DeBrabander, Geuens, DeMey and Joniav (1986), courtesy of Marc DeBrabander.</p>
</div>

</div>

</div>

<div id="outline-container-2-2" class="outline-3">
<h3 id="sec-2-2"><span class="section-number-3">2.2</span> Evolution of Technology</h3>
<div class="outline-text-3" id="text-2-2">


<p>
Technological emulation of life since the 13th century has been reviewed by author Claris Nelson (1985). Albertus Magnus is said to have create a life-like mechanical servant out of metal, wood, glass, leather and wax that could open doors and greet visitors. It was considered blasphemous work of the devil by Magnus' student Saint Thomas Aquinas who destroyed it. Science fiction writers predicted computers and robots long before they existed. In 1879, Edward Page Mitchell's The Ablest Man in the World featured a mechanical brain and in Edmund Hamilton's 1928 The Metal Giants an artificial brain turned against its creators.
</p>
<p>
Computers descended from calculating machines, the earliest of which was the abacus. In 1642 French mathematician and philosopher Pascal made a mechanical calculator that used the decimal system to add and subtract. In 1694, German mathematician/philosopher Leibniz created a "Stepped Reckoner," which was supposed to multiply, divide and take square roots. It didn't work, but utilized principles later essential to modern computers. Tasks were broken down into a great many simple mathematical steps using binary numbers and were performed sequentially. When computers later came to be operated by electricity, binary zero and one became represented by off and on. In the early 1800's George Boole developed "Boolean algebra," the mathematical logic by which computer circuits are designed. Charles Babbage and Ada Lovelace-Lord Byron's eldest daughter-designed an "analytical engine" using punched cards. Their contemporary technology could not construct the machine accurately enough, but it was built and functioned in the twentieth century.
</p>
<p>
The first electronic computer was apparently constructed and operated in 1939 by John Vincent Atanasoff, a theoretical physicist at Iowa State University (Mackintosh, 1987). Shortly thereafter, Alan Turing and colleagues in Bletchley, England designed a computer to perform all possible mathematical calculations. It was based on Turing's work proving the logical limits of computability and was used to decipher the German "Enigma" code during World War II. In a masterful presentation of key ideas previously developed by other pioneers, John von Neumann further advanced computer design by separating the machine from its problems. Prior to von Neumann, a computer would have to be rewired for each new task. With enough time, memory and software, computers could solve the problems that could be broken down into finite sequences of logical steps. Most current computers use "serial" processing based on von Neumann's design. In the 1940's, the University of Pennsylvania developed the first electronic computer, the Electronic Numerical Integrator and Calculator or "ENIAC." It weighed 30 tons, took up 3,000 cubic feet of space, and contained 18,000 vacuum tubes, one of which failed every seven minutes. It could calculate nuclear physics problems in two hours that would have taken 100 engineers a year to complete. Today, the same capacity is available on one chip. In 1950 Remington Rand marketed UNIVAC, which dealt with words and numbers stored by their binary equivalent. Since that time, roughly four generations of computers have evolved due to increased demand and advances in design, chip size, materials and other factors. For the same reasons further advances seem inevitable.
</p>
<p>
Von Neumann and Turing hoped that computers could duplicate our ability to think, so that our minds could be amplified just as our muscles had been by industrial machines. However further evolution of computers using serial processing seems limited. Computers and artificial intelligence are now evolving to parallel systems based on brain architecture and neural net models; a future step may be nanoscale, self organizing intelligence.
</p>
<p>
Von Neumann is one of several "fathers of the computer." In the "serial" processing which he skillfully formalized, information flows in one dimension. In the 1950's and 1960's, von Neumann (1966) and Stanislav Ulam developed the mathematics of computing in multiple dimensions. They considered two dimensional information spaces with discrete subunits ("cells") whose states could vary depending on the states of neighboring cells. Each cell and its neighbor relations were identical. Relatively simple rules among neighbors and discrete time intervals ("generations") led to evolving patterns and self-organization which were exquisitely sensitive to initial conditions. They called these systems "cellular automata." Von Neumann described a "universal computer" automaton which could solve any problem if given sufficient area and time. Today, computer technologists are considering the profound advantages of implementing molecular scale automata (Milch, 1986).
</p>
<p>
Edward Fredkin of Massachusetts Institute of Technology has considered multidimensional automata and the discreteness of time and matter. He argues that the universe is a cellular automaton whose "cells" are atomic and subatomic particles (Wright, 1985). The universe is made of information, Fredkin reasons. Cellular automata may be generalized "primordial computers" of which all other computers and complex systems are particular examples. Cellular automata in conformational states of cytoskeletal subunits could process biological information and be the substrate of consciousness.
</p>
<p>
The current trend in computer design and artificial intelligence or "AI" is parallel connectedness, emulating the brain. Many types of problems can be solved by breaking them down into serial mathematical steps. Today's electronic computers serially process very rapidly and can solve complex mathematical problems far faster than can humans alone. However qualitative functions which the brain performs naturally-recognizing patterns, or making judgments-are extremely difficult for computers. Consider the letter "a." We recognize it automatically, in any typeface, in all but the worst handwriting. To our brains it's simple, quick, obvious even if it's missing. If we see, "Sally 'red' a newspaper," we mentally insert the absent "a." Computer/Al scientist Jerome Feldman (1985) cites the example of interpreting the statement "John threw a ball for charity." The inherent ambiguities of this type of statement can be resolved in a highly parallel system in which multiple simultaneous interpretations are processed and evaluated. Hurling a sphere versus hosting a dance can be resolved by the qualifier "for charity" which is much more consistent with a dance than with a sphere. Human brains commonly resolve conflicts among differing drives or input, although failure to do so may cause psychiatric or emotional problems. At least according to science fiction, computers can suffer similar disturbances. In Arthur C. Clarke's and Stanley Kubrick's 2001: Space Odyssey and its sequel 2010, the computer "Hal 9000" becomes psychotic because of conflicting instructions and reacts by killing the space voyagers because their mission was too important to be entrusted to them. The brain/mind can perform "cognitive" functions including resolution of conflict by "subcognitive" processes such as recognizing patterns, making assumptions and performing imaginative leaps. The net effect is consciousness: a collective effect of simpler processes.
</p></div>

</div>

<div id="outline-container-2-3" class="outline-3">
<h3 id="sec-2-3"><span class="section-number-3">2.3</span> Collective Intelligence</h3>
<div class="outline-text-3" id="text-2-3">

<p>A collective phenomenon is more the product of, rather than the sum of, its parts, and has been explained by Cal Tech biophysicist John Hopfield (1982) whose "neural net" models are collective.
</p>
<p>
Suppose you put two molecules in a box, every once in a while they
collide and that's an exciting event. &hellip; If we'd put ten or even a
thousand more molecules in the box all we'd get is more
collisions. But if we put a billion billion molecules in the box,
there is a new phenomenon-sound waves.
</p>

<div id="Figure-1.3" class="figure">
<p><img src="UC-images/image003.jpg"  alt="UC-images/image003.jpg" /></p>
<p>Figure 1.3: Axoplasmic transport occurs by coordinated activities of microtubule attached sidearm, contractile proteins ("dynein") which cooperatively pass material in a "bucket brigade." The orchestration mechanism is unknown, but shown here as the consequence of signaling by "soliton" waves of microtubule subunit conformational states. By Fred Anderson.</p>
</div>

<p>
Observation of two, or ten, or thousands of those molecules would not suggest the Mozart or Madonna that can arise in a collection of more than a trillion trillion molecules. Other examples of collective phenomena may be seen in beehives, ant colonies, football teams, governments and various types of material phase transitions. For example, superconductivity and magnetism are collective effects which occur in certain metals as their individual atoms come into alignment. By cooling these metals, thermal fluctuations cease, atoms become highly aligned, and below a critical temperature totally different qualitative properties of superconductivity or magnetism emerge.
</p>
<p>
How might collective phenomena be tied to consciousness? Brain neuron synaptic transmissions are relatively slow at several milliseconds per computation-they are about 100,000 times slower than a typical computer switch. Nevertheless vision and language problems can be solved in a few hundred milliseconds or what would appear to be about 100 serial steps. Artificial Intelligence (AI) researchers conclude that this computational richness is accounted for by collective effects of parallelism and rich interconnectedness. With billions of neurons, and with each neuron connected to up to hundreds of thousands of other neurons, Al "connectionists" view the brain as a collective phenomenon of individually stupid neurons. Groups of highly connected neurons are thought to attain intelligent behavior through properties of feedback and reverberation. Walter Freeman (1972, 1975, 1983) of the University of California at Berkeley contends that a "critical mass" of about 100,000 neurons yields intelligent behavior. However, intelligent behavior occurs within nematode worms of 1000 cells and 300 neurons, within cytoplasm in single cell organisms and within single neurons. Individual neurons with tens to hundreds of thousands of connections cannot be stupid and fulfill their multiple functions, integrate input/output and modulate synaptic connection strength. Each nerve cell is a sophisticated information processing system in and of itself! The cytoskeleton within neurons and all living cells is a parallel connected network which can utilize its own collective phenomena to organize and process subcellular information (Figure 1.3). The cytoskeleton can convey analog patterns which may be connected symbols (Chapter 8). Although overlooked by AI researchers, the cytoskeleton may take advantage of the same attributes used to describe neural level networks. Properties of networks which can lead to collective effects among both neurons and cytoskeletal subunits include parallelism, connectionism, and coherent cooperativity.   
</p>

</div>

<div id="outline-container-2-3-1" class="outline-4">
<h4 id="sec-2-3-1"><span class="section-number-4">2.3.1</span> Parallelism</h4>
<div class="outline-text-4" id="text-2-3-1">

<p>The previous generations of computer architecture have been based on the von Neumann concept of sequential, serial processing. In serial processing, computing steps are done consecutively which is time consuming. One false bit of information can cascade to chaotic output. The brain with its highly parallel nerve tracks shines as a possible alternative. In parallel computing, information enters a large number of computer pathways which process the data simultaneously. In parallel computers information processors may be independent of each other and proceed at individual tempos. Separate processors, or groups of processors, can address different aspects of a given problem asynchronously. As an example, Reeke and Edelman (1984) have described a computer model of a parallel pair of recognition automata which use complementary features (Chapter 4). Parallel processing requires reconciliation of multiple outputs which may differ due to individual processors being biased differently than their counterparts, performing different functions, or because of random error. Voting or reconciliation must occur by lateral connection, which may also function as associative memory. Output from a parallel array is a collective effect of the input and processing, and is generally a consensus which depends on multiple features of the original data input and how it is processed. Parallel and laterally connected tracks of nerve fibers inspired AI researchers to appreciate and embrace parallelism. Cytoskeletal networks within nerve cells are highly parallel and interconnected, a thousand times smaller, and contain millions to billions of cytoskeletal subunits per nerve cell!
</p>
<p>
Present day evolution of computers toward parallelism has engendered the "Connection Machine" (Thinking Machines, Inc.) which is a parallel assembly of 64,000 microprocessors. Early computer scientists would have been impressed with an assembly of 64,000 switches without realizing that each one was a microprocessor. Similarly, present day cognitive scientists are impressed with the billions of neurons within each human brain without considering that each neuron is itself complex.
</p>
<p>
Another stage of computer evolution appears as multidimensional network parallelism, or "hypercubes." Hypercubes are processor networks whose interconnection topology is seen as an "n-dimensional" cube. The "vertices" or "nodes" are the processors and the "edges" are the interconnections. Parallelism in "n-dimensions" leads to hypercubes which can maximize available computing potential and, with optimal programming, lead to collective effects. Complex interconnectedness observed among brain neurons and among cytoskeletal structures may be more accurately described as hypercube architecture rather than simple parallelism. Hypercubes are exemplified in Figures 1.4, 1.5, and 1.6.
</p>
<p>
Al/Roboticist Hans Moravec (1986) of Carnegie-Mellon University has
attempted to calculate the "computing power" of a computer, and of the
human brain. Considering the number of "next states" available per
time in binary digits, or bits, Moravec arrives at the following
conclusions. A microcomputer has a capacity of about 106 bits per
second. Moravec calculates the brain "computing" power by assuming 40
billion neurons which can change states hundreds of times per second,
resulting in 40 x 10 ^11 bits per second. Including the cytoskeleton
increases the potential capacity for information processing
immensely. Microtubules are the most visible cytoskeletal
structures. Making some rough assumptions about cytoskeletal density
(i.e. microtubules spaced about 1000 nanometers apart) and the volume
of brain which is neuronal cytoplasm leads to about 10 ^14 microtubule
subunits in a human brain (ignoring neurofilaments and other
cytoskeletal elements). As described in Chapters 5 and 6, the
frequency of cytoskeletal subunit state changes may be greater than
billions per second! The cytoskeleton is capable not only of immense
information capacity, but appears to be designed such that interacting
conformational state patterns may perform computing functions. Several
theories which propose such mechanisms will be described in Chapter
8 (9 in this ed.)
</p>
<div id="Figure-1.4" class="figure">
<p><img src="UC-images/image004.jpg"  alt="UC-images/image004.jpg" /></p>
<p>Figure 1.4 Six dimensional hypercube with 64 nodes, and 6 connections per node. Computer generation by Conrad Schneiker.</p>
</div>

<p>
The brain is a continuous system. Classical computers have operated on
recursive repetitive functions to process information in batches and
the output is obtained as the final product. Similarly, most parallel
processing designs have discrete input and output points. Carl Hewitt
(1985) has described open systems within computers in which processing
may never halt, which can provide output while computing is still in
operation, and can accept input from sources not anticipated when the
computation began. Like the human brain/mind, open continuous systems
can interact with the environment and adapt to new situations. Hewitt
describes an asynchronous parallel computer system which can make use
of multiple inputs and outputs and whose parallel elements are
connected by "arbiters" which "weigh" and reconcile differing content,
and can provide continuous input and output. Among brain neurons,
"arbiters" would appear to be synaptic connections among laterally
connected parallel neurons. Within the cytoskeleton, laterally
connecting filaments and microtubule associated proteins ("MAPs")
could serve as logical arbiters.
</p>

<div id="Figure-1.5" class="figure">
<p><img src="UC-images/image005.jpg"  alt="UC-images/image005.jpg" /></p>
<p>Figure 1.5 Eight dimensional hypercube with 256 nodes, and 8 connections per node. Computer generation by Conrad Schneiker.</p>
</div>

<p>
Hewitt argues that parallel, open systems are "non-hierarchical" because input and output are continuously processed throughout the system. Early views of brain/mind organization assumed a hierarchical arrangement of processing units. Sensory input was thought to be processed and relayed to higher and higher levels of cognition until reaching a single "Grandfather neuron" or "Mind's Eye" which comprehended the input's "essence." Classical brain research by Lashley (1929, 1950) and others (Chapter 4) strongly suggest that memory and information are distributed throughout the brain and that specific anatomical hierarchical arrangements leading to "Grandfather neurons" do not exist. The "Mind's Eye" is not localized to a given site but is mobile over wide volumes of brain. Assuming that humans actually do comprehend the essence of at least some things, who or what is comprehending? The site and nature of attention, "self," consciousness or the Mind's Eye remains a philosophical issue and barrier to Mind/Tech merger. Neuroanatomical structure and the distributed storage of brain information point toward highly parallel, open brain/mind computing systems which may occur both at the neural level, and within neurons in the cytoskeleton. The perception component of consciousness, the "Mind's Eye" may be a mobile hierarchy determined by collective dynamics.
</p>
</div>

</div>

<div id="outline-container-2-3-2" class="outline-4">
<h4 id="sec-2-3-2"><span class="section-number-4">2.3.2</span> Connectionism</h4>
<div class="outline-text-4" id="text-2-3-2">


<p>
The Mind's Eye may be the apex of a collective hierarchy of parallel systems in which the cytoskeleton and related structures are the ground floor. Parallel systems in both computers and biological systems rely on lateral connections and networks to provide the richness and complexity required for sophisticated information processing. Computer simulations of parallel connected networks of relatively simple switches ("neural nets") develop "cognitive-like functions" at sufficient levels of connectedness complexity-a "collective phenomenon" (Huberman and Hogg, 1985). Philosopher John Searle (Pagels, 1984), who has an understandable bias against the notion that computer systems can attain human consciousness equivalence, points out that computers can do enormously complex tasks without appreciating the essence of their situation. Searle likens this to an individual sorting out Chinese characters into specific categories without understanding their meaning, being unable to speak Chinese. He likens the computer to the individual sorting out information without comprehending its essence.
</p>
<p>
It would be difficult to prove that human beings comprehend the essence of anything. Nevertheless, even the simulation of cognitive-like events is interesting. Neural net models and connectionist networks (described further in Chapter 4) have been characterized mathematically by Cal Tech's John Hopfield (1982) and others. His work suggests that solutions to a problem can be understood in terms of minimizing an associated energy function and that isolated errors or incomplete data can, within limits, be tolerated. Hopfield describes neural net energy functions as having contours like hills and valleys in a landscape. By minimizing energy functions, information (metaphorically) flows like rain falling on the landscape, forming streams and rivers until stable states ("lakes") occur. A new concept in connectionist neural net theory has emerged with the use of multilevel networks. Geoffrey Hinton (1985) of Carnegie-Mellon University and Terry Sejnowski of Johns Hopkins University have worked on allowing neural nets to find optimal solutions, like finding the lowest particular lake in an entire landscape. According to Sejnowski (Allman, 1986; Hinton, Sejnowski and Ackley, 1984) the trick is to avoid getting stuck in a tiny depression between two mountains:
</p>
<p>
Imagine you have a model of a landscape in a big box and you want to find a lowest point on the terrain. If you drop a marble into the box, it will roll around for a while and come to a stop. But it may not be the lowest point, so you shake the box. After enough shaking you usually find it.
</p>
<p>
Figure 1.6: Ten dimensional hypercube with 1,024 nodes, and 10 connections per node. Computer generation by Conrad Schneiker.
</p>
<p>
Hinton and Sejnowski have used this concept of mathematically shaking their neural net simulations to find optimal solutions. It requires a multilevel hierarchy of parallel systems so that one level can "shake" or tune a lower level. Such an arrangement can perhaps explain the relationship between hierarchical layers of parallel systems within the brain. For example, neural networks based on synaptic connection may regulate (and be regulated by) smaller, faster, more comprehensive networks in the intracellular cytoskeleton.
</p>
<p>
Extensive comparisons between information processing in the brain and artificial intelligence have been reviewed by A. M. Decallatay (1986) who feels the laws of thought described in philosophy have been rediscovered by AI: "The mental world of Plato is reproduced in the physical symbols of Newell and Simon." DeCallatay observes that Al represents data by virtual pointers which connect symbols. In computers these virtual relations are actual wires with potential gate connection; in the brain they appear to be neuronal synaptic connections. Within neurons they may be cross-bridge filaments connecting cytoskeletal microtubules. As a computer expert evaluating the brain, DeCallatay states that the brain learns by opening gates to build new connections between elements simultaneously activated. He sees the presence or absence of dendritic spines playing the role of an "all or none" switch at the neural level. Dendritic spines are knobby projections of membrane covered cytoplasm on neuronal dendrites which are generated and maintained by the cytoskeleton and form synapses with other neurons. The most accepted theory for learning and memory in the brain is that of strengthening of specific synapses within neural circuits, an idea generated by Donald Hebb (1949). As will be described in Chapters 4 and 5, dynamic structural activities of the cytoskeleton are responsible for all cytoplasmic rearrangements including formation and regulation of dendritic spines and synapses. The spines are branchings of dendrites which themselves are branchings of neurons. A further dimension of complexity, these cytoskeletal appendages are prime candidates for "synaptic plasticity," the cornerstone for prevalent models of brain learning and memory.
</p>
</div>

</div>

<div id="outline-container-2-3-3" class="outline-4">
<h4 id="sec-2-3-3"><span class="section-number-4">2.3.3</span> Cooperativity and Coherence</h4>
<div class="outline-text-4" id="text-2-3-3">




<p>
Collective effects manifest as diffuse reverberation, sustained oscillation, phase transitions, and deterministic chaos have been observed in computer simulation of parallel networks (Choi and Huberman, 1984). Collective mechanisms can exert long-range cooperativity and an executive level of organization within parallel arrays. Collective phase transitions in brain parallel arrays could be a fabric of consciousness, an "idea" emerging like the property of superconductivity from a large number of simple, "aligned" subunits. In most views the neuronal synapse is the brain's fundamental subunit, however synaptic activities are the net result of dynamic processes orchestrated by the cytoskeleton. Layers of cytoskeletal organization are evident within neurons, and their participation in cognitive functions appears unavoidable. Thus the highly branched cytoskeleton may be another dimension of brain organization, perhaps related to neuronal networks as a "fractal." Many natural processes manifest fractals, growth patterns in which local areas are scaled down images of the entire pattern. This occurs through some form of long range correlation in the pattern: components "know about each other over distances far in excess of the range of the forces between them" (Sander, 1986). Fractal relationships are one type of long range cooperativity (Figures 1.7 and 1.8). Densely parallel interconnected networks of cytoskeletal structures resemble larger scale networks of neurons, and may be viewed as fractal subdimensions of neural networks.
</p>
<p>
Long range cooperativity and collective mechanisms are favored by the
property of coherence which means peak energy excitations within an
area occur "in phase," or simultaneously as in a laser. How may
coherence arise in distributed processes? DeCallatay (1986) proposes
that coherence in the brain and AI need to be imparted from the top of
a hierarchy downward, like the chief executive of a corporation
setting goals and intentions. A different view is that of an
underlying rhythm or beat to which all elements are tuned. Rhythmic
coupling among neurons may be important, and some interpreters of
brain electrical activity (EEG) believe regional brain wave
entrainment leads to functional regions of mental representation. A
more fundamental coherence at the level of protein assemblies may be
universally important for biological cooperativity and communication.
</p>

<div id="Figure-1.7" class="figure">
<p><img src="UC-images/image007.jpg"  alt="UC-images/image007.jpg" /></p>
<p>Figure 1.7: Tree fractal in which branching patterns are the same at every scale, or dimension. Long range order is present. Computer generation by Conrad Schneiker.</p>
</div>


<div id="Figure-1.8" class="figure">
<p><img src="UC-images/image008.jpg"  alt="UC-images/image008.jpg" /></p>
<p>Figure 1.8: Branching box fractal in which patterns are identical at every scale, or dimension. Long range order is present. Computer generation by Conrad Schneiker.</p>
</div>

<p>
Proteins and their components oscillate among specific conformational
states which exist transiently for durations ranging from femtoseconds
(10 ^-15 sec) to minutes or longer. As will be described in Chapter
6, functional conformational states appear coupled to nanosecond (10 ^-9 sec) oscillations and more prolonged "metastable states." Herbert Fröhlich, an eminent physicist who helped develop the theory of superconductivity in the 1950's, has devoted recent efforts to the question of cooperativity in biological systems. Fröhlich (1970, 1975, 1984) argues that biochemical energy supplied to biomolecular assemblies can result in coherent elastic vibrations of individual subunits in the sub-nanosecond time range. The effect presupposes a voltage effect in the biomolecule (i.e. an "electret") and an organized spatial structure whose geometry favors coupling among subunits. Coherent oscillations in an appropriate medium like the cytoskeleton can lead to collective phenomena such as long range cooperativity, communication, and holography.
</p>
<p>
Another model can help explain long range cooperativity in biomolecules. Soviet biophysicist A. S. Davydov has considered almost lossless energy transfer in biomolecular chains or lattices as wave-like propagations of coupled conformational and electronic disturbances: "solitons." Davydov used the soliton concept to explain molecular level events in muscle contraction, however solitons in the cytoskeleton may do what electrons do in computers.
</p>
<p>
The Fröhlich and Davydov approaches may be seen as complementary
(Tuszynski, Paul, Chatterjee, and Sreenivasan, 1984). Fröhlich's
coherency model focuses on time-independent effects (stable states)
leading to order whereas Davydov's model looks at time-dependent
effects which propagate order through the system. These and other
theories of collective effects applied to information processing in
cytoskeletal lattices will be described in Chapters 6 and 8 (7 and 9
in this ed.)
</p>



</div>
</div>

</div>

<div id="outline-container-2-4" class="outline-3">
<h3 id="sec-2-4"><span class="section-number-3">2.4</span> Molecular Computing</h3>
<div class="outline-text-3" id="text-2-4">


<p>
To approach the cognitive capabilities of the human brain, Al must emulate brain structure at the nanoscale. Computer hardware is indeed evolving to smaller switching components, and advantages of proteins themselves are being considered. The smallward evolution of technological computing elements embraces a number of concepts and material collectively known as "molecular computing."
</p>
<p>
The potential advantages of molecular computers have been described by D. Waltz (1982) of Thinking Machines Corporation. 1) Current "planar" computer design is limited in overall density and use of three dimensional space. 2) Further miniaturization is limited with silicon and gallium arsenide technologies. Chips and wires cannot be made much smaller without becoming vulnerable to stray cosmic radiation or semiconductor impurities. 3) Biomolecular based devices may offer possibilities for self-repair or self-regeneration. 4) Certain types of analog, patterned computation may be particularly suited to molecular computers.
</p>
<p>
Forrest L. Carter (1984) of the Naval Research Laboratory has catalyzed the molecular computing movement through his own contributions and by sponsoring a series of meetings on Molecular Electronic Devices (in 1981, 1983, 1986). Strategies described by Carter and others at his meetings have been aimed at implementing nanoscale computing through switching in material arrays of polyacetylenes, Langmuir-Blodgett films, electro-optical molecules, proteins and a number of other materials. Interfacing between nanoscale devices and macroscale technologies is an obstacle with several possible solutions: 1) engineering upward, self assembling components, 2) optical communication, 3) molecular wires, 4) don't interface; build systems that are totally nanoscale (though they'd have to be somehow developed and tested), and 5) a sensitive bridge between macroscale and nanoscale. Technologies which may fulfill this latter possibility include ion beam nanolithography, molecular spectroscopy, quantum well devices, and scanning tunneling microscopy (STM). In STM, piezoceramic positioners control an ultra sharp conductor with a monoatomic tip which can probe and image material surfaces with atomic level resolution. STM related nanotools may soon be capable of ultraminiature fabrication and interfacing: "nanotechnology" (Chapter 10).
</p>
<p>
The medium of information flow in conventional computers is electronic current flow, but electron transfer may be too energetically expensive and unnecessary at the molecular nanoscale. Many of the projected modes of molecular computing rely on propagation of nonlinear coupling waves called "solitons" similar to what Davydov proposed for linear biomolecules. Carter (1981) proposed that solitons could propagate through switching circuits made of branched polyacetylene chains. He has also considered molecular computing in periodic arrays using electron tunneling, soliton "valving" and photo-activated conformational changes in lattice materials. He envisions three dimensional molecular scale memory and switching densities of 1015 to 1018 elements per cubic centimeter, near the theoretical limit for charge separation. A number of materials may be suitable for soliton switching and biological propagation of solitons in proteins has been suggested. Several authors have argued for cytoskeletal solitons mediating information processing (Chapter 8).
</p>
<p>
Wayne State University's Michael Conrad has defined his vision of a molecular computer in which proteins integrate multiple input modes to perform a functional output (Conrad, 1986). In addition to smaller size scale, protein based molecular computing offers different architectures and computing dimensions. Conrad suggests that "non-von Neumann, nonserial and non-silicon" computers will be "context dependent," with input processed as dynamical physical structures, patterns, or analog symbols. Multidimensional conditions determine the conformational state of any one protein: temperature, pH, ionic concentrations, voltage, dipole moment, electroacoustical vibration, phosphorylation or hydrolysis state, conformational state of bound neighbor proteins, etc. Proteins integrate all this information to determine output. Thus each protein is a rudimentary computer and converts a complex analog input to an output state or conformation.
</p>
<p>
Conrad and Liberman (1982) have defined an "extremal computer" as one which uses physical resources as effectively as possible for computation. They suggest that an extremal computer should be a molecular computer, with individual switches or information representation subunits composed of molecules. The state of each information. subunit should be coupled to an energy event near the quantum limit. Protein conformational states leveraged to dipole oscillations in the nanoscale may be that limit. Conrad and Liberman conclude that, within biological systems, macromolecular computing occurs by conformational changes generating "reaction diffusion patterns" of concentrations of biochemical energy molecules (cyclic AMP).
</p>
<p>
A 1984 conference (Yates, 1984) considered Chemically Based Computer Designs (Yates, 1984) and attempted to answer 6 relevant questions. 1) Are there fundamental, quantum mechanical limitations on computation? This question deals with energy loss due to friction or other factors in computation. The work of Benioff (1980, 1982), Landauer (1982) and Feynman (1986) lead to the conclusion that, in principle, computation can be achieved by a frictionless, energy conserving system. Thus there appear to be no quantum mechanical limitations on computation. 2) Are there fundamental, thermodynamic limitations on computation? Although there are some computing operations that are irreversible and dissipative, the work of Landauer (1982) and Bennett (1982) show that there are no fundamental thermodynamic limitations on computation per se. 3) Are there fundamental limits to serial processing on digital computers based on binary switches? This question has philosophical implications (does the universe function through continuous or discrete processes?) and so cannot be answered assuredly. The consensus of the conference was that there are probably limits on serial, digital computing. 4) What are the practical physical limitations on computer design? There are several practical limitations to the further miniaturization of digital switching circuits. However those limits probably won't be reached for decades. 5) What are the potential contributions of molecular electronics to digital computer design? The conference considered molecular conformational changes, solitons, charge flow and other approaches. Molecular gates, wires and switches may be worth trying to build, although redundancy and parallelism may be necessary. 6) Do biochemical systems inspire technological imitations for the purpose of computer design? Many biological systems (DNA, antibodies, receptors, enzymes) were reviewed and a major conclusion was that,
</p>
<p>
None of these materials is as rich in chemoelectric physical phenomena as are (cytoskeletal) microscopic biological objects. Microtubules offer the most possibilities for inspiring chemically based computation! (Yates, 1984)
</p>
</div>

</div>

<div id="outline-container-2-5" class="outline-3">
<h3 id="sec-2-5"><span class="section-number-3">2.5</span> Dynamic Pattern Representation</h3>
<div class="outline-text-3" id="text-2-5">

<p>Processing of patterns or symbols is conducive to optimal
computing. Patterns can be dynamically represented by a number of
descriptive mechanisms which would be useful in both AI and biological
systems. These include reaction-diffusion systems, holograms, macrons,
and cellular automata.
</p>

</div>

<div id="outline-container-2-5-1" class="outline-4">
<h4 id="sec-2-5-1"><span class="section-number-4">2.5.1</span> Reaction Diffusion Systems</h4>
<div class="outline-text-4" id="text-2-5-1">

<p>Reaction diffusion systems are evolving patterns which result from
various types of reactions and product diffusion within a dynamic
medium. Biological reaction diffusion systems within the submembrane
cytoplasm have been suggested by Conrad and Liberman (1982) as a
mechanism of biological information representation. In their model,
reaction diffusion patterns of the energy rich nucleotide, cyclic AMP,
which are regulated by the membrane are the texture of cytoplasmic
information. Propagation and interaction of chemical, nonlinear waves
lead to pattern formation in a number of chemical and biological media
(Winfree and Strogatz, 1984). In the well studied
"Belousov-Zhabotinsky reaction," spiral chemical reaction waves
propagate at uniform speed and interact with other waves to produce
complex patterns. Waves radiate from spiral centers at a rate of a few
millimeters per minute as the spirals turn in about one
minute. Several chemical reactions with suitable diffusion rates and
visible color changes of reaction products show these characteristic
patterns, as do cultured amoeba cells responding to pulses of cyclic
AMP (Figure 1.9). Similar phenomena have also been reported in retinal
and cortical nerve nets and in heart muscle. Smaller scale reaction
diffusion patterns are accordingly faster.
</p>


<div id="Figure-1.9" class="figure">
<p><img src="UC-images/image009.jpg"  alt="UC-images/image009.jpg" /></p>
<p>Figure 1.9: Self organizing spatial and temporal patterns described by the chemical reaction-diffusion system known as the Belousov-Zhabotinsky reaction and emulated by biological systems. With permission from Arthur Winfree.</p>
</div>

<p>
Winfree and Strogatz (1984) have studied the 3 dimensional behavior of
reaction diffusion systems. They find that reaction diffusion waves
commonly appear as involute spirals or scrolls radiating from tiny
rotating activity patterns called "organizing centers." The scrolls
emanate from their central organizing axis which typically forms a
closed ring or toroidal vortex. The origin of the waves is defined as
a phase singularity whose immediate neighborhood is a rotating pattern
of chemical activities, the pivot of the rotating spiral wave from
which it radiates. The ostensibly flat spiral is actually a cross
section of a three dimensional wave shaped like a scroll which emerges
from a filament of singularity in 3 dimensions (Figure 1.10).
</p>

<div id="Figure-1.10" class="figure">
<p><img src="UC-images/image010.jpg"  alt="UC-images/image010.jpg" /></p>
<p>Figure 1.10: Three dimensional computer simulation of a reaction-diffusion system. A filamentous organizing center emanates "scroll ring" patterns. With permission from Arthur Winfree.</p>
</div>

<p>
Cytoplasmic microtubules and centrioles are organizing centers which could behave like the singularities described by Winfree and Strogatz. Dynamic activities of the cytoskeleton may release diffusing waves of calcium ions which can alter the nature of surrounding cytoplasm by sol-gel transformations (Chapter 5). Coding by microtubule associated proteins (MAPs) and other factors could result in reaction-diffusion patterns specific to the dynamic state of the organizing center. Such patterns could suffice as short term memory in cells ranging from simple protozoa to human brain neurons. Another type of interactive, 3 dimensional pattern with interesting properties is the hologram.
</p></div>

</div>

<div id="outline-container-2-5-2" class="outline-4">
<h4 id="sec-2-5-2"><span class="section-number-4">2.5.2</span> Holograms</h4>
<div class="outline-text-4" id="text-2-5-2">

<p>The brain stores image files in a "distributed" manner which is resistant to local damage and allows for correct retrieval even when variable cues or addresses are presented. One explanation is that memory, learning and real time cognitive functions are represented in the brain by interference patterns which are the convergence of two or more wave trains: signal and reference information sources (Hudspeth and Jones, 1975). Interference patterns can be dynamic, expressive, ordered or chaotic; one example is the ocean surf as an interface and monitor of the collective effects of wind, current, beach, tides, water bonds, etc. Interference patterns are used in information and imaging technologies such as interferometry, coherent processing, autocorrelation filtering, pattern recognition and many others whose capabilities are limited by their coupling medium (Dolgoff, 1975). All space in the universe is, as 17th century German philosopher Leibniz said, "the result of harmonious coexistence of forces." Consciousness as well may be described as the dynamic coexistence of forces within the brain, although the harmony may vary over time.
</p>
<p>
A method of recording and reconstructing wavefronts associated with interference patterns is call "holography," a technology whose mechanism has inspired numerous speculations of "holographic" brain function and consciousness. Holography is a method of information storage employing coherent beams of electromagnetic radiation. It was invented in the late 1940's by Denis Gabor (1948) who won the Nobel prize, and achieved technical importance with the arrival of the laser as a convenient source of coherent light in the 1950's. A hologram is a permanent record of the pattern of interference between two sources of coherent light (or any coherent waveforms) in localized regions of space, usually a photographic film plate. Subsequent reference waves unlock the patterns from storage. The record of both the original interfering waves are stored and the relevant information used as an address to retrieve patterns. Each portion of the hologram contains information about each part of both original interfering waves. Consequently reillumination of any small fragment of a hologram will recreate the entire image stored there, losing only focus or clarity. Holograms thus store image files in a "distributed" manner, much like the brain is thought to function, and are also "fractal," in that small portions are scaled down versions of the whole. By exposing a hologram to time varying sets of interfering waves, it can function as a distributed memory. These properties led to a flurry of holographic brain models (Westlake, 1970; Longuet-Higgins, 1968; Pribram, 1971). Among these, van Heerdon (1968) discussed methods of optical information storage in solids using coherent light. Van Heerdon pointed out that such systems can store large amounts of information although they require a calibrating system to maintain exact phase relations between waves. Requirements for well tuned filters or coherent resonators to maintain phase relations between patterns in the spatial domain remain a major question regarding holographic models of brain function and memory. Consequently the biological existence of holograms has been questioned, based on the assumption that the coherence and phase relation would have to be provided at the cellular or neural level. However, nanoscale coherence may have the required spatial and temporal periodicity to generate cytoplasmic holograms. Photo-refractive crystals can produce dynamic, real time holography (Gower, 1985). Conformational dynamics of the cytoskeleton could tune and generate coherent standing waves and interference patterns of calcium gradient fields, sol-gel states, and structure of the cytoskeletal microtrabecular lattice (Chapters 6 and 8). Dynamic and deterministic intracellular patterns would be useful in biological activities of all sorts. Holographic models of consciousness including a cytoskeletal approach will be described further in later chapters.
</p>
</div>

</div>

<div id="outline-container-2-5-3" class="outline-4">
<h4 id="sec-2-5-3"><span class="section-number-4">2.5.3</span> Macrons.</h4>
<div class="outline-text-4" id="text-2-5-3">

<p>The evolution of form and information from chaos has been termed "morphogenesis" and related to philosophical literature from many cultures. Mathematician Ralph Abraham (1976) has compared mathematical descriptions of the dynamic evolution of biological form to the Rigveda, I-Ching, Kabala, and Heraclitus. Using the catastrophe theory of Rene Thom (1973) and an observational device, the macroscope of Hans Jenny, Abraham has studied collective vibrational patterns which occur widely in nature and which he calls "macrons." Abraham describes physical, chemical, and electrical categories of macrons which may be further subdivided according to the material state of the macron medium. For example, physical macrons may occur within a solid, isotropic liquid, liquid crystal, or gas. Abraham cites one example of a solid macron: if a flat metal plate is vibrated transversely by an external force such as coupled electromechanical transducers, a vibrational pattern may be observed as a "spider-web" of motionless curves (the "Chladni" nodal lines). Originally observed by sprinkling sand on a vibrating plate, these patterns more recently have been observed by laser interferometry. The pattern is the "macron" and depends upon intrinsic dimensions and elasticity of the medium, and extrinsic frequency and amplitude of the driving force. The plate is a two dimensional example, however a simple rubber ball may be visualized with stable vibrational modes characterized by symmetric distortions of shape separated by motionless nodal surfaces. Another macron example is a round dish filled with a thin layer of isotropic liquid. If the bottom of the dish is heated, the liquid will soon begin to simmer; careful observation reveals nodal lines and packed hexagons called Benard cells within which the liquid convects toroidally. This Benard phenomenon, also seen as wind induced patterns in the sands of the Sahara and other deserts, is also considered by Abraham as a macron. These macrons or stable modes also depend on intrinsic controls such as shape, compressibility and viscosity, and external controls such as frequency and amplitude of the driving force.
</p>
<p>
Other forms of macrons described by Abraham include smoke rings, opalescences like abalone shell, and the aurora borealis or Northern Lights. Turning to the brain, Abraham conjectures: "a thought is a macron of the brain bioplasma." He proposes that spatial patterns of EEG are electrical macrons at dendritic surfaces or that macrons occur within nerve cells. He suggests that repetitive reinforcement of specific macrons "hardens" them into a structural form in a learning mechanism. Abraham's macrons may be compared to standing waves, reaction diffusion systems, and holograms which can all manifest 3 dimensional analog patterns of interactive information suitable to the cytoskeleton. Another "digital" system of interactive patterns in dynamic lattices is the "cellular automaton."
</p></div>

</div>

<div id="outline-container-2-5-4" class="outline-4">
<h4 id="sec-2-5-4"><span class="section-number-4">2.5.4</span> Cellular Automata</h4>
<div class="outline-text-4" id="text-2-5-4">

<p>Complex behavior resulting from collective activities of simple subunits occurs in "cellular automata." Von Neumann's (1966) original cellular automaton consisted of a large number of identical "cells" connected in a uniform pattern. The term "cell" was chosen by Von Neumann and others as the indivisible subunit in "cellular automata" based on biological "cells" as indivisible subunits of life. Much like atoms once indivisible, are now recognized to be composed of electrons, protons, neutrons, quarks, etc., it is now apparent that biological cells are complex entities whose actions depend on collective functions of intracellular structures including the cytoskeleton. Nevertheless, "cellular" in cellular automaton jargon means an indivisible grain, a discrete subunit with a finite number of states. The essential features of cellular automata are 1) at a given time, each cell is in one of a number of states. 2) The cells are organized according to a fixed geometry. 3) Each cell communicates only with other cells in its neighborhood; the size and shape of the neighborhood are the same for all cells. Depending on geometry, the number of neighbors may be 4 (rectangular), 6 (hexagonal), 8 (rectangular with corners) or more neighbors per subunit or cell. 4) There is a universal clock. Each cell may change to a new state at each tick of the clock depending on its present state, and the present states of its neighbors. The rules for changing state are called the transition rules of the cellular automata. At each clock tick (or "generation") the behavior of each cell depends only on the states of its neighbors and its own state. In cellular automaton, simple neighbor rules can lead to complex, dynamic patterns.
</p>
<p>
Cellular automaton may be considered similar to lattice models such as a two dimensional Ising generator. Based on magnetic spin states of components within a lattice, Ising generators evolve to stable patterns in which states of opposite spin align in one direction, and like spins align in another direction. A generalized two dimensional Ising generator is shown in Figure 1.11. Cellular automaton models in microtubules (Chapter 8) evolve to similar states in which opposite states align in one direction, and similar states align in another direction (Figure 1.12).
</p>
<p>
Von Neumann studied how cellular automata could perform useful
computations. He assumed a large number of cells start in a quiescent,
or inactive state and that input was encoded by placing a number of
contiguous cells in a specific pattern. By then running the clock
through a sequence of generations, an output can be obtained by the
patterns of states at a later time. A cellular automaton is said to be
universally computing if, for any solvable problem, there is an
initial configuration of the cellular automaton which evolves to a
configuration containing the solution. As far as implementing such
computing capabilities, access to every cell must be established to
set its initial state and read its final state. Von Neumann discovered
a universally constructing cellular automaton in which an initial
configuration of a small number of cells (the "constructor") can set
initial states of distant cells to the pattern required to solve any
problem. The constructor communicates with distant cells through
intermediate cells according to transition rules. If a cellular
automaton is universally constructing, it can be "programmed" to solve
any problem, even if only a few cells can communicate with the outside
world. Several universally constructing cellular automata have been
devised in simulation; "constructors" as patterns of cytoskeletal
subunit conformation would be useful mechanisms for biological
computation.
</p>
<div id="Figure-1.11" class="figure">
<p><img src="UC-images/image011.jpg"  alt="UC-images/image011.jpg" /></p>
<p>Figure 1.11Two dimensional Ising generator evolves to stable state of opposite spin states aligned horizontally, and like spin states aligned diagonally. This stable configuration is similar to MT automaton simulation (Figure 1.12). Computer generation by Conrad Schneiker.</p>
</div>

<p>
Cellular automata are frequent topics of Scientific American's
Mathematical Games columns. Written by Martin Gardner and, more
recently, A. K. Dewdney these columns have intermittently focused on
the game of "Life," a cellular automaton invented by Cambridge
mathematician John Conway in 1968 (Gardner, 1970). "Life" is played on
a large two-dimensional grid of square cells. Each cell has eight
neighbors, four at the edges and fourat the corners, and exists in one
of two states: "dead" or "alive." At each generation, cells may die or
come alive, their fate determined by the number of living
neighbors. For example a living cell with fewer than two living
neighbors, or more than three, will not survive (due to lack of
sustenance or overcrowding, respectively). A dead cell will be born in
a subsequent generation if it has exactly three living neighbors (or
"parents"). Conway's game was named "Life" because the cells could be
either dead or alive, however the behavior of the patterns of "living"
cells included some "life-like" behaviors. These included movement
through the grid and oscillatory patterns which came to be called
blinkers, beacons, gliders, and beehives. Repeating von Neumann,
though in a much simpler format, Dewdney (1985) showed that a computer
could exist within the game of Life.
</p>

<div id="Figure-1.12" class="figure">
<p><img src="UC-images/image012.jpg"  alt="UC-images/image012.jpg" /></p>
<p>Figure 1.12: Cellular automaton model in microtubules (Chapter 8) reaches stable state in which opposite states are aligned along long axis of MT, and like states aligned along rows. A "kink-like" pattern is seen moving through the structure. By Paul Jablonka.</p>
</div>

<p>
Carter Bays has extended the game of "Life" to three dimensions (Dewdney, 1987). In his version, each cell is a cube with 26 neighbors, but the neighbor rules are essentially the same as in Conway's two-dimensional "Life." A variety of interesting behaviors ensue in Bay's "Life," dependent on initial patterns. For example he observed a 10 cube "glider" traveling through space like a "sofa in free fall." Another 7 cube form (a "greeter") dies unless it is in the presence of another structure. Gliders which pass near greeters are grabbed and held until rescued by a second glider which collides with the repressive greeter. Other stable patterns emerge which Bays has called arcades, stairs, helices, and space-time barriers. Life and other cellular automata have enraptured computer buffs who can now create their own realms. Beyond that, cellular automata have serious scientific and mathematical implications.
</p>
<p>
Stephen Wolfram (1984) has viewed cellular automata as systems of simple components capable of complex collective effects such as the simulation of partial differential equations and deterministic chaos. He has described four general behaviors for cellular automata patterns. 1) They disappear with time, 2) they evolve to a fixed finite size, 3) they grow indefinitely at a fixed speed, 4) they grow and contract irregularly. Type three, which grow indefinitely at a fixed speed, are often found to be self similar in scale; parts of such patterns when magnified are indistinguishable from the whole. Thus these cellular automata patterns are characterized by a fractal dimension.
</p>
<p>
Wolfram notes that the mechanisms for information processing in
natural systems appear more similar to those in cellular automata
which are highly parallel than to conventional serial processing
computers. The "results" are given by the configuration obtained; the
"medium is the message." Further, "it is common in nature to find
systems whose complexity is generated by the cooperative effect of
many simple identical components." Cellular automata are sensitive to
initial conditions and their behavior is characterized by the
stability or predictability of their behavior under small
perturbations in initial configurations. With a given set of rules,
changes in a single initial site value can lead to markedly different
patterns. Such perturbations have characteristic effects on Wolfram's
four classes of cellular automata: 1) no change in final state, 2)
changes only in a finite region, 3) changes over an ever increasing
region, 4) irregular change. Thus at least some cellular automata
patterns are nonlinear and deterministic.
</p>

<div id="Figure-1.13" class="figure">
<p><img src="UC-images/image013.jpg"  alt="UC-images/image013.jpg" /></p>
<p>Figure 1.13: Self replicating automata described by Edward Fredkin (Dewdney, 1985). "Off" states are shown as all black. Computer generation by Conrad Schneiker.</p>
</div>


<div id="Figure-1.14" class="figure">
<p><img src="UC-images/image014.jpg"  alt="UC-images/image014.jpg" /></p>
<p>Figure 1.14: Self replicating automata described by Edward Fredkin (Dewdney, 1985). Computer generation by Conrad Schneiker.</p>
</div>

<p>
Cellular automata can be ascribed to exist within a variety of environments. Perhaps the most extreme view is that the universe is a cellular automaton. MIT's Edward Fredkin has been contending that the universe may work according to the same principles as a cellular automaton (Wright, 1985). He believes the basic material of which everything is made of can be considered as information rather than mass and energy. Working at the interface of physics and computer science, Fredkin has become intrigued with the relations between cellular automata and nature. With the right rules, a cellular automaton can simulate the formation of a snowflake, mollusc shell, or galaxy. Fredkin's view is to apply cellular automata to fundamental levels of physics and the rules needed to model the motion of molecules, atoms, electrons, and quarks. With sufficient information to model these particles, an automaton may be designed that describes the physical world with perfect precision. At that level, says Fredkin, the universe is a cellular automatonin three dimensions: a lattice of interacting logic units, each one deciding billions of times per second whether it will be "off or on" at the next instant. Fredkin sees this information as the fabric of reality, the stuff from which matter and energy are made. He argues that cellular automata can represent the universe as usefully as can differential equations, the prevalent mathematical alternative. The cellular automaton view is by far the simpler. A child can understand the rules governing a cellular automaton and with pencil, paper and enough time can predict the course of an automaton including charting the growth of a snowflake, the ripples of a pond or a sound wave. Cellular automata are the language of pure information and may be involved in biological information processing as well as future computer devices. Forrest Carter (1984) of the Naval Research Lab and James Milch (1986) of Eastman Kodak have both proposed the construction of molecular automata, extolling the virtues of the cellular automaton concept applied to problems of interfacing to molecular scale devices. With a large cellular automaton molecular computer, communication to the "macro" world need only interface with a "constructor," a small portion which can take advantage of the entire cellular automaton capacity.
</p>
<p>
Subunits of cytoskeletal microtubules may be particularly suitable for "cellular" automaton behavior and information processing in the nanoscale. Cytoskeletal automata and their dynamic consequences may be an important substrate of biological computing ranging from the actions of single cells to brain/mind consciousness. Will they pave the way to Ultimate Computing?
</p></div>
</div>
</div>

</div>

<div id="outline-container-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> Brain/Mind/Computer</h2>
<div class="outline-text-2" id="text-3">




</div>

<div id="outline-container-3-1" class="outline-3">
<h3 id="sec-3-1"><span class="section-number-3">3.1</span> Metaphors of Consciousness</h3>
<div class="outline-text-3" id="text-3-1">

<p>Systems for information processing are evolving within both biological life forms and computer technologies. The most highly evolved information processing system currently appears to be human consciousness which resides in the human brain. The scientific relationships between consciousness and structural brain activities remain obscure and are often referred to as the brain/mind "duality." To explain this duality, humans have historically perceived their minds in the context of predominant cultural themes, particularly information technologies. Author Julian Jaynes (1976) has chronicled how the metaphors of the mind are the world it perceives. The trail of brain/mind metaphors perhaps began during the Greeks' Golden Age. According to Plato, Socrates said:
</p>
<p>
Imagine &hellip; that our minds contain a block of wax &hellip; and say that whenever we wish to remember something we hear or conceive in our own minds, we hold this wax under the perceptions or ideas and imprint them on it as we might stamp the impression of a seal ring.
</p>
<p>
The Greeks traveled about in freedom (while their slaves did the work) and consciousness was perceived by free men as a free entity. Heraclitus described consciousness as an "enormous space whose boundaries could never be found out." Later, Augustine of Carthage described "the mountains and hills of my high imagination," "the plains and caves and caverns of my memory" with "spacious chambers wonderfully furnished with innumerable stores."
</p>
<p>
The geological discoveries in the 19th century revealed a record of the past written in layers of the earth's crust. Consciousness became viewed as layers recording an individual's past in deeper and deeper layers until the original record could no longer be read. This emphasis on the unconscious mind grew until the late 19th century when most psychologists thought that' consciousness was but a small part of the mind. As chemistry superceded geology in scientific esteem, consciousness became viewed as a compound structure that could be analyzed in a laboratory into precise elements of sensations and feelings. When steam engines became commonplace, the subconscious was perceived as a boiler of straining energy demanding release, and when repressed, pushing up and out into neurotic behavior. In the early part of the 20th century, mind metaphors continued to encompass technologies for information processing such as telephone switching circuits, tape recorders, clocks, holograms, and computers.
</p>
<p>
The computer is the most recent brain/mind metaphor and has evolved
qualitatively beyond its predecessors (as has human
consciousness). Computer technology has approached, and in some cases
surpassed, some aspects of human brain function such as "brute force"
calculations. Computers may also be used to simulate dynamical systems
(including the brain), thus providing a metaphorical medium. In
efforts to construct computing machines capable of independent logic
and decision making, artificial intelligence (AI) researchers have
examined what is known about the workings of the brain and
mind. Accordingly, they have been led away from classical "serial"
computers towards massively parallel systems with high degrees of
lateral interconnection. Because the brain at first glance is a
parallel aggregation of billions of neurons with tens of thousands of
connections per neuron, AI researchers of the connectionist school
have viewed and modeled the brain as "neural networks" which may be
simulated on conventional computers. These neural net models, to be
discussed later in this book, are based on relatively simple
assumptions regarding interneuronal synapses as switches between
neurons. Dynamic patterns of neural net activity can simulate systems
capable of learning, independent recognition, different "mental"
states, and with some imagination, rudimentary consciousness. The
general architecture of parallel computers is similar to neurons
within the brain, and can take advantage of simultaneous processing
with lateral resolution of conflicting concepts. Despite these
apparent similarities, the brain's complexity and the dynamic vastness
of human consciousness remain unassailable by current technology. The
mind remains enigmatic to brain and computer.
</p>

<div id="Figure-2.1" class="figure">
<p><img src="UC-images/image015.jpg"  alt="UC-images/image015.jpg" /></p>
<p>Figure 2.1: The Brain/Mind/Computer metaphorical triangle. Is the cytoskeleton the key to understanding?</p>
</div>

<p>
Brain, mind, and computer are mutually metaphorical; each is related to the other in ways that are not clearly understood. This impasse, the "brain/mind/computer triangle," is based on an incorrect assumption. The irreducible substrate of information processing within the brain has been assumed to be the notoriously slow interneuronal synapse. Consequently, synapses have been compared to simple switches, and the brain has been compared to a computer composed of a collection of synaptic switches. Because each neuron within the brain has up to several hundred thousand synapses, it must "integrate" information from among these synapses to regulate its output. Neurons utilize a variety of analog functions including dendritic morphology, slow wave membrane properties, and cytoskeletal activities which determine their responses within neural networks, and which alter synaptic efficacy as apparent mechanisms of learning. Thus each of the billions of neurons in the brain is a computer. Similarly, single cell organisms which have no synapses and are independent agents perform complex tasks involving rudimentary decision making, behavior, and organization. Thus, the basic irreducible substrate of information should reside within biological cells, and the brain may then be viewed as an organized assembly of billions of computers in which collective emergent properties may be specifically related to consciousness. The hierarchy of brain organization may thus have a secret basement-a new "dimension." Advances in intracellular imaging and molecular biology have illustrated the complex dynamic organization of intracellular cytoplasm. Specifically a dense, parallel, highly interconnected solid state network of dynamic protein polymers, the "cytoskeleton," is a medium which appears to be ideally suited for information processing, and which is actively involved in virtually all cell functions. Appreciation of this "cytoskeletal dimension" may be the key to the brain/mind/computer triangle (Figure 2.1).
</p></div>

</div>

<div id="outline-container-3-2" class="outline-3">
<h3 id="sec-3-2"><span class="section-number-3">3.2</span> Historical Perspectives-Consciousness as &hellip;</h3>
<div class="outline-text-3" id="text-3-2">

<p>Many disciplines have concerned themselves with attempts to understand consciousness. Like the proverbial group of blind men trying to describe an elephant, each discipline's perception is highly dependent on its orientation and particular elephant part it happens to contact. The blind men succeed, largely because they have the elephant surrounded.
</p>
<p>
Some feel the mind is too complicated to be described by the human brain. Perhaps the mystery of the mind is a necessary barrier to man's "roboticization"? As philosopher Richard Rorty has said: "the ineffability of the mental serves the same cultural function as the ineffability of the divine-it vaguely suggests that science does not have the last word" (Jaynes, 1976). Despite these worries, a progression of theories and metaphors of the mind have evolved and are reviewed historically in Julian Jaynes' book, The Origin of Consciousness and the Breakdown of the Bicameral Mind. Jaynes describes eight solutions to the brain/mind problem developed through the 20th century. They describe consciousness as a property of matter, of protoplasm, of learning, as a metaphysical imposition, a helpless spectator, an emergent property of evolution, behavior, and as activity within the brain's reticular activating system. These are reviewed with modifications and additions relevant to computer technology and the cytoskeletal dimension. 
</p>

</div>

<div id="outline-container-3-2-1" class="outline-4">
<h4 id="sec-3-2-1"><span class="section-number-4">3.2.1</span> Consciousness as Particle/Wave Physics</h4>
<div class="outline-text-4" id="text-3-2-1">

<p>Great discoveries in 19th century particle physics dissolved the solidity of  matter into mere mathematical relationships in space. Thoughts, feelings, introspection, and mind-environment interactions were related to the brain as waves to electrons. In the 20th century, Nobel biochemist Albert Szent-Gyorgyi (1960) wrote Introduction to a Submolecular Biology in which he perceived the essence of life and consciousness to exist in coordinated electron movement within semiconductive proteins. Others, including Russian physicists Pullman and Pullman (1963) compared life and consciousness with the mobility of electrons within resonant bond orbitals. Scottish biologist A. G. Cairns-Smith (1985) has theorized that life developed from crystals of clay. The molecular lattice structure in clay allows for shifting neighbor relationships and processing of information which Cairns-Smith has likened to genetic development. These views equate life's basic processes with those of atoms and sub-atomic particles. Information is represented as dynamic electron patterns within computers, and life and consciousness are certain to be related to fundamental particle activities. The questions are how, where and at what level of organization?
</p>
</div>

</div>

<div id="outline-container-3-2-2" class="outline-4">
<h4 id="sec-3-2-2"><span class="section-number-4">3.2.2</span> Consciousness as a Property of Protoplasm</h4>
<div class="outline-text-4" id="text-3-2-2">

<p>Believing that consciousness is a fundamental property of all living things, some 19th century biologists saw its essence in the irritability of the smallest one cell organisms. Popular books of this era included, The Animal Mind by M. F. Washburn, and The Psychic Life of Microorganisms by Alfred Bonet. Observation of an amoeba hunting food or responding to various stimuli, or paramecium avoiding obstacles or conjugating led to application of human psychology to such behavior. These concepts were accepted by Charles Darwin and E. B. Titchner, who saw such rudimentary consciousness related to man through the course of evolution.
</p>
<p>
Circumstantial support for this thesis is found in the inhibitory effects .of general anesthetic gases on protoplasmic streaming in slime molds, and anesthetic inhibition of amoeboid and paramecium motility. This suggests a common link between these primitive organism activities and brain activities related to consciousness in that all are reversibly sensitive to the same anesthetic gas molecules at comparable concentrations. Protoplasmic streaming,
</p>
<p>
amoeboid movement and paramecium motility all depend on dynamic activities of cytoskeletal structures including "computer-like" cytoplasmic microtubules, actin sol-gel transitions, and ciliary appendages (Chapter 5). The cytoskeletal link among anesthetic sensitive processes could be a clue to the brain/mind/computer triangle.
</p>
<p>
Jaynes objects to protoplasmic consciousness, suggesting that humans may be projecting their own mind functions onto protozoan behavior which he believes to reside entirely in physical chemistry rather than introspective psychology. However, introspective psychology itself is in all probability a function of physical chemistry at some level. If an amoeba, or slime mold, or paramecium are not conscious, at what point in the evolutionary hierarchy does consciousness emerge? Stanford University Professor Karl Pribram (1966), known for his conceptualization of mind functions as "holographic," recalls being confronted with this issue during a lecture at the Montreal Neurological Institute in the late 1950's. Famed neuroscientist Wilder Penfield asked Pribram whether the difference between man and the non-human primates was quantitative or qualitative. Pribram replied that the difference was quantitative but to such an extent that qualitative changes emerged. He cited the relatively new computer technology as an example: vast increases in the capacity of memory and central processors had changed computational power not only quantitatively but qualitatively. Penfield argued for a more fundamental distinction to distinguish man. Pribram countered by saying that, although the only difference in brain structure between man and other animals is quantitative, changes in organization, chemical composition, developmental sequence, and in time and duration of critical periods had led to collective emergence of qualitatively distinctive properties. The quantitative common link of consciousness may be the cytoskeleton within cells ranging from single cell organisms, viruses, (and perhaps more simple "life" forms such as "prions," or independent protein structures) to neurons within the human brain. The qualitative differences appear to lie in nonlinear collective properties related through evolution to structural complexity.
</p></div>

</div>

<div id="outline-container-3-2-3" class="outline-4">
<h4 id="sec-3-2-3"><span class="section-number-4">3.2.3</span> Consciousness as Learning</h4>
<div class="outline-text-4" id="text-3-2-3">

<p>Proponents of this view believed that consciousness began at some specific time after life evolved and was directly related to learning. The rationale was: if an animal modifies its behavior on the basis of experience, it must be having an experience and therefore must be conscious. By equating learning, experience and consciousness, this school viewed associative processes as the essential element of consciousness.
</p>
<p>
Models of associative memory in neural net computer simulations may be bolstered by the historical glorification of learning per se, and learning is important for biological success. Structural correlates of learning in mammalian brain (discussed in Chapter 4) appear to involve strengthening of specific synapses brought about by a dynamic reorganization of the neuronal cytoskeleton. However, as Jaynes observes, learning and consciousness are separate problems. AI systems can learn, but they clearly are not conscious. Information may be perceived in human consciousness, exist in short term memory, but fail to be stored in long term memory-hence no "learning" occurs. Certain drugs, including some anesthetics and tranquilizers, specifically block long term memory storage and retrieval in conscious patients. Thus consciousness constitutes more than learning.
</p></div>

</div>

<div id="outline-container-3-2-4" class="outline-4">
<h4 id="sec-3-2-4"><span class="section-number-4">3.2.4</span> Consciousness as a Metaphysical Imposition</h4>
<div class="outline-text-4" id="text-3-2-4">

<p>Assessment of the evolutionary link, but intellectual chasm, between civilized man and apes resulted in a metaphysical view: consciousness could not have evolved merely by natural selection from assemblages of molecules and cells. Something must have been added from outside of the closed system to account for an entity so different as human consciousness. This school was founded by Alfred R. Wallace, co-discoverer of the theory of natural selection with Charles Darwin. Wallace believed that some metaphysical force had directed evolution at three different points: the beginning of life, the beginning of consciousness, and the beginning of civilized culture. Because Wallace sought evidence for a metaphysical force among vitalists, spiritualists, and seances, he was discredited and Darwin became known as the discoverer of evolution.
</p>
<p>
Some so called vitalists and spiritualists attempted to apply particle/wave physics to what was then known about cell biology in their search for consciousness. Like Wallace, they were vilified because they had no proof and the scientific establishment felt that to explain consciousness by metaphysical imposition was outside the realm of science.
</p>
<p>
Modern bioelectromagnetic field theories pertaining to embryology and consciousness have been proposed by many authors but remain undocumented. Dynamic nanoscale activities within a cytoskeletal information system could provide such a field yet be beyond detection by current technologies. Future nanotechnology may permit detection of these fields, if they exist. The metaphysical imposition theory, its "vitalist" and particle/wave physics counterparts remain speculation, but the degree to which they irritate the scientific establishment is noteworthy. Perhaps it is because they blur the distinction between science, philosophy and religion. This may presage violent opposition to the future development of artificial consciousness.
</p></div>

</div>

<div id="outline-container-3-2-5" class="outline-4">
<h4 id="sec-3-2-5"><span class="section-number-4">3.2.5</span> The Helpless Spectator Theory</h4>
<div class="outline-text-4" id="text-3-2-5">

<p>A materialistic view of the origin of consciousness arose in response to the metaphysical imposition theory. The helpless spectator theory suggests that life is like a roller coaster ride and that consciousness does nothing at all, being an epiphenomenon to important biological activities. As a helpless spectator of cosmic events, consciousness was described as
</p>
<p>
the heat given off by wires, colors laid on the surface of a mosaic, the movement of a train going along tracks that have determined its destiny, the melody that floats from a harp but cannot pluck its strings, the foam raging from a river that cannot change its course, the shadow of a pedestrian (Jaynes, 1976).
</p>
<p>
Giving up on free will, T. H. Huxley bleakly summarized "we are conscious automata." (The negative connotation of automata as helpless spectators prevails in the context of robots and machines, however should not be confused with the notion of cellular automata which may independently process information and deterministically compute, and which have been likened to biological processes.) The helpless spectator theory was rejected by William James who found inconceivable the notion that consciousness should have nothing to do with the business it so faithfully attends. He asked, "why is consciousness more intense when action is most hesitant, why are we least conscious when doing something most habitual?"
</p></div>

</div>

<div id="outline-container-3-2-6" class="outline-4">
<h4 id="sec-3-2-6"><span class="section-number-4">3.2.6</span> Emergent Evolution</h4>
<div class="outline-text-4" id="text-3-2-6">

<p>In this view, consciousness was rescued from the undignified position of a helpless spectator by reconciling the metaphysical imposition view with collective emergent properties. One metaphor used was: as the property of wetness cannot be derived from the properties of hydrogen and oxygen atoms alone, so consciousness emerged at some point in evolution in a way underivable from its constituent parts. John Stewart Mill and others suggested that as properties of matter emerged from an unspecified forerunner, properties of complex compounds emerged from conjunction of simpler compounds, and properties distinctive of living things emerged from the conjunction of these complex compounds, and finally consciousness emerged from these living things (Jaynes, 1976). Thus a scaffolding of new conjunctions were thought to result in previously unseen relationships bringing new emergent phenomena. Coalescing as something genuinely new at a critical stage of evolution, consciousness assumed guidance over the course of events in the brain, and causal efficacy in bodily behavior. In some ways this view is like the "Indian rope trick" in which the Fakir tosses a rope into the air where it mysteriously stays, he then climbs up the rope, pulls it behind him and disappears. Evolutionary processes may have provided for the development and existence of consciousness which then assumed control and guidance of biological systems. The conditions leading to the appearance of consciousness may be viewed as a nonlinear emergence from evolutionary events.
</p>
<p>
The emergent evolution theory liberated biologists and neuroscientists from their burden of needing to base all of their results on known physical properties. The mind could thus be dealt with in a subjective sense, allowing psychiatry and Freudian theory to become acceptable without a concrete basis for concepts such as ego, id, and superego. Significant questions which then arose included: When did consciousness emerge? Where? In what species? And what was it? The brain/mind duality still existed and in fact the mind was dealt with only in broad and nebulous generalities.
</p>
</div>

</div>

<div id="outline-container-3-2-7" class="outline-4">
<h4 id="sec-3-2-7"><span class="section-number-4">3.2.7</span> Behaviorism</h4>
<div class="outline-text-4" id="text-3-2-7">

<p>The problem of consciousness could be solved by ignoring it. Behaviorists traced their roots to the so called epicurians of the 18th century and before that to attempts to generalize plant tropisms to the actions of animals and man. Behaviorists explained all cognitive processes on reflexes and conditioned responses which were comparable across wide varieties of organisms. Thus human behavior, no matter how noble or furtive, could be explained on reflex responses to given situations or needs to satisfy bodily functions. Behaviorism did lend itself to experimentation very readily and was a boon to the credibility of scientists studying the mind. Behaviorist laboratories flourished in universities throughout the world; rat mazes and conditioned responses became the operant paradigms. Behaviorists were able to attract university positions, grant money, and behaviorist laboratories dominated neuroscience for a significant period of time. The failing of behaviorism is that it is a method rather than a theory and is patently hypocritical in denying or ignoring consciousness. Behaviorism did, however, purge psychology to place it squarely in the mainstream of academic science.
</p></div>

</div>

<div id="outline-container-3-2-8" class="outline-4">
<h4 id="sec-3-2-8"><span class="section-number-4">3.2.8</span> Consciousness as Dynamic Activities of the Brain's Reticular Activating System   39</h4>
<div class="outline-text-4" id="text-3-2-8">

<p>As technology accelerated, brain and mind theorists eventually turned back to the brain-the three and a half pound lump of pinkish-gray "wonder tissue." Mathematician-philosopher Rene Descartes, who had defined the brain/mind duality by his statement "cogito, ergo sum," (I think, therefore I am) chose the brain's pineal gland as the site of consciousness. His choice was partly based on the fact that the pineal gland is a midline, single structure. Thus, unlike nearly all other brain regions it had no duplicate, and was therefore thought to be essential. Descartes' proposal was readily refuted by neurophysiologists but did start the search for a single site of brain consciousness. Since many researchers viewed the brain/mind as a hierarchical arrangement of information processing, the logical conclusion was that at a certain site or region all information was recognized and assimilated by the "Mind's Eye," the site of consciousness, the Grandfather neuron, or some manifestation of a hierarchical apex. Recently, most of the brain has been found to be involved with wide ("distributed") parallel files of information, memory, and cognition. Historically, however, many workers focused on the reticular activating system (RAS) as the neural substrate of consciousness.
</p>
<p>
Maintenance of consciousness depends to an important extent upon the
RAS, an organized tangle of tiny interconnecting neurons extending
from the top of the spinal cord up through the brain stem into the
thalamus and hypothalamus. The RAS integrates collaterals from sensory
and motor nerves, has direct lines to half a dozen major areas of the
cortex and probably all of the nuclei of the brainstem, and sends
fibers down the spinal cord where it influences the peripheral sensory
and motor systems. Its function is to sensitize or awaken selective
neurons and nervous centers and desensitize others such that it can
regulate the activity and wakefulness of the entire brain. Anesthetic
induction drugs such as sodium thiopental are thought to exert their
effects largely on the RAS. Destructive lesions of this area also
produce permanent sleep and coma, and stimulating the RAS electrically
can wake up a sleeping animal. It can also regulate the activity of
most other parts of the brain through its own internal electrical
excitability and neurochemistry.
</p>
<div id="Figure-2.2" class="figure">
<p><img src="UC-images/image016.jpg"  alt="UC-images/image016.jpg" /></p>
<p>Figure 2.2: A group of associated neurons such as brain cortical pyramidal cells. The long axons and dendrites extending from cell bodies are on the ,order of a few microns (thousand nanometers) thick. Some lateral synaptic connections are evident. By Jamie Bowman Hameroff.</p>
</div>

<p>
Although the RAS regulates wakefulness, the riddles of consciousness are unsolved. For example, high level integration and associative functions implicit to cognition occur predominantly in the cortex, structurally more evolved in advanced animals such as man. Conversely, the RAS is one of the oldest evolutionary parts of the nervous system and is relatively unchanged when compared among lower animals and humans. Jaynes observes that even if we had a complete wiring diagram, if we were aware of every transmitter in the nervous system, understood all of the billions or trillions of synapses, we could still not discern that a specific brain contained a consciousness like our own.
</p></div>

</div>

<div id="outline-container-3-2-9" class="outline-4">
<h4 id="sec-3-2-9"><span class="section-number-4">3.2.9</span> Neural Net Connectionism</h4>
<div class="outline-text-4" id="text-3-2-9">


<p>
This movement has been fortified by computer scientists' efforts to mimic the brain by constructing artificial intelligence systems. Based on approximation of cortical neurons as linear threshold units, a large number of "neural net" models have been constructed and simulated on computers. A key concept in relating neural network dynamics to the facts of psychology is the cell assembly introduced by Donald Hebb in 1949. In his view, cell assemblies are specially organized reverberatory circuits that constitute elements of thought. An individual neuron may participate in many of them just as an individual member of society participates in many social assemblies. By allowing strengthening or reinforcement of repeatedly used connections ("synaptic plasticity"), recognition, learning and problem solving become manifest in lowered thresholds of specific loops. By assigning energy levels to various patterns ("landscapes") within the net, mathematical solutions can also be imposed. The "intelligence" or capabilities of a given neural net model depends on the richness of its interconnections and nonlinear feedback. Neural net connectionist theory may help to advance robotic and computer systems for artificial intelligence, and may provide significant insight into brain function. These theories have provided evidence that dynamic activities within a given network can at least mimic some aspects of brain activities.
</p>
<p>
Shortcomings of early neural net models are that they have been based
on hypothetical neurons with huge assumptions about neural
function. Each neuron has been considered an on/off gate or switch,
and interneuron synapses viewed as variable weight
interconnections. More recent models incorporate axonal impulses,
synaptic delays, dendritic analog functions and spatial coherence. In
their most elegant form, neural net theories provide possible
representations of mental objects ("consciousness"?) in the transient
instantaneous patterns of network activity. "Temporally stable
cooperative coupling" among sets of neurons are suggested to manifest
thoughts and images by the work of Hebb, Kohonen, Edelman, Thom, von
der Malsburg, Hopfield, Pellionisz, Llinas, Changeux, and others. Some
of their work suggests the brain forms sets of "prerepresentations" of
what is expected from which sensory input induces "selection" of its
reality candidate. In this context, Changeux (1985) has defined
consciousness as "a kind of global regulatory system dealing with
mental objects and computation using those objects." Neural net models
and associative memories have significantly advanced understanding of
collective neural capabilities. Their essential features (parallel
processors with lateral variable connections) may also be operant
within neurons in the cytoskeleton.
</p>

<div id="Figure-2.3" class="figure">
<p><img src="UC-images/image017.jpg"  alt="UC-images/image017.jpg" /></p>
<p>Figure 2.3: Closer view of neurons with intraneuronal cytoskeleton visible. Dendrites, ascending from below into cell bodies, have numerous dendritic pines. Several synapses are depicted. By Jamie Bowman Hameroff.</p>
</div>

</div>

</div>

<div id="outline-container-3-2-10" class="outline-4">
<h4 id="sec-3-2-10"><span class="section-number-4">3.2.10</span> Holography</h4>
<div class="outline-text-4" id="text-3-2-10">

<p>Holograms may be formed from interference patterns generated from two or more coherent wave sources. Initially a laboratory curiosity, holography became important with the advent of lasers as coherent light sources in the early 1960's. A hologram recorded in a photographic plate appears to be mere garble until reilluminated with one of the original coherent wave sources and thereupon projects three dimensional spatial images. Two properties of holograms have attracted ' interest and comparisons with consciousness and mental imagery. One is that holograms have an enormous capacity for information storage, although coherent reference waves are necessary for recall. The second is that much information in a given hologram is contained in any one small portion of it, although with reduced resolution and signal to noise ratio. Recently, dynamic real-time holography has been developed with the use of photorefractive crystals (Gower, 1985).
</p>
<p>
Denis Gabor (1948), who received the 1969 Nobel prize for his invention of holography, remarked:
</p>
<p>
for some years now this property of holograms has attracted the interest of neurophysiologists who were puzzled by the difficulty in locating the 'engram' in the human or animal memory. As is now well known, especially since the famous experiments of Lashley, large parts of the brain can sometimes be destroyed without wiping out a learned pattern of behavior. This has led to speculation that the brain may contain a holographic mechanism.
</p>
<p>
Gabor was skeptical, however, about the "existence of waves or tuned resonators in the brain." The mantle of holographic brain theory was taken up by Stanford's Karl Pribram (1986) who has contended that the brain perceives sensory information by analysis of the interference of neural firing frequencies. What results within the brain, according to Pribram, is a holographic domain in which space and time are enfolded. Consequently transformations into ordinary domains can be achieved from any part of the encoded records. This is the property of distributedness of information which characterizes holograms and brain functions. Holographic brain models have been based on coherent wave interference at the level of neuronal activities, particularly dendritic-dendritic interactions. Verification of coherency among neurons has been lacking, and the neural level hologram remains merely an interesting mathematical model. However, the cytoskeleton within neurons (and all cells) may be well suited for holographic mechanisms due its spatial coherence (i.e. 8 nanometer periodicity) and potential temporal coupling (coherent nanosecond oscillations, see Chapter 6). Thus intracellula cytoplasm surrounding the cytoskeleton may be the substrate for holographic consciousness.
</p>
<p>
The holographic concept of consciousness has psycho-physical
implications (Weber, 1975). Physicist David Bohm has remarked that our
perceptions of reality are conditioned on lenses (eyes, cameras,
microscopes, etc.) which focus, objectify, form boundaries, and
particularize. Lensless holograms are distributed, lack boundaries and
are "holistic." Bohm suggests that the reality 'of the universe is
mathematically similar to a hologram (the "implicate" domain) which
deals with frequency domain, and fluctuating waveform properties as
opposed to our lens conditioned Euclidean-Newtonian impressions. This
approach seems consistent with modern physics views on wave/particle
duality and the uncertainty principle. Experiences reported by
mystics, schizophrenics and hallucinogenic drug experimenters describe
loss of spatial and temporal boundaries, and a holographic ("fractal")
characteristic of the whole being represented in every part. One may
argue whether mystical/schizoid/drug induced perceptions are
aberrations or clarified reality, but certain properties of holograms
(distributedness of information, vast storage capacity, three
dimensional spatial imagery) bear some resemblance to consciousness.
</p>
</div>

</div>

<div id="outline-container-3-2-11" class="outline-4">
<h4 id="sec-3-2-11"><span class="section-number-4">3.2.11</span> Cytoskeletal Basis of Consciousness</h4>
<div class="outline-text-4" id="text-3-2-11">



<div id="Figure-2.4" class="figure">
<p><img src="UC-images/image018.jpg"  alt="UC-images/image018.jpg" /></p>
<p>Figure 2.4: Interior of neuron showing cytoskeletal network. Straight cylinders are microtubules, 25 nanometers in diameter. Branching interconnections are microtrabecular lattice filaments. Neurofilaments are not shown. By Jamie Bowman Hameroff.</p>
</div>

<p>
Classical approaches to understanding the brain/mind have assumed a hierarchy of organization in which interneuronal synapses are the indivisible substrates of information transfer (Figure 2.2). However, neurons appear far too complex to be simple digital switches or gates and must contain intrinsic information processing systems.
</p>
<p>
The neuron is often and mistakenly described as a simple device that compares a weighted sum of dendritic "analog" input signals with some threshold level above which an output "digital" pulse is transmitted along an axon. The structure of neurons, in which vast arborizations of dendritic fibers may accept some 100,000 synaptic inputs per neuron, indicates a very complex system. While some have viewed the dendritic tree as being a passive transmitter of impulses, data suggest action potentials in large dendrites, slow depolarization waves in others, and the possibility of elementary logic operations at branching points (Scott, 1977). Each dendritic branch point may act as a logical "OR" gate if a pulse on either daughter branch can supply sufficient charge to excite a pulse on the parent; otherwise it may act as a logical "AND." Dendrites may also be transmitting presynaptic information to other neurons by graded potentials at dendrodendritic synapses, a process called "whispering together" (Adey, 1977). The extent and significance of "electrotonic" current pathways among dendritic membrane glycoproteins, membrane patches and dendritic spines are unknown but could also be important. The net summation of dendritic potentials in cerebral cortex is recorded at the scalp as electroencephalography (EEG). On the axonal or output side the parent fibers do not necessarily excite all daughters at each branching point, and branch points of some axons contain regions where high frequency filtering, alternate firing and other forms of information processing can occur (Scott, 1977). Branch point conductance may be influenced by small changes in local geometry and electrical coupling, thus providing intraneural regulation of neural transmission. Composition of membranes, spatial distribution of glycoproteins, ion channels, myelin gaps ("nodes of Ranvier") and clustering of receptors have also been viewed as information coding. All potential neural information processing modes (synaptic plasticity, axon and dendrite morphology, membrane protein distribution) depend on the dynamic cytoskeletal functions of axoplasmic transport and' trophism (Chapter 5).
</p>
<p>
The neuron's complexity may indeed be more like a computer than a single gate. But what are the gates? What is the indivisible substrate of neuronal function? Where is the neuron's neuron? How does an amoeba or paramecium perform complex tasks without benefit of a synapse, neuron, or brain? Relatively recently, with perfection of electron microscopic fixation, immunofluorescence and other techniques, the interior of living cells has been revealed. It has been shown to possess complex, highly parallel interconnected networks of cytoskeletal protein lattices which connect to and regulate membranes and all other cellular components. The structure of these protein polymers, their dynamic activities and the lack of a clear alternative understanding of cognition have led to theoretical consideration of dynamic cytoskeletal activities as functional information processing modes such as cellular automata and holograms.
</p>
<p>
This cytoskeletal view, developed in detail later in this book, is consistent with many of the earlier schools of understanding consciousness. From the cytoskeletal perspective, consciousness is a property of protoplasm (specifically related to cytoskeletal proteins) but the vertebrate variety of consciousness is a nonlinear collective effect-an emergent evolution-of that which exists in simple organisms. An early nonlinear jump in the evolution of consciousness may have occurred with the introduction of cytoskeletal centrioles and microtubules, and the concomitant transformation of prokaryotic cells to eukaryotic cells about one billion years ago (Chapter 3). Perhaps, as cytoskeletal networks and higher organizational levels such as neural networks reached sufficient complexity in the brains of mammals, collective properties emerged nonlinearly due to cooperativity, resonance, phase transitions, and coherent phenomena allowing for automata, holography, or some other mechanism of information processing. Neural network theory, parallelism, connectionism, and the AI approach to consciousness have provided enlightenment regarding the brain/mind. Many of these approaches may be applied to the cytoskeleton, a fractal subdimension of neural networks (Figures 2.3 and 2.4). Levels of neural network connections such as the reticular activating system or hippocampal circuits may depend on intracellular cytoskeletal dynamics for their regulation. For example, learning in neural net theories is based on Donald Hebb's (1949) suggestion that circuits of connected neurons develop more conductive synapses which facilitate activation of that circuit. Firing along given patterns following a specific stimulus is thought to represent a specific concept, thought, or memory-information. Learning is then thought to occur by reinforcement or strengthening of synaptic connections, or formation of new synapses along given neural net patterns. Synaptic strength and neuronal connection depend on intracellular cytoskeletal rearrangements and axoplasmic transport to maintain synaptic efficacy and to form new synapses and dendritic spines. Ingredients for synapses, membrane proteins, receptors, ion channels, enzymes, and apparatus for neurotransmitter releasing mechanisms are synthesized in cell bodies and transported to synapses along relatively great lengths by axoplasmic transport, a coordinated effort of cytoskeletal microtubules. Synaptic modulation may represent a mechanism by which separate dynamic layers in an information hierarchy communicate and "tune" each other.
</p>
<p>
A dozen models of cytoskeletal information processing have been
published and will be reviewed in Chapter 8. Nanoscale activities in
cytoskeletal lattices may offer a future bridge between consciousness
and emerging nanotechnology. As complex and highly connected as
neuronal branches are (i.e. dendritic trees the cytoskeleton within
all neurons may be a forest within those trees.
</p>
</div>
</div>
</div>

</div>

<div id="outline-container-4" class="outline-2">
<h2 id="sec-4"><span class="section-number-2">4</span> Origin and Evolution of Life</h2>
<div class="outline-text-2" id="text-4">



</div>

<div id="outline-container-4-1" class="outline-3">
<h3 id="sec-4-1"><span class="section-number-3">4.1</span> Soup vs Mud, Chicken vs Egg</h3>
<div class="outline-text-3" id="text-4-1">

<p>What is life? Living organisms have certain properties that are nearly synonymous with the trait of being alive-organization, growth, reproduction, dynamic purposeful activities and (at least in higher organisms) intelligence and consciousness. Life forms that we have come to know are all based on the same type of genetic blueprints (DNA, RNA) and building blocks (proteins), suggesting a common ancestry. That ancestry, life's emergence, is generally viewed as a rearrangement of cosmic matter originally produced in the "Big Bang" which is presumed to have given birth to the universe some 14 billion years ago. Life's molecular emergence can be viewed in the context of two basic questions concerning place of origin ("soup vs mud") and molecular cause and effect ("chicken vs egg").
</p>
<p>
In the 1920's Russian biochemist A. I. Oparin (1938) and British biologist J. B. S. Haldane (1947) described their concept of a "primordial soup" of organic molecules existing in the earth's oceans a mere 4 billion years ago. Their soup was thought to be a product of geochemical processes and energy sources acting in an atmosphere of unoxidized gases such as methane, ammonia and hydrogen, similar to what exists currently on Jupiter. This primordial atmosphere was the view of eminent chemist Harold Urey (1939), whose graduate student Stanley L. Miller carried out a key experiment in the early 1950's. Miller created a closed environment containing such a primitive atmosphere and passed electric sparks simulating lightning through it. He detected organic molecules relevant to living processes. Fifteen percent of the original methane carbon was found in molecules which included four amino acids, the building blocks of proteins. Miller also found precursors of DNA and ribose sugars from which RNA is formed. Because the most central molecules of life are identical in all organisms on earth, Miller's primordial soup has been considered to represent the conditions from which life emerged. Other research has questioned the hydrogen rich atmosphere upon which Urey and Miller based their experiment and still other work has shown that at least some organic precursors of life can be generated in many types of atmospheres.
</p>
<p>
There are other candidates for the site of life's origin. Conditions above the thermal vents recently discovered on the ocean floor are believed conducive to the formation of organic compounds, leading some to propose these spots, rather than the traditionally imagined ponds or tidal pools, as the cradle of life ("deep soup"). Thermal vents are home to strange and exotic life forms such as giant tube worms which thrive in the great pressures of the deep ocean. Organic compounds have also been found commonly in intrastellar dust, in comets, and in meteorites that fall to earth. Many believe the supply of organic precursors to life was augmented from space while few admit to believing that primitive cells were transplanted to earth from space.
</p>
<p>
An alternative explanation has been advanced by A. Graham Cairns-Smith (1982) of Glasgow University, who suggests that early organisms utilized pre-existing information templates in the form of wet clay crystals ("mud"). Crystalline inorganic materials appear to have many "life-like" properties such as the ability to store and replicate information in the form of crystal defects, dislocations, twin boundaries, and substitutions. Clay minerals like kaolinite crystallize at ordinary temperatures from aqueous solutions of common rock. Their catalytic surfaces and complex morphology suggested to Cairns-Smith an environment not unlike living material. He observed that defects in crystals could supply multiple, stable alternative configurations which can store and process information much like modern computers. Crystal defects which can move are very similar to primitive cellular automata, dynamic patterns occurring in lattice neighborhoods capable of computing. Cairns-Smith reasoned that certain clays proliferated with their replicating defects (representing information) acting as primordial genetic information and proving useful in alignment of amino acids and protein synthesis. As more efficient organic synthesis developed, Cairns-Smith argues that clay machinery became expendable and was jettisoned in favor of a new biotechnology-DNA and RNA.
</p>
<p>
Whether or not Cairns-Smith's clay theory is correct, he demonstrates the capacity for information storage in crystal defects. Perfectly ordered crystals which are repetitive and homogeneous have no capacity for information storage but are also extremely rare or do not exist at all. Real crystals have defect structures superimposed. Simply to be finite-to have a shape and size-is a defect, but many other features are almost invariably present. Units are often missing or are replaced by others, and sections of the crystal structure may be misaligned in various ways. While such features can be very small in scale, they provide real crystals with a large potential capacity for information. Certain classes of crystals might have defect structures that replicate as the crystal grows by having the right combination of structural characteristics, growth patterns and cleavage properties. Cairns-Smith (1982) concludes by posing a challenge to discover crystal genes of various materials. He asks:
</p>
<p>
&hellip; Imagine doing experiments with crystals that could evolve, setting them problems-applying selection pressures-and seeing how they cope. This would be an interesting thing to do any way whatever the crystals are made of. We would soon find out whether mineral versions of replicating systems are plausible although we might lose interest in our ultimate ancestors once we had in our hands the first organisms of another kind: the first organisms of our own contriving.
</p>
<p>
The implications of Cairns-Smith's ideas include the possibility of alternative life forms from propagating crystalline structures and a suggestion that DNA and RNA are not necessarily the only carriers of genetic information. This is in concert with a demystification of life in general. At an international meeting on the origins of life (Eckholm, 1986), Dr. Cyril Ponnamperuma of the University of Maryland suggested "the division between life and nonlife is perhaps an artificial one." He views the animate and inanimate as lying on a continuum both over evolutionary time and among currently existing systems. On such a scale prions, proteinoids, and some viruses would lie near the middle as might some ancient unknown protocell that became the ancestor of life on earth. To speak of advanced chemistry rather than divine creation is certain to disturb religious fundamentalists. Equating life with oscillations in crystals does have an almost biblical resonance, and narrows the conceptual gap between life molecules and technological devices.
</p>
<p>
Regardless of the precise environment in which life-related molecules emerged, other major questions include whether the carriers of genetic information, DNA and RNA, preceded proteins whose amino acid sequences they determine, or whether proteins, including enzymes and structural elements seemingly necessary for genetic replication, came first. Thus a chicken (DNA, RNA) vs egg (protein) conundrum regarding life's origins has developed. A primary information flow from nucleic acid to protein (chicken before egg) was a "central dogma" in molecular biology. Fox and Dose (1972) challenged this conviction by proposing an alternative evolutionary continuum from the beginning of the material cosmos to the first organisms. In their "egg before chicken" view the sequence of life's organization was from interstellar gases, to amino acids, to polymers, to organized microsystems. As evidence they cite the self organization of amino acids and proteins into "proteinoid" microspheres which can establish communication links and perform other "life-like" functions. Evidence for a "chicken before egg" view has been found by chemist Leslie Orgel and colleagues (Schwarz and Orgel,1985) of the Salk Institute in La Jolla, California. They recently discovered a 15 nucleotide long DNA-like molecule that had formed spontaneously from much simpler carbon compounds and zinc in the absence of living cells or protein enzymes. Other work has suggested that RNA can function enzymatically to facilitate reactions and the bulk of recent findings leans towards the primacy of nucleic acids.
</p>
<p>
Manfred Eigen (1971) views this cause/effect problem as a "closed loop" whose original starting point is unimportant. What is important, in Eigen's view, is how molecular self-organization occurs from random events and feedback which lead to macroscopic functional organization, self-reproduction, selection, and evolution: "hypercyles." Eventually, according to Eigen, such systems can escape the prerequisites of their origin and change the environment to their own advantage.
</p>
<p>
A view of primary nucleic acid (chicken) organization in a primordial aqueous environment (soup) is summarized and elaborated in the writings of biologist Lynn Margulis and Dorion Sagan (1986). They view as logical the facts that RNA and DNA spontaneously formed in the shallow seas of early earth and also became able to self replicate perfect copies of themselves. They liken RNA molecules to half of an open zipper. With the proper complementary ingredients, the missing half forms by using the existing RNA as a template.
</p>
<p>
Margulis and Sagan (1986) note:
</p>
<p>
An RNA molecule can do more than copy itself. The sequence of its nucleotides can also serve as a signal for a neighboring strand of RNA to attach the amino acids in its environment, thus forming a portion of a protein which will in turn accelerate the matching of other RNA molecules producing more RNA, more protein like fragments, and so on.
</p>
<p>
This suggests that at a critical level of evolution, nonlinear accelerations occurred due to the level of associative inter-relationships among evolving molecules. This can help explain how biological systems can produce "order from chaos," and thus apparently violate the second law of thermodynamics which states that ordered systems must dissipate towards disorder.
</p>
<p>
Margulis and Sagan describe the following scenario for the development of life on earth. RNA formation in the primordial soup led to the evolution of double stranded DNA eons later. This in turn allowed the full variety of life-as manifest in the richness of structures and functions of proteins and other macromolecules. Survivability was enhanced by enclosure of dynamic molecules inside membranes, apparently formed when phospholipid hydrocarbons aligned and, because they were charged on one end, formed spherical droplets which sequestered biomolecules. With the advent of ion channels and other membrane proteins came regulatory voltages and a discrete microcosm: the "prokaryotic" bacterial cell.
</p></div>

</div>

<div id="outline-container-4-2" class="outline-3">
<h3 id="sec-4-2"><span class="section-number-3">4.2</span> Prokaryote to Eukaryote-Symbiotic Jump</h3>
<div class="outline-text-3" id="text-4-2">


<p>
Proliferation of prokaryotes literally changed the face of the earth. According to the Margulis/Sagan scenario, collective teams of bacteria gathered nutrients, disposed of toxins, recycled organic matter by turning waste into food and stabilized the atmosphere. Prokaryotic bacteria produced ammonia which adjusted the acidity of oceans and lagoons and increased the earth's temperature through a "greenhouse" effect similar to that of carbon dioxide (which lets in more solar radiation than can escape). About two billion years ago purple and green photosynthetic bacteria began using water to manufacture hydrogen rich compounds, giving off oxygen which was poisonous to most ("anaerobic") prokaryotes. This "toxic waste crisis" pressured adaptations including motility systems to escape oxygen exposure, detoxification, and eventually oxygen breathing. The resultant early "aerobic" prokaryotic bacteria flourished for a few hundred million years, but as atmospheric oxygen increased, aerobic and anaerobic bacteria begat a new improved form of life, the eukaryotic or nucleated cell.
</p>
<p>
We are all eukaryotes, as are all animals and nearly all plants existing on earth today. Eukaryotic cells differ from their prokaryotic ancestors by having organized cell interiors (cytoplasm or protoplasm) including separate membrane enclosed compartments (nuclei) which contain, among other structures, chromosomes: DNA libraries and their supportive proteins. Eukaryotic cytoplasm usually contains mitochondria, chemical energy factories which utilize oxygen to generate ATP to fuel cellular activities (respiration) and, within green plants, chloroplasts which convert solar energy to chemical energy foodstuffs (photosynthesis).
</p>
<p>
Eukaryotic cells are enormously sophisticated compared to their prokaryotic predecessors. Fossil records indicate that eukaryotes appeared abruptly, with no apparent intermediate form which would indicate progressive genetic mutation from prokaryotes. This evolutionary gap, which separates bacteria and blue-green algae from all other present day cellular life forms, is a mysterious dichotomy, an evolutionary chasm. Explanations based on symbiosis-a mutually beneficial association-were advanced by Marishkowski in 1905 and Wallen in 1922 (Margulis and Sagan, 1986). They proposed that eukaryotic cells resulted from a symbiotic association of two types of prokaryotes-a primitive "monera" and a more advanced cocci-type bacteria. Ingestion of the cocci by the monera is thought to have led to a stable symbiosis in which the more evolved cocci became the nuclear material and the monera became the cytoplasm. Marishkowski proposed other examples of symbiosis such as the emergence of green plants from a union of colorless nucleated cells and minute cyanophycae which became chloroplasts specialized for photosynthesis. This proposed union is similar to the symbiosis of green algae and fungi to form lichen, and of chloroplasts in metazoa such as hydra. Wallen proposed that mitochondria originated as symbiotic bacteria which entered, and became indispensably entrenched within, animal cells.
</p>
<p>
A more complete "endosymbiotic" theory of eukaryote origin was introduced by biologist Lynn Sagan (later Lynn Margulis) in 1967. She suggested that prokaryotic cells (specifically anaerobic heterotrophic bacteria) underwent a series of three symbiotic events leading to the first eukaryotes. During the period of adaptation to oxygen breathing an aerobic heterotroph was engulfed by an anaerobic heterotroph. The aerobic bacteria became the ancestor of the mitochondria, converting oxygen to ATP and remained as an intracellular organelle. The next symbiotic event, according to Sagan-Margulis, was the ingestion of a spirochete-a motile organism which traveled by whip-like beating of its tail-like flagellum composed of cytoskeletal proteins. Ingestion of flagellae and their intracellular anchors, basal bodies, are thought to have led to cilia, centrioles, and microtubules-cytoskeletal structural and organizational elements which brought the capabilities for cell movement, cytoplasmic organization, and (apparently) information processing (Figure 3.1). Multiple cilia attached to cell membranes and extending outward enabled single cell organisms such as paramecium to swim about in their aqueous medium, greatly expanding their ability to find food, avoid predators, and increase their horizons. In other stationary organisms cilia could flow the environmental medium past the organism, achieving the same results. Within the cytoplasm, cytoskeletal structures such as centrioles, basal bodies and microtubules organized, oriented, and transported organelles and materials. The eukaryotic cytoskeleton took on functions akin to mechanical scaffolding, conveyor lattice, and the cell's own nervous system.
</p>
<p>
Basal bodies, cilia, flagella, and centrioles are assemblies of microtubules, themselves complex cylindrical assemblies of protein subunits, and are ubiquitous throughout eukaryotic biology. In these organelles, nine pairs or triplets of microtubules are arranged in a super-cylinder, which may have an additional microtubule pair in its center (9+2 or 9+0 arrangements, Figure 3.2). Involvement of these structures in nearly all instances of dynamic cell activities (mitosis, growth and differentiation, locomotion, food ingestion or phagocytosis, cytoplasmic movement etc.) greatly accelerated the capabilities of eukaryotic cells. Utilizing the chemical energy from mitochondrial ATP, these cytoskeletal elements appear to have provided not only stable structure and motility, but also a sophisticated "computer-like" information processing system.
</p>
<p>
Eukaryotic microbial technology was as different from the basic bacterium as a main frame computer to an abacus. The eukaryotes flourished, evolved and solved environmental problems by mixing and merging. Forming new collectives, they eventually found their way from water to land and air and branched into the myriad forms of plant and animal life that have since populated the biosphere. The human brain and nervous system are recent innovations; Homo sapiens apparently appeared about 50 thousand years ago.
</p>
<p>
The endosymbiotic theory can explain the nonlinear jump in evolution that occurred with the advent of eukaryotes, but does have its detractors. For example, Hyman Hartman (1975) of MIT has noted that, while mitochondria and chloroplasts are agreed to have originated as free living prokaryotic cells, there is some question as to the pedigree of basal bodies and centrioles. Sagan-Margulis (1967) had claimed that:
</p>
<p>
upon entry into a host, such a symbiot may lose from none to all of its synthetic capabilities except the ability to replicate its own DNA and synthesize complementary RNA from that DNA-the sine qua non of any organism.
</p>

<div id="Figure-3.1" class="figure">
<p><img src="UC-images/image019.jpg"  alt="UC-images/image019.jpg" /></p>
<p>Figure 3.1: Symbiotic ingestion of motile spirochetes by a primitive bacteria, resulting in the first "eukaryotic" cells. The spirochete's filamentous proteins became, according to Sagan-Margulis (1967), the centrioles and cytoskeleton providing movement and organization of cytoplasm. By Paul Jablonka</p>
</div>

<p>
This implies that symbiotic organelles which originated as separate organisms must retain their nucleotide synthesis capabilities. Mitochondria and chloroplasts have been shown to have their own DNA, however DNA has not been isolated with centrioles or basal bodies. These cytoskeletal organelles in fact, routinely self replicate without DNA, although Hartman has shown that RNA may exist in association with basal bodies. Perhaps centriolar DNA became lost in the evolutionary shuffle, or the cytoskeleton possesses other mechanisms of information transfer. Evidence of cytoplasmic information being transmitted over hundreds of generations of paramecium without genetic involvement (Aufderheide, Frankel and Williams, 1977) suggests that centrioles and other cytoskeletal elements may have a degree of independence (Figure 5.27). Real time information processing is in the cytoskeletal province, so DNA replication may not be the "sine qua non" of living organisms. Dynamic, collective activities of centrioles, microtubules, and other cytoskeletal proteins may manifest biological intelligence and be closer to life's essence than are genetic mechanisms. Ambiguous life forms may be particularly important in the future.
</p></div>

</div>

<div id="outline-container-4-3" class="outline-3">
<h3 id="sec-4-3"><span class="section-number-3">4.3</span> Centrioles-Evolution's Hijackers</h3>
<div class="outline-text-3" id="text-4-3">

<p>Appearance of centrioles and related cytoskeletal structures as motile intelligent organizers on the evolutionary scene one billion years ago may have been the key to success for eukaryotes, and initiation of the lineage that has led to human consciousness.
</p>
<p>
Centrioles are the specific apparatus within living cells which trigger and guide major reorganizations of cellular structure occurring during mitosis, growth and differentiation. Centrioles are composed of two similar cylinders (each of which is also referred to as a "centriole") whose diameters are 0.2 microns (200 nanometers). Each cylinder possesses a nine fold radial symmetry and consists of microtubule triplets longitudinally fused. A cartwheel filamentous structure (or "pinwheel") appears to hold together the end of each centriole cylinder. One centriole begets another by replication which occurs at right angles to the long axis of the cylinders. This perpendicular replication which initiates mitosis is counter-intuitive compared to longitudinal replication or fission, and remains one of the mysteries surrounding centrioles.
</p>

<div id="Figure-3.2" class="figure">
<p><img src="UC-images/image020.jpg"  alt="UC-images/image020.jpg" /></p>
<p>Figure 3.2: Centrioles are cylinders of 9 triplets of microtubules, shown here in cross-section. Pairs of centrioles associate at right angles to each other, shown here at bottom. By Paul Jablonka.</p>
</div>

<p>
Centrioles reside within a portion of the cytoplasm known as the
centrosome (or centrosphere) adjacent to the cell nucleus outer
membrane. By triggering and guiding polymerization of microtubules and
other cytoskeletal elements, centrioles temporally and spatially
organize cytoplasm ("microtubule organizing center"-MTOC, Figure 3.3
and Chapter 5). For example centrioles and microtubules (mitotic
spindles) separate chromosomes and establish daughter cell
architecture (Figure 3.4)-features which had enormous advantages in
accelerating eukaryotic evolution.
</p>


<div id="Figure-3.3" class="figure">
<p><img src="UC-images/image021.jpg"  alt="UC-images/image021.jpg" /></p>
<p>Figure 3.3: Spindle pole centrioles in PtK2 kidney mitotic cell. Perpendicular centrioles are seen in the dense pericentriolar material from which MT radiate, dotted by immunogold. A filamentous network is seen to the right of, and above, the microtubule organizing center (MTOC). Scale: 3.3 millimeters on micrograph = 100 nanometers. With permission from Geuens, Gundersen, Nuydens, Cornelissen, Bulinski and DeBrabander (1986), courtesy of Marc DeBrabander and Janssen Pharmaceutica Research Laboratories</p>
</div>

<p>
Centriole-like basal bodies, acting near cell membranes, induce formation of cilia as appendages which protrude from outer surfaces of cells. Cilia have structures virtually identical to centrioles except being membrane covered and, in the case of motor cilia, having a central microtubule pair and contractile interconnections which act to bend and wave cilia in a variety of control functions. These range from propulsion of single celled paramecium to expulsion of dust and particles from human airways. Similarly, sensory cilia permit communications with external environments across a wide biological range from single cell organisms to the inner ears of human beings, transducing mechanical sound into the nervous system. Generations of motile and sensory cilia allowed eukaryotic cells like paramecium to roam about vaster quantities of their aqueous environment, serving to maximize their food supply as well as perceive sensory information from their environment. This resulted in complex activities involving logic and information processing which led 19th century scientists to ascribe rudimentary consciousness to such organisms.
</p>
<p>
Another mystery surrounding centrioles is their command of orientation in space and ability to convey that information to other cytoskeletal structures. Navigation and gravity sensation have been suggested to represent a "gyroscopic" function of centrioles (Bornens, 1976) which have also been described as perfectly designed signal detectors (Albrecht-Buehler, 1981). These and other models of information processing and intelligence in centrioles and the cytoskeleton will be covered in Chapter 8.
</p>
<p>
Relevant to evolution is that centrioles provided eukaryotes with a sophisticated cellular information processing and communication system. The consequences of such a system on biology is perhaps analogous to the potential impact of computers on societies. The mystery and aesthetic elegance of centrioles, as well as the fact that in certain instances they appear superfluous, have created an enigmatic aura about this marvelous organelle. In the forward to Wheatley's (1982) book Centrioles: The Central Enigma in Cell Biology, biochemist B. R. Brinkley states:
</p>
<p>
Before Gallileo's telescope challenged their views, early scholars argued that the earth was the center of the universe around which revolved the sun. Following their discovery by light microscopists, centrioles were given an equally permanent role in the cytoplasm of eukaryotic cells. This minute organelle was thought to be the center of the cytoplasmic universe &hellip; .
</p>
<p>
Centrioles' structural beauty, unfathomable geometry, intricate behavior, navigational command, and apparent origin as invader from the prokaryotic kingdom add to their mystique. Writing in Wheatley's book, Patelca states: "biologists have long been haunted by the possibility that the primary significance of centrioles has escaped them."
</p>
<p>
A possible conclusion is that centrioles are intelligent nano-engines
who "jumped ship" from a previous species to symbiotically upscale
their lifestyle. By so doing, they have coopted biology and, in
concert with other dynamic cytoskeletal structures, pushed
intelligence to its current stage of evolution. The next symbiotic
event may have equally profound implications. Nanoscale technologies
may directly interact with biomolecular intelligence.
</p>

<div id="Figure-3.4" class="figure">
<p><img src="UC-images/image022.jpg"  alt="UC-images/image022.jpg" /></p>
<p>Figure 3.4: Centrioles in cell division. 1) Cross-section of centriole microtubule triplet. 2) Cross section of a centriole with 9 microtubule triplets, 9 satellite bodies, and central "pinwheel" structure. 3) Centriole pairs near cell nucleus, prior to cell division. 4) Centriole pairs have separated and migrated; chromosomes ready for separation. 5) Mitotic spindles, composed of microtubules, have formed from centriole centers (MTOCs) with chromosomes in middle. 6) Centriole anchored microtubules separating a pair of duplicate chromosomes. By Paul Jablonka.</p>
</div>

</div>

</div>

<div id="outline-container-4-4" class="outline-3">
<h3 id="sec-4-4"><span class="section-number-3">4.4</span> Biotech Evolution-The Next Symbiosis</h3>
<div class="outline-text-3" id="text-4-4">


<p>
There are several indications that the evolution of technology will force another nonlinear acceleration in biological evolution which has dealt with crises such as toxic oxygen two billion years ago, utilized new energy sources, inhabited new environments, developed new forms, and spawned technologies which themselves have evolved. Many observers have been alarmed by technological evolution. Nineteenth century scientist/satirist Samuel Butler (Margulis and Sagan, 1986) considered the possibility of machines suppressing humans and assuming supremacy of earth:
</p>
<p>
man will become to the machine what the horse and the dog are to man-he may continue to exist, even improve, and will probar bly be better off in a state of domestication under the beneficent rule of the machines than he is in his present wild state. After all we treat our horses, dogs, cattle, and sheep on the whole with great kindness. We give whatever experience teaches us to be best for them. In like manner it is reasonable to suppose that machines will treat us kindly for their existence is as dependent upon ours as ours is upon lower animals.
</p>
<p>
Of course we eat some animals, and experiment upon others. It seems every new technology is a double-edged sword with capacity for good or evil-the basic "Frankenstein" scenario. But reliance on new technology is probably necessary and inevitable for adaptation and survival in an ever crowding and progressively toxic world. Margulis and Sagan (1986) cite general systems theorist John Platt who is a student of evolutionary acceleration and believes that life on earth may be nearing an enormously important turning point. The global computing and communication that has emerged following World War Two has become, according to Platt: "a collective social nervous system for managing millions of our problems, and its importance for the long range future may be as great as that of the first learning nervous system."
</p>
<p>
New technologies may help biology to deal directly with current and future crises. In their book, Microcosmos: 4 Billion Years of Evolution from our Microbial Ancestors, Margulis and Sagan (1986) describe some surprising possibilities. They feel that current man is little more than communities of bacteria, modular manifestations of the nucleated cell, and that new "artificial" life forms will emerge from symbiotic fusion of biology and technology. They see this happening along three lines: genetic biotechnology, computer robotics, and biochips:
</p>
<p>
&hellip; one day soon entire suits of genes, proteins and hormones may be dovetailed in the laboratory to create new species of microbes. As we gain a greater understanding of embryology and immunology we will surely clone cells into progressively larger and more complex organisms sure to intervene in our own evolution.
</p>
<p>
As computer robotics evolve smallward to become nanotechnology, collective interactions with genetic biotechnology and natural biochips could precipitate the next evolutionary phase transition: mind/tech symbiosis.
</p>
<p>
Margulis and Sagan (1986):
</p>
<p>
Robotics and bacterium [may become] &hellip; ultimately united in biochips based not on silicon, but on complex organic compounds. &hellip; Manufactured molecules would exchange energy with their surroundings &hellip; to turn it into information [and] open doors to 'cybersymbiosis,' the comingling of human and manufactured parts in new life forms and ultimately enable us to remake our species. &hellip; Homo sapiens might survive only as a rudimentary organ, a delicately dissected nervous system attached to electronically driven plastic arms.
</p>
<p>
Hans Moravec (1986) of Carnegie-Mellon University's Robotics Laboratory and author of Mind Children has his own vision of mind/tech symbiosis in which ultra-precise robotic brain surgeons transfer the software of human consciousness to a supercomputer. He describes advantages of existing in silicon or gallium arsenide with robotic bodies. These include being impervious to harsh environments, electronic transportation across galaxies and immunity to disease. Max Headroom is a hypothetical television personality whose consciousness exists solely within computers and electronic equipment. The mind content of a head injured motocyclist ("Max. Headroom 2.3m" was his last image before the crash) is somehow transferred, collected, and actively existing in electronic circuitry. Somewhat of a video cult figure, Max Headroom may be the first of a breed of technocognitive entities.
</p>
<p>
Comingling of mind and technology would be a neat trick, fraught with potential benefits and dangers! Certainly it would depend on an understanding of the mechanism of consciousness which is not currently available. Perhaps imminently available nanosensors will be able to interact dynamically at the level of cytoskeletal protein lattices within all living cells. This interaction may lead to the next symbiosis, one which will have as profound effects on biology as did the conversion from prokaryote to eukaryote. If nanotechnology and biology become symbiotic, consciousness can be a commodity.
</p></div>
</div>

</div>

<div id="outline-container-5" class="outline-2">
<h2 id="sec-5"><span class="section-number-2">5</span> From Brain to Cytoskeleton</h2>
<div class="outline-text-2" id="text-5">



</div>

<div id="outline-container-5-1" class="outline-3">
<h3 id="sec-5-1"><span class="section-number-3">5.1</span> Nervous System Evolution</h3>
<div class="outline-text-3" id="text-5-1">


<p>
The German philosopher Nietzsche wrote:
</p>
<p>
"Then you must be a scientist whose field is the leech" said Zarathustra, "and you must pursue the leech to its last rock bottom, you conscientious man!" "Oh Zarathustra!" answered the man, "that would be an enormity, how could I take up such a huge task? What I am the master and connoisseur of is the brain of the leech: that is my field and it is a whole universe."
</p>
<p>
The human brain appears to have evolved from predecessors of earthworms and leeches whose development was a milestone in eukaryotic evolution (Somjen, 1983). These organisms' nervous systems probably consisted of a chain of organized clumps of nerve cells called ganglia, or perhaps two chains of symmetrically paired ganglia with an enlarged head ganglion at the front end. The polarity and preferred axis of orientation which defined these basic nervous systems are related to polarity and asymmetry within their component nerve cells, or neurons, each a "universe" of its own. As will be described in the next chapters, neuronal orientation and asymmetry are determined by the cytoskeleton which, in many ways, is the nervous system within all higher plant and animal cells.
</p>
<p>
Over the course of evolution the primitive leech's head ganglion began to dominate other members of its chain, performing "decisions" which required cooperation of the entire assembly. Each segmental ganglion still retained some autonomy of action and, when cut into pieces, such a creature may have been able to regenerate complete new individual organisms like its current descendants. Pairs of leech ganglion chains resemble sympathetic ganglion chains of vertebrates which retain a measure of autonomy. For example, man's autonomic nervous system can efficiently regulate heart, intestine, blood vessels and other organ systems even when disconnected from the brain and spinal cord.
</p>
<p>
Transition from a segmented organism to a nervous system like our own
probably occurred due to fusion of the paired chains of ganglia into a
tubelike structure of nervous tissue. Paired nerve roots then emerged
from the primitive central system similar to the spinal roots of
today's vertebrates. These roots connected the central nervous system
with the peripheral sensory organs, muscles and glands. Eventually,
the head end of the neural tube increased in size and importance until
it dominated most nervous system functions, a process termed
"encephalization" by famed English neurologist Hughlings Jackson
(Somjen, 1983). Encephalization, which occurred over eons and may be
continuing presently within man, reflects development of a
hierarchical organization in an otherwise parallel, distributed
system. Brain components which are more highly organized and capable
of more complex functions are generally newer on the evolutionary
scale (i.e. "neocortex"). A collective hierarchy of parallel
information processing systems based on functional organization which
includes subcellular elements (cytoskeleton and cytoplasmic ground
substance) is shown in Table 4.1.
</p>
</div>

</div>

<div id="outline-container-5-2" class="outline-3">
<h3 id="sec-5-2"><span class="section-number-3">5.2</span> Nervous System Organization</h3>
<div class="outline-text-3" id="text-5-2">


<p>
Brain activities have been intensively studied by various disciplines for many years. In the following sections, essential elements of brain organization are presented. The purpose is to provide sufficiently comprehensive background in order to justify the contention that the cytoskeleton is an underlying medium of information processing within brain neurons.
</p>

</div>

<div id="outline-container-5-2-1" class="outline-4">
<h4 id="sec-5-2-1"><span class="section-number-4">5.2.1</span> Architecture</h4>
<div class="outline-text-4" id="text-5-2-1">


<p>
The central nervous system (CNS) of vertebrates including man is
organized in an ascending hierarchy of parallel structures-spinal
cord, brain stem, and brain. The peripheral nervous system consists of
peripheral nerves and the ganglia of the autonomic nervous
system. Human brains contain about a hundred billion
neurons. Evolution has caused a "cephalic" shift of importance,
relative size, and control towards the higher centers or neocortex,
which in man is larger and more complex than in other mammals. There
are generalized similarities in structure, composition and functioning
of central nervous systems in all vertebrates. Neurons within all
nervous systems are themselves organized by their component
cytoskeletons.
</p>



<table border="1" >
<caption> Table 4.1 Collective hierarchy of parallel information processing systems.</caption>
<tr><th>
Brain/Mind                                                                                </th><tr>
<tr><td><center> consciousness, “self,” “Mind’s Eye,” attention </center>
</td></tr>
<tr><th> Systems, Homunculi, “Centers”
</th></tr>
<tr><td><center> functionally related neurons, anatomical regions, assemblies
of networks, reverberation</center>
</td></tr>
<tr><th>Neural Synaptic Networks, Cartels, Modules
</th></tr>
<tr><td> <center> cooperativity due to dense interconnectedness,
parallelism,associative memory, learning, synaptic plasticity </center>
</td></tr>
<tr><th>Neuron
</th></tr>
<tr><td><center> multiple synaptic inputs and outputs, dendritic processing,
synaptic plasticity, axoplasmic transport </center>
</td></tr>
<tr><th>Cytoskeleton
</th></tr>
<tr><td><center> centrioles, microtubules, filaments, synaptic morphology,
spatiotemporal cellular organization, cellular automata, coherent
oscillations </center>
</td></tr>
<tr><th> Cytoplasmic Ground Substance (“Infoplasm”)
</th></tr>
<tr><td><center>sol-gel states, geodesic actin, tensegrity structures, ordered
water, dissipative patterns, holographic interference</center>
</td></tr>
</table>
<p>
Two types of cells make up nervous tissue: neurons and satellite cells. In the central nervous system, the satellite cells are called neuroglia and in the periphery, Schwann cells. These satellite cells wrap layers and layers of myelin sheeting around neurons forming what is generally considered to be merely insulation which increases the velocity of propagating signals.
</p>
<p>
The parts of a neuron are the dendrites, the cell body (or perikaryon) and the axon which is also referred to as the nerve "fiber." Dendrites and the cell body generally receive incoming signals and the cell body transforms these into an outgoing signal carried by the axon (Figure 4.1). The "white matter" of the central nervous system consists of fiber tracts and their myelinating glial cells while the "gray matter" refers to clumps of cell bodies and dendrites known as "nuclei." A schematic diagram of brain functional organization is shown in Figure 4.2.
</p>
</div>

</div>

<div id="outline-container-5-2-2" class="outline-4">
<h4 id="sec-5-2-2"><span class="section-number-4">5.2.2</span> Neuronal Signaling</h4>
<div class="outline-text-4" id="text-5-2-2">

<p>Signals which transmit information among nerve cells consist of electrical potential changes produced by ionic currents flowing across their surface membranes. The currents are carried by ions such as sodium, potassium, calcium, and chloride and occur due to the opening and closing of membrane protein ion channels. The nerve maintains an electrical polarization across its membrane by actively pumping sodium ions out, and potassium ions in. Thus when the ion channels are opened (by voltage change, neurotransmitters, drugs, etc.) sodium and potassium rapidly flow through the channel creating a depolarization. Depending on the spatial location and temporal sequence of channels, activation can result in waves used as signals.
</p>
<p>
Neurons carry only two obvious types of signals: localized "gated" potentials which are older on the evolutionary scale and analog, and propagating "all or none" action potentials which are newer and digital. Localized gated potentials can spread only one to two millimeters, are attenuated and distorted by local resistivity, and are essential where spatial and temporal summation ("integration") is required. This occurs at sensory nerve endings ("receptor potentials"), neuronal synaptic junctions where both excitatory and inhibitory potentials are integrated ("synaptic potentials"), and as slow waves arising as rhythmic depolarizations in dendrites. Gated potentials in dendrites are also integrated at the cell body to initiate (when appropriate) propagating action potentials along axons. A primary role for localized dendritic potentials in cerebral neuron information processing has been emphasized by several authors including Alwyn Scott (1977) and Ross Adey (1966) who feel dendritic slow wave potentials allow cerebral neurons to "whisper together."
</p>
<p>
Action potentials ("nerve impulses") propagate as membrane depolarization waves along axons. They occur due to sequential opening of membrane channels which allow passive diffusion of ions. Gaps in myelinization ("nodes of Ranvier") along axons contain abundant ion channels so that impulses propagate rapidly between nodes where they are slowed and susceptible to modulation ("saltatory conduction"). With this exception, action potentials occur on an "all or none" basis (i.e. digital) from integration of dendritic input (i.e. analog) at the cell body region of the neuron. The frequency of firing is related to the stimulus intensity; a sensory nerve responding to muscle stretch fires at a rate proportional to the degree of stretch. Action potential velocity is fixed for given axons dependent on axon diameter, degree of myelinization, and distribution of ion channels. Typical action potential velocities of about 100 meters per second allow effective communication within relatively large nervous systems.
</p>
</div>

</div>

<div id="outline-container-5-2-3" class="outline-4">
<h4 id="sec-5-2-3"><span class="section-number-4">5.2.3</span> Interneuronal Synapses</h4>
<div class="outline-text-4" id="text-5-2-3">

<p>Action potentials and axons terminate at synaptic connections with other neurons or effector cells such as muscle or gland. Final branch portions of axons are thin with swollen synaptic terminals known as boutons. Some axons may have multiple boutons, each one forming a synapse. Generally, synapses form between the axon terminal and another neuron's dendrite, although axon-cell body, axon-axon, and dendrite-dendrite synapses also occur. Many, even most, dendritic synapses occur on dendritic "spines"knobby dendritic protuberances.
</p>
<p>
Two modes of synaptic signaling have been recognized: electrical and chemical. At electrical synapses, currents generated by an impulse of the presynaptic nerve terminal spread directly to the next neuron through a low resistance pathway (which may be networks of extracellular protein filaments known as "synapsin"). The sites for electrical communication between cells have been identified in electron micrographs as gap junctions in which the usual intercellular space of several tens of nanometers is reduced to about two nanometers. There appear to be a huge number of electrical synapses in mammalian brain (estimated to be as high as 80 percent of all synapses), but because of difficulties in isolation, characterization, and inability to study them by pharmacological manipulation, their significance remains unknown. Chemical synapses have been extensively studied.
</p>
<p>
At chemical synapses the fluid gap between presynaptic and
postsynaptic membranes prevents a direct spread of current and the
lack of an electrical connection between neurons. The synaptic bouton
contains large quantities of spherical vesicles (about 50 nanometers
diameter) which contain neurotransmitter molecules. Acetylcholine,
norepinephrine, serotonin, dopamine, gamma amino butyric acid (GABA)
and various peptides and amines have been identified as
neurotransmitters. Some are excitatory while others (i.e. GABA) are
inhibitory.
</p>

<div id="Figure-4.1" class="figure">
<p><img src="UC-images/image023.jpg"  alt="UC-images/image023.jpg" /></p>
<p>Figure 4.1: Neuronal organization: 1) Branching dendrites (top) entering cell body or perikaryon; branching axons exiting at bottom. 2) Axons forming synapses on dendrites and cell body. 3) Axon surrounded by 100 layers of myelin which increases conduction velocity; structures visible in axon include mitochondria, neurotransmitter vesicles, and microtubules. 4) Synaptic cleft; neurotransmitter vesicles (top right) fuse with membrane as they are released. By Paul Jablonka.</p>
</div>



<div id="Figure-4.2" class="figure">
<p><img src="UC-images/image024.jpg"  alt="UC-images/image024.jpg" /></p>
<p>Figure 4.2: Schematic diagram of brain functional components. By Paul Jablonka.</p>
</div>

<p>
The sequence of events liberating neurotransmitter molecules from nerve endings is remarkably uniform at all synapses. Transmitter molecules are stored inside presynaptic nerve terminals in small vesicles that are analogous to the secretory granules of gland cells. The amount of neurotransmitter in one vesicle is considered a "quantum" and in neuromuscular synapses each quantum consists of one thousand to five thousand molecules of acetylcholine. Each action potential reaching the presynaptic terminal releases a number of vesicle quanta ranging from a few to several hundred. The coupling mechanism between the action potential and vesicle release involves both calcium and the cytoskeleton. As an action potential impulse arrives at the presynaptic nerve terminal, calcium ions enter the cytoplasm through the membrane by way of voltage gated channels. In presynaptic nerve terminals, inward ionic current of the action potential is thus carried partially by sodium and partially by calcium. Free calcium in the cytoplasm of the terminal causes vesicles to fuse with the surface membrane and to expel their contents. The mechanisms by which calcium triggers the release of vesicles from the presynaptic terminal is not clearly understood, however cytoskeletal proteins including contractile actin, myosin, and other filamentous proteins are involved. Calcium mediates dynamic contractile activities in flagella and skeletal muscle and appears to trigger cytoskeletal expulsion of neurotransmitters from nerve terminals.
</p>
<p>
After release, transmitter molecules diffuse across the synaptic cleft and bind reversibly with the postsynaptic membrane receptors. The distance between the two membranes is sufficiently small such that the diffusion takes about a millisecond-a relatively slow event compared to switching in semiconductors. Whenever a transmitter molecule binds to the postsynaptic membrane, it causes a small voltage change in the postsynaptic membrane called the miniature endplate potential which can be either excitatory or inhibitory depending on the neurotransmitter molecule and postsynaptic receptor. In the resting state there are spontaneous releases of individual vesicles causing a background rate of miniature end plate potentials which are below the threshold for depolarization of the postsynaptic cell.
</p>
<p>
Specific binding of neurotransmitter molecules to post synaptic receptors changes the membrane permeability to specific ions which produce localized receptor potentials which are either excitatory or inhibitory. The post synaptic membrane "integrates" the local receptor potentials spatially and temporally such that when a "threshold" is exceeded, signals propagate in the post synaptic dendrite, cell body, or axon.
</p>
<p>
Whether the response is excitatory or inhibitory depends on the species of ion channel carrying the synaptic current. For example, in the neuromuscular junction, acetylcholine increases post synaptic permeability to sodium and potassium, leading to an excitatory, depolarizing action potential. Post synaptic acetycholine activated channels open for one to two milliseconds and allow a net entry of about 2 x 104 ions. Other synaptic channels stay open for tens of milliseconds and pass 105 ions or more. Still other post synaptic receptors couple directly to cytoskeletal changes and do not involve ionic conductance at all. At inhibitory synapses, GABA may increase permeability to chloride ion, driving the membrane potential away from threshold: Inhibition may also occur pre-synaptically in which case release of excitatory neurotransmitter is prevented. By combining multiple inputs, synapses "compute" to determine their output.
</p>
<p>
Nerve cells influence each other by either excitation, producing impulses in another cell, or by inhibition, tending to prevent impulses from arising in an adjacent cell. Lateral inhibition also occurs; activity in a group of active axons inhibits firing in nearby fibers-an apparent sharpening or focusing mechanism. A neuron receives many excitatory and inhibitory inputs from other cells (convergence) and in turn supplies many others (divergence). The process whereby neurons combine together all of their incoming signals is known as integration. Thus each cell must integrate a multitude of synaptic inputs (up to 200,000 synapses per neuron) to determine its own output. Additional levels of processing at dendritic branch points, dendritic spines, active nodes between myelin sheaths, and changes in synaptic efficacy illustrate the complexity at the level of individual neurons. Rather than a simple switch, each neuron is more like a computer. The intraneuronal cytoskeleton is the nervous system within the nervous system.
</p>
</div>
</div>

</div>

<div id="outline-container-5-3" class="outline-3">
<h3 id="sec-5-3"><span class="section-number-3">5.3</span> Representation of Information</h3>
<div class="outline-text-3" id="text-5-3">

<p>The central enigma in brain science is how information is represented within nervous systems. Understanding mechanisms of the vast capacities for storage, retrieval, and processing of information within the brain would be of enormous benefit not only to neuroscience, but to workers in computer science, particularly artificial intelligence (AI). Indeed, vast strides have been made in AI by utilizing "good guesses" about brain information processing and, conversely, understanding of brain functions and capabilities is being advanced by AI related theory including neural nets and parallel connectionism.
</p>
<p>
The underlying assumption about brain function and the comparative basis for AI considers parallel networks of connected units in which neurons and their synaptic connections are the fundamental substrates. However individual neurons perform a significant amount of analog processing both at the level of dendrites and within their cytoskeleton. For example, modification of synaptic transmission threshold, the cornerstone of neural net learning models, is regulated by the cytoskeleton and its cytoplasmic connections. Viewing neurons as fundamental digital substrates (switches or gates in a computer) may be overlooking an important dimension available for the organization of intelligence.
</p>

</div>

<div id="outline-container-5-3-1" class="outline-4">
<h4 id="sec-5-3-1"><span class="section-number-4">5.3.1</span> Integration-Sherrington's Reflex Centers</h4>
<div class="outline-text-4" id="text-5-3-1">

<p>Processing the dynamic excitatory and inhibitory patterns of activity within masses of neurons ("reflex centers") was described as "integration" by the famed neuroscientist C. S. Sherrington during the 1930's.
</p>
<p>
The brain is continually faced with the task of making decisions on the basis of information about the outside world provided by sensory end-organs and information stored in memory. At any one instant, incoming signals from diverse sources in the periphery excite the brain. The mechanisms by which the various types of information are taken into account and assigned priorities is called "integration" which is carried out at all levels of brain organization. In a global example of integration, an animal confronted by danger integrates input towards a binary output decision: "fight or flight." Our higher centers continually receive information arising in a great variety of sources on the surface of the body and in the internal organs. A typical central neuron faces a task similar to that of the brain as a whole. It is a target of converging excitatory and inhibitory signals that it transforms ("integrates") into its own impulses. The general principles of integration were discovered in the early 20th century by Sherrington (1933, 1947) who recorded tension in skeletal muscle by the stretch reflex before electrical recording from individual cells was possible. Integration appears to occur at all levels of nervous systems and among various types of organisms: crustacean, fish, and mammals. Sherrington proposed and cited evidence for integration by groups of neurons which he termed neural masses or reflex centers and suggested that they correlated with anatomically identifiable "nuclei."
</p>
<p>
A nucleus is a compact region of gray matter of relatively homogeneous neural architecture and recognizable boundaries which contains a high density of neuronal cell bodies and synapses. (White matter connotes a high density of cable-like axon fibers.) A reflex center is an assembly of neurons performing a specific function. A nucleus is purely morphological or structural while a center is functional. Nuclei may coincide with centers, but often do not (Freeman, 1972).
</p>
<p>
The concept of neural centers may convey an erroneous impression of anatomically specific function, but remains as a vestigial reference to Sherrington's concept of the nervous system and now denotes groups of neurons whose destruction leads to loss of specific function and/or the stimulation of which evoke a certain behavioral or physiological function. Brain functions are clearly not divided among centers in the same way as the work of a large organization or factory is divided among its various offices and workshops. The relation between anatomic regions devoted to specific functions, and the brain-wide distribution of information is perplexing and complicated. For example, the satiety center is located in the hypothalamus; if this general region is stimulated in an animal having a meal, the animal will stop eating as though it has had enough. If the same structure is destroyed, the animal eats too much and gets fat as though it is never satisfied. Thus clearly the satiety center neurons are essentially related to evoking the sensation of fullness or satiety. Feeding behavior, however, is regulated by a much wider range of many neuronal circuits in different regions. The satiety center integrates multiple inputs to a binary output: eat or don't eat. Body representations such as motor and sensory homunculi and other concrete evidence of anatomical localization of neuronal function may also integrate wide sources of distributed input to representations of anatomical sensation and action. Anatomical hardware such as satiety centers, motor and sensory homunculi appear to be evolutionary adaptations necessary for larger and more complex nervous systems.
</p>
<p>
Sherrington is a key figure in the history of neuroscience. His concept of integration by reflex centers illuminated possible modes of information processing by neural structures. It is now appreciated that information transfer functions occur at all levels of nervous system organization and include functions now used in computers such as summation, ramp triggers, analog/digital conversion, and logic.
</p>
</div>

</div>

<div id="outline-container-5-3-2" class="outline-4">
<h4 id="sec-5-3-2"><span class="section-number-4">5.3.2</span> Pulse Logic</h4>
<div class="outline-text-4" id="text-5-3-2">

<p>Electrical signaling in the nervous system was, according to legend, discovered during a demonstration given by Luigi Galvani to a class in the late 18th century. While Master Galvani was dissecting a frog, an electrostatic generator (which discharged electric sparks) was being played with by a bored student. Each time he drew a spark, the frog's leg (held in a forceps by Galvani) twitched. Galvani pursued this curious observation and published his treatise on Animal Electricity in 1791. Galvani felt that animal electricity was the material of excitation of nerves and of the contraction of muscles. Only after his death did his followers demonstrate that animals indeed generated their own electrical currents, rather than merely responding to applied electricity (Freeman, 1972).
</p>
<p>
The development of the microelectrode and appropriate electronic support equipment after 1940 revealed discrete electrical nerve impulses to be ubiquitous throughout the central and peripheral nervous systems. Electrophysiological techniques afforded an approach to complex problems by recording the activity of individual cells or small groups of cells. For example, the neural events involved in perception of touch were studied by recording signals from a neuron that terminates in the skin and whose function-touch sensation-was unambiguous. These signals consist of brief electrical pulses about 0.1 volt in amplitude, they last for about one millisecond, and they move along nerves at a speed up to 120 meters per second. Electrophysiological pulses within "Sherringtonian centers" had been correlated with appropriate forms of behavior, for example bursts of firings of neurons in medullary reticular formation were related to breathing. Neural activity was conceptually limited to actuation of information stored in specific neural regions. Newer approaches introduced the possibilities of encoding by dynamic neural firing patterns.
</p>
<p>
In 1943 McCulloch and Pitts proposed that neurons might be approximately described by the following assumptions: 1) the output activity of a neuron is an "all or none" process, 2) a certain number of input synapses must be excited within a brief period to excite the neuron's output, and 3) the only significant delay within the nervous system is synaptic delay. These "McCulloch-Pitts neurons" connected in networks could, in theory, perform any computation. Behaviorally significant information ("psychons") were conceived as action potential patterns in single neurons much like mass discharge in "centers" had been previously considered. A finer structure of neural information processing was perceived.
</p>
<p>
All or none action potentials which were the central element of pulse logic are relatively new over the course of evolution compared to graded wave-like events which occur in more primitive nerve nets. In the olfactory bulb, granule cells have no axons and do not generate extracellularly detectable action potentials at all. Thus the nerve impulse is not the only basis for transmission either between neurons or within neurons. What is the basic substrate of information transfer and processing within the nervous system? McCulloch (1943) considered:
</p>
<p>
&hellip; Why have I chosen to quantize in nervous impulses? &hellip; If we think (of the brain) in terms of its ultimate particles, one might split this at the level of the atoms or one might split this at the level of the neurons and so on. The question is at what level can one split the behavior so as to define a set of units in terms of which to work? And obviously the nervous impulse at the level of the neuron is a fairly nice unit for working &hellip; . But what I'm looking for is something that will perform a logical task. I'd like a thing that has a grain and I'd like to take that grain as my unit.
</p>
<p>
The grain which would explain information processing within all eukaryotic systems is the dynamic activity of subunits within cytoskeletal proteins. McCulloch, Pitts and others had guessed that information was coded in the pattern and sequence of nerve impulses somewhat like Morse code in telegraph lines. However, Adrian showed in 1947 that the frequency of firing in a nerve cell is a quantitative measure of the intensity of the stimulus. When skin is pressed, the stronger the pressure applied to the skin, the higher the frequency and the better maintained the firing of the cell. Frequency coding appears limited to information about the intensity of a stimulus and impulses in a given cell appear identical with those in other nerve cells. The significance and meaning are quite specific for each cell; for example skin sensory neurons indicate that a particular part of the skin has been pressed. Although there appears to be no reason why a great deal of information could not be conveyed by any predetermined signal including a code made up of different frequencies, the frequency or pattern of discharges do not appear to stand on their own as qualitative information. Following this recognition, the meaning of a signal became attributed to origins and destinations of the nerve fibers which convey it: "connectionism." The importance of connections is exemplified by sensations of light produced by nonvisual stimulation of the eyeball, or the phantom limb phenomenon in which an amputee may have sensation of a limb long since removed. In each case, mental representation is determined by the location of stimulation.
</p>
<p>
McCulloch and Pitts elaborated their model by adding a term which included the possibility that a firing decision might depend on inputs of times more remote than the synaptic delay period (dendritic memory) and by considering circular neural networks: closed pathways with logical feedback and reverberation. Thus pulse logic evolved into connectionism and neural networks as media of neural information representation.
</p>
</div>

</div>

<div id="outline-container-5-3-3" class="outline-4">
<h4 id="sec-5-3-3"><span class="section-number-4">5.3.3</span> Connectionism and Neural Networks</h4>
<div class="outline-text-4" id="text-5-3-3">

<p>The form and structure of neurons and the observation of neuroanatomy was made available to optical microscopy by Italian anatomist Camillo Golgi in 1875. He found a method by which, seemingly at random, a very few neurons in a brain region became stained in their entirety, with all their branches becoming evident. The cytoplasm of selected neurons take up a brightly colored stain and are thus exposed against the tangled morass of less visible cells. Golgi's contemporary, Spaniard Santiago Ramon y Cajal (1955) used the Golgi stain to investigate nearly every part of mammalian nervous systems. His neuroanatomy texts are still classic and he resolved the question of whether nerves were separate entities like all other cells, or part of a continual network. He also demonstrated that the complex connections among neurons are not random, but highly selective and specific.
</p>
<p>
Subsequent generations of neuroanatomists and neuroembryologists including Roger Sperry (1969, 1980) have emphasized the meticulous detail with which neural connections are formed, and initially supported the concept of the nervous system as a pulse logic device, superseding the older concept of the brain as a switchboard of reflex centers. Adrian's discovery that neural pulse coding was limited to a frequency/intensity coupling shifted emphasis to connectionism per se. Because the electric signals the brain uses to communicate among cells were seen as stereotyped, or nearly identical, they were viewed as symbols which do not themselves resemble the external world they represent. The consensus of opinion regarding brain functions shifted to a concept in which the shape of a neuron and its fiber origins and destinations determine mental representation as part of a neural network. The meaning of stereotyped signals was thought to be derived from specific connections of neurons.
</p>
<p>
The high degree of precision with which nerve cells are connected to each other and to different tissues in the periphery became emphasized in the connectionist concept. Orderliness of connections formed during development became viewed as essential for integrating mechanisms and representation of information in some way. The nervous system appeared to be constructed as if each neuron had built into it an awareness of its proper place in the system. The question of mental representation refocused on the embryological development during which synaptic connections were formed. During development, the neuron grows towards its target, ignores some cells, selects others, and makes permanent contact-not just anywhere on a cell but with a specified part of it. Further, neurons behave as if they were aware when they have received an appropriate synaptic connection. When they lose their synapses they respond in various ways. For example, neurons or muscle fibers disconnected from their neuronal contacts may die, but first develop "super-sensitivity" to their chemical neurotransmitter by means of an abundance of new synaptic membrane receptor proteins. Cell death or dysfunction induced by denervation occurs due to a loss of morphologicial "trophism," a neural function which conveys structural and functional material and information by cytoskeletal axoplasmic transport. Atrophy, dystrophy and spasticity of muscles and limbs which occur after strokes and other nervous system insults are examples of the loss of normal trophism. Microtubules and other cytoskeletal proteins responsible for trophism and axoplasmic transport also allow growth and extension of neuronal axon growth cones, dendrites and dendritic spines and thus play a key role in neural connections. Super-sensitivity, spasticity, atrophy and dystrophy are examples of "synaptic plasticity," changes in connections or connection strength among neurons which are relevant to brain and bodily function.
</p>
<p>
Association of learning with ongoing alteration of synaptic function was considered by several late 19th century writers and was popularized due to the Pavlovian and behaviorist influences of conditioned responses. Pavlov (1928) proposed that conditioned reflexes are established by forming new connections between cortical neurons that receive a conditioned stimulus (one accompanied by a reward or punishment) and those that receive an unconditioned stimulus. Once a new pathway was established the unconditioned stimulus would acquire the same power of evoking the response that only the conditioned stimulus originally possessed. Pavlov's idea of a new connection became fused with Donald Hebb's (1949) concept of plastic changes in synaptic efficacy to correlate with learning. Because it was believed that new fibers and therefore new synaptic connections, could not grow in adults, long term facilitation of anatomically preformed, initially nonfunctional connections became the likely alternative. This implied that at birth there existed a vast number of redundant and ineffective synaptic conditions which became "selected" during the individual's lifetime of experience. An alternative view is that, at birth, excitations can pass between any two points of the CNS through a random network of connections. As maturation, experience, and learning occurred, synaptic activity gradually sculpted usable patterns by suppressing unwanted interconnections.
</p>
<p>
Thus the connectionist brain/mind became viewed as one of two types of systems: a blank slate ("tabula rasa") in which acquired learning and internal organization result from direct environmental imprinting, or a "selectionist" network chosen from a far vaster potential network. Selectionists believe that the brain/mind spontaneously generates variable patterns of connections during childhood periods of development referred to as "transient redundancy," or from variable patterns of activity called prerepresentations in the adult. Environmental interactions merely select or selectively stabilize preexisting patterns of connections and/or neural firings which fit with the external input. Selectionists further believe that, as a correlate of learning, connections between neurons are eliminated (pruning) and/or the number of accessible firing patterns is reduced. Supporting a selectionist viewpoint is the observation that the number of neurons and apparent synapses decreases during certain important stages of development in children. However, this reduction could be masking an increase in complexity among dendritic arborizations, spines, synapses, and cytoskeleton. The selectionist view is also susceptible to the argument that new knowledge would appear difficult to incorporate.
</p>
<p>
On the assumption that the basic mode of learning and consciousness within the brain is based on synaptic connections among neurons (connectionist view) several attempts to model learning at the level of large assemblies of interconnected neurons have been made. Hebb pioneered this field by proposing that learning occurred by strengthening of specific synaptic connections within a neuronal network. This led to a concept of functional groups of neurons connected by variable synapses. These functional groups as anatomical brain regions have been described by various authors as networks, assemblies, cartels, modules or crystals. These models are aided by the mathematics of statistical mechanics and have been rejuvenated due to the work of Hopfield (1982), Grossberg (1978), Kohonen (1984) and others who drew analogies between neural networks within the brain and properties of computers leading to applications for artificial intelligence. They emphasized that computational properties useful to biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components or neurons with a high degree of interconnection. Neural networks started as models of how the brain works and have now engendered chips and computers constructed with neural net connectionist architectures utilizing hundreds of computing units and linking them with many thousands of connections. Hopfield (1982) remarks that neural net chips can provide finely grained and massively parallel computing with:
</p>
<p>
a brainlike tolerance for fuzzy facts and vague instructions. Some of the general properties you get in these systems are strikingly like &hellip; properties we see in neurobiology &hellip; . You don't have to build them in; they're just there &hellip; .
</p>
<p>
Neural networks had formally appeared in Rosenblatt's (1962) "perceptron" model of the 1950's and 1960's. Perceptrons created enthusiasm, but failed to reach their potential due to limitations of the model and its mathematics. Al experts Marvin Minsky and Seymour Papert (1972) wrote a harshly critical review which discouraged neural net research until Hopfield's resurgence in the 1980's. Hopfield introduced an energy function so that information in a neural net circuit would settle into a series of stable energy states much like rain water falling on mountains flows through valleys into lakes and rivers. Depending on the rainfall, an information state (i.e. memory, conscious image, thought) would be a given watershed pattern. Hopfield's neural nets are loosely based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of his model produce a content addressable memory (described by a phase space flow of the state of the system) which correctly yields an entire memory from any sub-part of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, time sequence retention, and insensitivity to failure of individual components. Hopfield nets and similar models are best categorized with the "tabula rasa" view of learning in which the initial state is taken as a flat energy landscape which becomes progressively contoured, eroded and complicated by direct interactions with the environment.
</p>
<p>
A selectionist approach to neural net theory has been taken by Jean Pierre Changeux, who pioneered description of allosteric interactions among proteins. Turning to the brain/mind, Changeux and colleagues (1984, 1985) have proposed a model of learning by selection based on the most recent advances in the statistical mechanics of disordered systems, namely the theory of spin glasses. Spin glasses are materials which are not crystalline, yet whose atoms possess a high degree of similar neighbor relationships and a finite number (i.e. 2) of magnetic spin states influenced by their neighbors. Aggregates of "like spin" states beget similar states among neighbors. Consequently the spin states of atoms in a spin glass can be viewed as a network (or cellular automaton) much like a collection of neurons in a nervous system. Changeux also uses terms from mathematical chaos theory like basins and attractors to describe the states to which the spin glass model evolves. Unlike the blank slate approach, the brain's initial state is viewed by Changeux as a complex energy landscape with an exuberance of valleys typical of spin glasses. Each valley corresponds to a particular set of active neurons and plays the role of a prerepresentation. An input pattern sets an initial configuration which converges towards a valley whose entry threshold is lowered by synaptic modification. Starting from a hierarchical distribution of valleys, the "lowest" valleys (sea level fjords) would correspond to maximal comprehension, ultimate answer, best correlation. The learning process is viewed as smoothening, gardening, and evolutionary pruning as already stored information influences the prerepresentations available for the next learning event. Changeux's spin glass model of neural nets is elegant, and successfully presents a hierarchical pattern of static information sorting. It's shortcomings are that it is unidirectional and fails to describe dynamic, "real time" information processing.
</p>
<p>
Another selective connectionist network model of learning is that of George Reeke and Gerald Edelman (1984) of Rockefeller University. They describe two parallel recognition automaton networks which communicate laterally. Automata are dynamic patterns of neighbor interactions capable of information processing (Chapter 1). The two parallel recognition automata which Edelman and Reeke devised have distinct and complementary personalities. They are named Darwin and Wallace after the co-developers of the theory of evolution, and utilize different approaches to the problem of recognition. "Darwin" is highly analytical, keyed to recognizing edges, dimensions, orientation, intensity, color, etc. "Wallace" is more "gestalt" and attempts to merely categorize objects into preconceived classifications. As in all parallel processing systems, output of the individual processors must be reconciled if they are not identical. Lateral communicating networks between Darwin and Wallace resolve conflicting output and form an associative memory. Because they operate on an unchanging connectionist network, Darwin and Wallace are considered "selectionist." Similar recognition automata may be operating in dynamic cytoskeletal networks within neurons.
</p>
</div>

</div>

<div id="outline-container-5-3-4" class="outline-4">
<h4 id="sec-5-3-4"><span class="section-number-4">5.3.4</span> Distributedness</h4>
<div class="outline-text-4" id="text-5-3-4">

<p>Neuroanatomical appreciation of synaptic structure gave credence to connectionist theory, and permitted Hebb to extend the theory of synaptically regulated, discretely assembled neural nets to memory and behavior in humans. However, the only experimental data came from 30 years of work by Karl Lashley (1929, 1950) who had shown that memory and perception appear to be distributed throughout the brain. Lashley's quest was the site of representation-the "engram"-of information, memory and learned behavior in the brains of laboratory animals.
</p>
<p>
Lashley's experiments in search of the engram consisted of ablation of specific parts of animal brains with careful testing for retention of habits learned before the ablation, ability to relearn, and ability to learn new tasks. The overall conclusion was that memory function is disturbed in proportion to the amount of cortex destroyed, irrespective of which part of the cortex had been removed. As far as learning, Lashley felt that all parts of the cortex were equipotent except for the specific sensory receiving areas involved in that particular learning modality. Lashley's findings were a disappointment to connectionists and engendered a bleak, hopeless outlook. In his famous life's work, In Search of the Engram, Lashley (1950) wrote that after 30 years of searching for the location of the engram in the brain he was convinced that "learning is just not possible. Nevertheless, in spite of all the evidence against it, learning does sometimes occur." Lashley rallied from despair to propose an alternative to localized storage of memory traces attached to spatially fixed reflex pathways. Agreeing that recall involves reactivating a previous pattern of neuronal excitation, he insisted that the pattern representing any one memory could be evoked not just in one specific set of neurons, but in many sets, in many places, and perhaps anywhere in regions of the brain having to do with memory function. This distribution of information in memory was explained by Lashley as excitatory patterns in cortex related to the spread of interference patterns on the surface of a liquid disturbed at several points at once. (His theory of interference patterns later inspired comparisons between the brain, storage of information and laser holography).
</p>
<p>
Lashley (1929):
</p>
<p>
Nerve impulses are transmitted &hellip; through definite intercellular connections, yet all behavior seems to be determined by masses of excitation &hellip; within general fields of activity without regard to particular nerve cells. It is the pattern and not the element that counts.
</p>
<p>
Hebb (1949) commented:
</p>
<p>
Lashley has concluded that a learned discrimination is not based on the excitation of any particular nerve cells. It is supposed to be determined solely by the pattern or shape of the sensory excitation &hellip; this suggests that the 'nmemonic trace', the neural change that is induced by experience and constitutes memory, is not a change of structure &hellip; [it] is a lasting pattern of reverberatory activity without fixed locus like some cloud formation or an eddy in a mill pond.
</p>
<p>
"Engram" was originally described as the brain's "nmemonic" trace of an elementary idea as if it were the atom of mental content. An earlier proposal was that one engram was stored in the firing pattern of one cortical neuron: a "psychon" within a "grandfather" neuron at the apex of a neuronal hierarchy. Pulse logic saw "psychons," (or engrams) in the discharge patterns of neurons and connectionist neural nets equated engrams with specific circuits of synaptically connected neurons. Activity within those circuits was thought to represent consciousness and memory that would occupy specific locations within the brain. Memory was viewed as libraries, filing cabinets, digital computers, and junk boxes in which information was stored in particular places and retrieval involved finding where it was stored. Lashley's experiments suggested that information is not stored anywhere in particular, but rather is stored everywhere; memory was distributed. One prevalent interpretation was that information was stored in the relationships among units and that each unit participated in the encoding of many, many memories. Information could thus be distributed over large spatial areas. With distributed memory, individual traces from within a complex of traces can be found much like the way filters can extract individual frequency components from complex acoustic waveforms. Filters are able to detect the presence of specific frequencies even when they are completely intertwined with others. Consequently, a filtered, distributed memory system can operate as a storage and retrieval device. If memories are not independent of one another, the storage of one memory can affect another. Previously stored information tends to evoke an original pattern of activity even though the inputs to the system may differ in many details. This description is similar to the hologram concept in which coherent reference waves are necessary to retrieve information from an interference pattern.
</p>
<p>
Lashley (1950):
</p>
<p>
It is not possible to demonstrate the isolated localization of a memory trace anywhere within the nervous system. Limited regions may be essential for learning or retention of a particular activity, but within such regions the parts are functionally equivalent. The engram is represented throughout the area. All of the cells of the brain must be in almost constant activity either firing or actively inhibited. Every instance of recall records the activity of literally millions of neurons. The same neurons which retain the memory traces of one experience must also participate in countless other activities.
</p>
<p>
Recall involves the "synergic" action or some sort of resonance among a very large number of neurons &hellip;
</p>
<p>
Hebb's view of engram representation was a closed loop of neurons firing in a confined region. Lashley's studies led him to suggest an open, parallel, distributed network covering wide regions of brain. Hebb's linkage of learning and synaptic efficacy transcended this conflict because it related to both concepts, which may also operate within cytoskeletal networks.
</p>

<div id="Figure-4.3" class="figure">
<p><img src="UC-images/image025.jpg"  alt="UC-images/image025.jpg" /></p>
<p>Figure 4.3 Brain memory bank based on "conventional" notions of dendritic spine synapses. Input lines (B1-3) are axons which branch and synapse on dendritic spines (E) connected to output lines (C). "File dump lines" (A, d1-3) direct spine activities to "copy" or "dump." Such a configuration allows each spine to hold about 3 bits of information, remarkably low when compared to the capacities of biomolecules such as DNA or microtubules. Cytoskeletal activities within dendritic spines may contribute. By Paul Jablonka.</p>
</div>

</div>

</div>

<div id="outline-container-5-3-5" class="outline-4">
<h4 id="sec-5-3-5"><span class="section-number-4">5.3.5</span> Synaptic Mechanisms of Learning and Memory</h4>
<div class="outline-text-4" id="text-5-3-5">

<p>Memory processes have traditionally been divided into two classes; short term and long term. Short term memory, or working memory, is apparently how we remember telephone numbers from the time we look them up in the directory until we dial them. Long term memory or reference memory is used in recording information for long term reference. Short term or working memory is thought to be of relatively small capacity with a maximum of 5 to 9 items at any one time. It is labile and easily disrupted if attention is diverted and it automatically erases within minutes. Continual verbal rehearsal counteracts erasure and re-enters the contents as long term memory. Once laid down, long term memory can endure for a long time-perhaps an individual's lifetime. Long term memory has a large capacity, and difficulty in recalling specific items arise not because memory traces fade, but rather because their address is lost. Well practiced access routes to long term memory items include "nmemonics," easily remembered reference clues. Items which have been stored and then not used will become increasingly difficult to recall. Once they are retrieved, such seemingly forgotten memories become again accessible. Conventional wisdom has held that items become stored in long term memory only after they have been first held in short term memory. This is a process known as consolidation which is thought to require a finite period of time on the order of 45 seconds (Cherkin and Harroun, 1971). Some regard the two processes as independent parallel functions. If brain activity is markedly altered by seizures, trauma resulting in unconsciousness, or by general anesthesia the phenomenon of amnesia may occur in which the subject cannot remember events that occurred immediately before the disruption. Events farther in the past are not forgotten by such interventions. One explanation is that short term memory depends on some dynamic process such as the continued circulation of impulses in a pattern which, when disrupted, is erased. According to this scheme, long term memories are stored by an enduring change in the neurons or in connections between them which would be unaffected by such upheavals. An analogy to computer jargon would suggest that a software program becomes "hardwired." Other models of memory process describe more of a continuum in the consolidation process divided into three or five stages, or entirely different mechanisms with varying methods of entry, storage capacities, lifespan and accessibility. Still other models regard all memory functions as the same basic mechanism differing only in secondary characteristics.
</p>
<p>
Learning is linked to memory; learning a complex task probably involves generating a pattern suitable for memory storage. For example, the image of a person's face may be recalled by exciting neurons in a pattern similar to the one generated when that face was actually perceived. The ability to swing a tennis racket implies the existence of a program or pattern for activating muscles in the proper sequence and degree. Acquiring such neuronal programs has been attributed to changes in the functioning of synapses between specific neurons (Figure 4.3). Structural changes which lead to alteration in the function and sensitivity of interneuronal synaptic connections are the cornerstone of current concepts of learning and memory. Classifications of the types of plastic changes that could occur in synapses include habituation, long term potentiation, and heterosynaptic potentiation.
</p>
<p>
Habituation to a response is the simplest form of learning. When an animal hears a new sound it may respond by perking its ears showing some form of attention. If that sound is repeated continuously, the animal learns that the sound or stimulus is neither threatening nor interesting and becomes "habituated" to it. Habituation is different from other forms of decreased response such as synaptic fatigue or desensitization and is specific for the stimulus and its intensity. If the habituating stimulus is withheld for a period of time and presented again, the response reappears ("dishabituation"). Habituation to noxious stimuli does not occur and when non-noxious and noxious stimuli are paired there is no habituation to either of the two. The mechanism of habituation has been studied in detail in the marine organism aplysia, or sea slug. The sea slug has a "gill withdrawal reflex" which is convenient for study. When the skin of the slug's syphon is stimulated, the animal withdraws its gill. This response shows habituation, dishabituation and other features typical of more complex mammalian responses. The neuronal network mediating this reflex response has been extensively mapped and the participating synapses studied electrically. The habituation of gill withdrawal might have been the result of many processes including synaptic inhibition, but in fact has been shown to be the result of decreased output of excitatory neurotransmitter at the presynaptic axon terminals mediating the withdrawal reflex. Neuroscientist Eric Kandel (1976) of Columbia University has shown that the habituation is different from ordinary fatigue, does not involve exhaustion of available transmitter, and is related to decreased flux of calcium ions through presynaptic calcium channels. Thus a behavioral response has been elegantly related to molecular level events. The activity of presynaptic calcium channels and other neural proteins have been viewed as "allosteric"-an ability to spatially and temporally integrate multiple converging signals to a specific protein state, or "conformation."
</p>
<p>
The second form of neuronal plasticity is long term potentiation (LTP). In LTP, repeated use of a synapse makes transmission through that synapse increasingly easy. In the synapses of mammalian brain hippocampus, the effect endures for many hours and LTP has been classically related to learning and memory. If two pathways share an interneuron, then LTP can enhance transmission through the pathway not originally excited, a form of associative memory and recall. The duration of LTP effect of many hours to days corresponds with the morphological turnover and trophic maintenance of synaptic membrane proteins by axoplasmic transport, a function of the neuronal cytoskeleton.
</p>
<p>
The third form of neuronal plasticity is heterosynaptic potentiation in which activity on one synapse changes efficiency of transmission in another on the same postsynaptic membrane. This may occur either through change in sensitivity of the post synaptic neuron to the transmitter, or by change in the amount of transmitter released. There is some evidence that LTP may be due to increased numbers of receptors in post synaptic membranes and a similar mechanism could occur in heterosynaptic potentiation in which more then one neuron is involved. Habituation, long term potentiation, and heterosynaptic potentiation can account for synaptic plasticity and some aspects of learning and memory. Brain processes related to representation, memory, learning, and consciousness thus focus on molecular level alterations in synaptic membrane proteins which are regulated by the neuronal cytoskeleton.
</p>
<p>
There is some evidence for direct cytoskeletal involvement in cognitive processes. Activities of cytoskeletal microtubules and turnover of microtubule subunits ("tubulin") have been shown to be increased in the brain during specific times of learning, memory and experience. Mileusnic, Rose, and Tillson (1980) have utilized a learning model in baby chicks who can be readily trained not to peck at a bright bead coated with an unpleasant tasting substance. These authors have studied some of the neurochemical correlates of this "passive avoidance learning" and point out that tubulin, the major constituent of microtubules, is present in large amounts in the developing brain of young chicks. Significant amounts of tubulin are associated with synaptic membranes leading the authors to conclude that any model of learning and memory which postulates modulation of synaptic structure, as consistent with Hebb's postulates, must involve tubulin in learning. Other work from their laboratory and others have shown that both incorporation of precursor amino acids and total quantity of tubulin may be enhanced by experience and learning during early development.
</p>
<p>
John Cronly-Dillon and co-workers (1974) of Britain's Manchester University have found that when baby rats first open their eyes, genes in visual cortex suddenly begin producing vast quantities of tubulin which presumably form microtubules involved in establishing new synaptic connections. When the rats are 35 days old, the critical phase for learning is over and tubulin production is drastically reduced. Their conclusion is that tubulin turnover and microtubule activity are involved in synaptic plasticity aspects of learning and memory.
</p>
<p>
Another dynamic mode of synaptic plasticity focusing on dendritic spines has been proposed by Francis Crick (1982). He suggested that dendritic spines can "twitch" and change their shape, thereby altering their synaptic thresholds by mechanical changes. The placement and architecture of dendritic spines are determined by microtubules, but spines themselves are comprised mostly of contractile actin (Matus, Ackermann, Pehling, Byers, and Fujiwara, 1982). Dynamic spine plasticity, orchestrated by dendritic MT and cytoskeleton, may be an important mechanism of short term memory, and a link between the cytoskeleton and synaptic level neural networks. Another link is axoplasmic transport which maintains and supplies the form and functions of dendritic spines and all neuronal synapses and structures.
</p>
</div>

</div>

<div id="outline-container-5-3-6" class="outline-4">
<h4 id="sec-5-3-6"><span class="section-number-4">5.3.6</span> Axoplasmic Transport</h4>
<div class="outline-text-4" id="text-5-3-6">

<p>Synaptic membrane proteins including ion channels and receptors, cytoskeletal protein structures which expel neurotransmitter vesicles, organelles including mitochondria, and enzymes required for the synthesis and metabolism of transmitters are manufactured only in the cell bodies of neurons where biochemical machinery exists for protein synthesis and assembly (Golgi apparatus and ribosomes). These materials or their precursors are then moved through the axon (or dendrite) to the nerve terminal by a cytoskeletal mechanism similar to a conveyer belt or bucket brigade. Time lapse photography of neurons in cell culture show mitochondria (large organelles which produce chemical energy in the form of ATP) floating down axons like barges on a river. Recent technology such as video enhanced contrast microscopy (Allen, 1987) has shown vesicles zipping along microtubules on the surfaces of axoplasm extruded from squid neurons. Transmitters are synthesized throughout the entire neuron as the enzymes which catalyze transmitter formation move along the cytoskeletal apparatus from cell body to terminal. The highest enzymatic activity and transmitter concentrations are reached in the terminal boutons. Thus the plasticity of a synapse, its efficacy, readiness and threshold which appear to regulate learning and memory in neural nets over time all depend on axoplasmic transport.
</p>
<p>
Several separate and independent axoplasmic transport processes have been identified by following the movement of various tracers. The fastest move at a rate of 400 millimeters per day (about 500 nanometers per second), the slowest barely one millimeter per day. The mechanical parts of the system are microtubules and contractile proteins attached to specific sites on microtubule walls. These contractile proteins (dynein or kinesin) utilize chemical energy in the form of ATP hydrolysis to contract in orchestrated sequences of bucket brigade activity. What is not understood is the mechanism by which microtubules orchestrate the cooperative sequential activities of the attached contractile proteins. The main stream of axoplasmic transport can be stopped by drugs such as colchicine, which depolymerizes microtubules. Axoplasmic transport generally flows from the cell body toward the tips of fibers. In motor nerves, axoplasmic transport flows in the same direction as the impulse traffic; in primary sensory neurons it flows in the opposite direction to the sensory impulses. In dendrites, the main flow is also from the cell body to the periphery. These are all examples of anterograde axoplasmic flow. There is also simultaneous transport in the opposite direction toward the cell body called retrograde axoplasmic flow which apparently brings feedback information to the cell machinery to regulate the production of transmitter enzymes and other materials. It might also return worn or broken down cell constituents to be recycled. These trophic feedback mechanisms create dynamic neurons capable of changing shape and function as an adaptation to ongoing experience without excessive loss of old information. Synapses, dendritic spines, dendritic branch patterns and membrane proteins are continually changing, yet the memories they contain are somehow maintained by the ever present and ever-changing cytoskeleton.
</p>
</div>

</div>

<div id="outline-container-5-3-7" class="outline-4">
<h4 id="sec-5-3-7"><span class="section-number-4">5.3.7</span> Parallelism, Collective Cooperativity, and the Grain of the Engram   77</h4>
<div class="outline-text-4" id="text-5-3-7">

<p>Neuron to neuron synapses operate on the order of milliseconds whereas modern high speed computers operate with semiconductor switches which function on the order of nanoseconds. Yet the brain is able, in a few hundred milliseconds, to perform processing feats that are impossible to emulate in hundreds of minutes of computer time. The assumption is that the brain accomplishes this feat through the simultaneous operation of many, many parallel components.
</p>
<p>
Parallel, distributed models of collective mind organization have been proposed by two noteworthy authors coming from different orientations. Michael Gazzaniga (1985) is one of the first researchers to work with "split brain" patients in whom a severed corpus collosum has separated right and left hemispheres. He contends that minds consist of large collections of smaller semiautonomous parts with limited communication among them. Gazzaniga has developed convincing evidence that our minds are "modular"; they are organized into relatively independent functioning units that work in parallel. The mind does not operate in a single way to solve problems but has many identifiably different units that contribute to our conscious structure in ways that can sometimes be isolated by clever experiments. Specific modules might be devoted to face and visual image recognition, language interpretation, and what Gazzaniga calls an "inference engine." Located in the brain's dominant hemisphere close to the language interpreter module, the inference engine is thought to "coordinate" consciousness. These modules may be compared to those described by Pribram or the "cartels" described by Freeman and represent a level of brain organizational hierarchy just below that of the entire brain. Gazzaniga relates free will to a basic feature of brain organization, and suggests that the particular belief in free will itself follows from the modular theory of mind. He observes that we are continually interpreting behaviors produced by independent brain modules as behaviors that are produced by the "self." We conclude that we are acting freely whereas at the root of it we don't really know why we do almost anything. This notion may be compared to the parallel connectionist concept (i.e. "Darwin" and "Wallace") which requires a vote or caucus to determine a summary output. Gazzaniga also states that basic cognitive phenomena such as acquiring and holding social beliefs are just as much a product of human brain organization as our behaviorist desires to eat, sleep, and have sex. He argues that we are "hardwired to have beliefs."
</p>
<p>
A comparable conclusion has been reached by Marvin Minsky (1986). In The Society of Mind, the patriarch of AI discusses the mind as a vast number of "agents." Information is represented by "frames" which are multiple connected knowledge nodes. Minsky throws a much more complex grid of agents over the mind than Gazzaniga's modules, but both describe levels of organization between the neuronal synaptic level and the whole brain which are more or less representative of neural network theory. Gazzaniga argues that the brain is more a social entity than a psychological one. Rather than being an indivisible whole as was once believed, it is a vast confederacy of relatively independent modules, each of which processes information and activates its own thoughts and actions. But what are the modules? Where is the grain of consciousness? Isn't the mind more than an array of squabbling modules?
</p>
<p>
John O'Keefe and Andrew Speakman (1986) at the University College of London have completed a series of experiments on the activity of rat hippocampal neurons while the animals were performing spatial working memory tasks. These and other results suggest a hippocampal cognitive map in which the representation of place in an environment is distributed across the surface of the hippocampus. O'Keefe and Speakman find that the grain of the representation is at or below the single cell level. That is, each cell in a small cluster participates in the representation of different patches of environment. Conversely, any cluster of about 8 to 10 cells appears adequate to provide a coarse representation of an entire environment. The addition of more cells to the network increases the resolution, or grain of the representation, but does not alter it. The representation of an environment is thus distributed and the "graininess" is at a level below that of individual nerves and synapses. E. R. John and collegues (1986) from New York University have used metabolic mapping of memory traces in cats to show that information is extensively distributed, requiring that "(nerve) cells participate in multiple memories." They implicate:
</p>
<p>
&hellip; cooperative processes in which the nonrandom behavior of huge ensembles of neural elements mediate the integration and processing of information and the retrieval of memories. Memory and awareness in complex neural systems may depend on presently unrecognized properties of the system as a whole.
</p>
<p>
Walter Freeman (1972, 1983) of the University of California at Berkeley agrees that nervous systems are more than the sum of their parts. According to Freeman, this occurs because interconnections of numbers of neurons give rise to collective properties belonging to the neural populations in general rather than to specific individual neurons. Such collective properties related to mental processes are thought by Freeman to be generated by the interconnectedness of numbers of neurons of at least ten thousand or more.
</p>
<p>
Freeman and others who advocate cooperative collective aspects of mental processes cite the electroencephalogram (EEG) as supportive evidence. EEG is a continuous electromagnetic wave which pervades the brain and is composed of frequencies from one hertz (= Hz = cycles per second) to a few thousand Hz, but concentrated in the range between 3 and 50 Hz (Chapter 7). EEG has been used for half a century to diagnose brain disease, but not until the 1960's was the source of the "brain waves" clarified. EEG arises not from the sum of propagating action potentials in axons, but rather from the slow, graded potentials produced by dendrites and cell bodies. Local potentials combine to form regional and brain-wide patterns. Individual neurons and their dendrites slip in and out of phase with the surrounding EEG field. Studies by Adey (1977), John (1980) and many other scientists have correlated mental activities in animals and humans with EEG pattern changes. Because the EEG is produced by large numbers of neurons, these correlations may suggest that collective neuronal effects are the basis for mental activities. Freeman proposes that functionally significant EEG wave phenomena occur within neural masses in which there exist feedback connection of one neuron with many others in the same mass. Collective waves of graded potentials are Freeman's candidate for the grain of consciousness. Localized wave activity within neural masses or "cartels" would be related to EEG waves in the same way that atmospheric temperature and pressure waves generate cloud patterns-observable side effects which may yield information about the internal dynamics.
</p>
<p>
Opinions regarding the significance of local collective EEG wave fields vary from superfluous epiphenomena, to information transmitters, to the substance of consciousness itself. E. R. John (1984) is perhaps the strongest proponent; he points out that individual neurons are sensitive to the fields they generate. Adey (1984) and colleagues have applied "EEG-like" fields to the brains of experimental animals and found they produce behavioral effects. John proposes that a specific electromagnetic field is evoked by sensory stimuli and "resonates" with similar patterns stored in memory. New patterns bring new resonances which lead, according to John, to the stream of conscious experience. Wave patterns modify neuronal structure, forming memories to be evoked by later resonances.
</p>
<p>
E. R. John (1980) asserts that:
</p>
<p>
Consciousness is a property of these improbable distributions of energy in space and time, just as gravity is a property of matter.
</p>
</div>
</div>

</div>

<div id="outline-container-5-4" class="outline-3">
<h3 id="sec-5-4"><span class="section-number-3">5.4</span> Toward Molecular Consciousness</h3>
<div class="outline-text-3" id="text-5-4">

<p>How is electrical wave energy coupled to neuronal structure, and what neuronal structures are most suitable for coupling and representation of cognitive content? Simultaneous recognition (and cooperative coupling) by large numbers of neural elements requires rapid changes in chemical state of widely distributed macromolecules. Likely candidates are the "allosteric" proteins which can transduce regulatory signals (binding of molecules, ions/acidity, voltage fields etc.) to undergo functional conformational changes. Hyden (1977) initially proposed that proteins rapidly change their conformation in response to weak, oscillating electric fields. W. Ross Adey (1977) has elaborated on the coupling of neural protein conformation and function to EEG waves. He has suggested that webs of hydrated glycoproteins (extending from neural membranes into the extracellular space), membrane proteins, and the cytoskeleton are primed to undergo rapid conformational changes in response to localized and selective spatiotemporal EEG patterns, as well as biochemical signals. Transduction of electromagnetic energy into conformational states by widely distributed proteins can cooperatively represent dynamic information.
</p>
<p>
The common thread of biological intelligence, the "grain of the engram," may be found within cooperative dynamics of a molecular network whose structure and functions appear perfectly adapted to information processing: the cytoskeleton. response to weak, oscillating electric fields. W. Ross Adey (1977) has elaborated on the coupling of neural protein conformation and function to EEG waves. He has suggested that webs of hydrated glycoproteins (extending from neural membranes into the extracellular space), membrane proteins, and the cytoskeleton are primed to undergo rapid conformational changes in response to localized and selective spatiotemporal EEG patterns, as well as biochemical signals. Transduction of electromagnetic energy into conformational states by widely distributed proteins can cooperatively represent dynamic information.
</p>
<p>
The common thread of biological intelligence, the "grain of the engram," may be found within cooperative dynamics of a molecular network whose structure and functions appear perfectly adapted to information processing: the cytoskeleton.
</p>
</div>
</div>

</div>

<div id="outline-container-6" class="outline-2">
<h2 id="sec-6"><span class="section-number-2">6</span> Cytoskeleton/Cytocomputer</h2>
<div class="outline-text-2" id="text-6">

<p>Living organisms are collective assemblies of cells which contain collective assemblies of organized material called protoplasm. In turn, protoplasm consists of membranes, organelles, nuclei and the bulk interior medium of living cells: cytoplasm. Dynamic rearrangements of cytoplasm within eukaryotic cells account for their changing shape, repositioning of internal organelles, and in many cases, movement from one place to another. We now know that the cytoskeleton, a dynamic network of filamentous proteins, is responsible for cytoplasmic organization (Figures 5.1 thru 5.3).
</p>

</div>

<div id="outline-container-6-1" class="outline-3">
<h3 id="sec-6-1"><span class="section-number-3">6.1</span> The Nature of Cytoplasm</h3>
<div class="outline-text-3" id="text-6-1">

<p>The nature of cytoplasm has been scientifically studied for at least a century and a half. That history was described by Beth Burnside (1974) in a landmark meeting devoted to the cytoskeleton at the New York Academy of Sciences.
</p>
<p>
An early French observer of cellular material, Felix Du Jardin proposed in 1835 that all cells were composed of a motile material called "sarcode" that had both structural and contractile properties. In 1861, Austrian E. Brucke linked the mechanical and physiological properties of cells to a fundamental organization or architecture of cytoplasm as distinguished from purely chemical or physical properties. Early Dutch microscopist van Leeuwenhoek observed that red blood cells became deformed passing through capillaries Hand then sprang back into shape, demonstrating the elasticity of cytoplasm. The variety of elaborate forms that cells assume and maintain also require some cytoplasmic rigidity, properties which led nineteenth century biologists to conclude that cytoplasm is not merely a liquid nor an emulsion nor an aqueous suspension of life bearing granules. Rather, cytoplasmic architecture and contractility could be explained by the proposal of a mesh-like "reticular" or "fibrous" substructure whose interstices were filled with fluid. To some early biologists, the structure of cytoplasm therefore consisted of a continuous reticular network of delicate fibrils extending through the cell (reticular theory). Others claimed that the fibrils forming the cytoplasmic substratum were unbranched and discontinuous (fibrillar theory). Both of these theories were initially supported, but later deflated, by microscope preparation techniques of fixation and staining which arose between 1870 and 1890. Fibrillar and reticular frameworks appeared everywhere in many types of fixed cells, particularly in muscle, nerve, cartilage and epithelial cells.
</p>

<div id="Figure-5.1" class="figure">
<p><img src="UC-images/image027.jpg"  alt="UC-images/image027.jpg" /></p>
<p>Figure 5.1 Cytoskeletal network in a rat kangaroo kidney cell (ptK2) illustrated by tubulin antibody and light microscopy. Microtubules emanate from a dense MTOC region near the nucleus (N). With permission from Marc DeBrabander (1982).</p>
</div>

</div>

</div>

<div id="outline-container-6-2" class="outline-3">
<h3 id="sec-6-2"><span class="section-number-3">6.2</span> Microtubules</h3>
<div class="outline-text-3" id="text-6-2">



</div>

<div id="outline-container-6-2-1" class="outline-4">
<h4 id="sec-6-2-1"><span class="section-number-4">6.2.1</span> Microtubule Structure and Function</h4>
<div class="outline-text-4" id="text-6-2-1">


</div>

</div>

<div id="outline-container-6-2-2" class="outline-4">
<h4 id="sec-6-2-2"><span class="section-number-4">6.2.2</span> Microtubule Assembly and the Generation of Form</h4>
<div class="outline-text-4" id="text-6-2-2">


</div>

</div>

<div id="outline-container-6-2-3" class="outline-4">
<h4 id="sec-6-2-3"><span class="section-number-4">6.2.3</span> Microtubule Organizing Centers (MTOC) and Centrioles. 93</h4>
<div class="outline-text-4" id="text-6-2-3">


</div>

</div>

<div id="outline-container-6-2-4" class="outline-4">
<h4 id="sec-6-2-4"><span class="section-number-4">6.2.4</span> Microtubule Associated Proteins (MAPs)</h4>
<div class="outline-text-4" id="text-6-2-4">


</div>
</div>

</div>

<div id="outline-container-6-3" class="outline-3">
<h3 id="sec-6-3"><span class="section-number-3">6.3</span> Intermediate Filaments</h3>
<div class="outline-text-3" id="text-6-3">


</div>

</div>

<div id="outline-container-6-4" class="outline-3">
<h3 id="sec-6-4"><span class="section-number-3">6.4</span> The Cytoplasmic Ground Substance</h3>
<div class="outline-text-3" id="text-6-4">



</div>

<div id="outline-container-6-4-1" class="outline-4">
<h4 id="sec-6-4-1"><span class="section-number-4">6.4.1</span> The Microtrabecular Lattice (MTL)</h4>
<div class="outline-text-4" id="text-6-4-1">


</div>

</div>

<div id="outline-container-6-4-2" class="outline-4">
<h4 id="sec-6-4-2"><span class="section-number-4">6.4.2</span> The Cytomatrix</h4>
<div class="outline-text-4" id="text-6-4-2">


</div>

</div>

<div id="outline-container-6-4-3" class="outline-4">
<h4 id="sec-6-4-3"><span class="section-number-4">6.4.3</span> Cytoplasmic Solid State</h4>
<div class="outline-text-4" id="text-6-4-3">


</div>
</div>

</div>

<div id="outline-container-6-5" class="outline-3">
<h3 id="sec-6-5"><span class="section-number-3">6.5</span> Cytoskeletal Motility</h3>
<div class="outline-text-3" id="text-6-5">



</div>

<div id="outline-container-6-5-1" class="outline-4">
<h4 id="sec-6-5-1"><span class="section-number-4">6.5.1</span> Cytoplasmic Probing</h4>
<div class="outline-text-4" id="text-6-5-1">


</div>

</div>

<div id="outline-container-6-5-2" class="outline-4">
<h4 id="sec-6-5-2"><span class="section-number-4">6.5.2</span> Bending Sidearms</h4>
<div class="outline-text-4" id="text-6-5-2">


</div>

</div>

<div id="outline-container-6-5-3" class="outline-4">
<h4 id="sec-6-5-3"><span class="section-number-4">6.5.3</span> Ciliary and Collective Movement</h4>
<div class="outline-text-4" id="text-6-5-3">


</div>

</div>

<div id="outline-container-6-5-4" class="outline-4">
<h4 id="sec-6-5-4"><span class="section-number-4">6.5.4</span> Geodesic Tensegrity Gels</h4>
<div class="outline-text-4" id="text-6-5-4">


</div>
</div>

</div>

<div id="outline-container-6-6" class="outline-3">
<h3 id="sec-6-6"><span class="section-number-3">6.6</span> The Cytoskeleton and Development</h3>
<div class="outline-text-3" id="text-6-6">


</div>

</div>

<div id="outline-container-6-7" class="outline-3">
<h3 id="sec-6-7"><span class="section-number-3">6.7</span> The Cytoskeleton and Medicine</h3>
<div class="outline-text-3" id="text-6-7">


</div>

</div>

<div id="outline-container-6-8" class="outline-3">
<h3 id="sec-6-8"><span class="section-number-3">6.8</span> Intelligence in the Cytoskeleton</h3>
<div class="outline-text-3" id="text-6-8">


</div>
</div>

</div>

<div id="outline-container-7" class="outline-2">
<h2 id="sec-7"><span class="section-number-2">7</span> Protein Conformational Dynamics</h2>
<div class="outline-text-2" id="text-7">



</div>

<div id="outline-container-7-1" class="outline-3">
<h3 id="sec-7-1"><span class="section-number-3">7.1</span> Protein Structure</h3>
<div class="outline-text-3" id="text-7-1">


</div>

</div>

<div id="outline-container-7-2" class="outline-3">
<h3 id="sec-7-2"><span class="section-number-3">7.2</span> Protein Conformation</h3>
<div class="outline-text-3" id="text-7-2">


</div>

</div>

<div id="outline-container-7-3" class="outline-3">
<h3 id="sec-7-3"><span class="section-number-3">7.3</span> Proteins and Energy</h3>
<div class="outline-text-3" id="text-7-3">


</div>

</div>

<div id="outline-container-7-4" class="outline-3">
<h3 id="sec-7-4"><span class="section-number-3">7.4</span> Protein Cooperativity-Historical View</h3>
<div class="outline-text-3" id="text-7-4">


</div>

</div>

<div id="outline-container-7-5" class="outline-3">
<h3 id="sec-7-5"><span class="section-number-3">7.5</span> Living Water and Hydrophobic Interactions</h3>
<div class="outline-text-3" id="text-7-5">


</div>

</div>

<div id="outline-container-7-6" class="outline-3">
<h3 id="sec-7-6"><span class="section-number-3">7.6</span> Electret, Piezo, and Pyroelectric Effects</h3>
<div class="outline-text-3" id="text-7-6">


</div>

</div>

<div id="outline-container-7-7" class="outline-3">
<h3 id="sec-7-7"><span class="section-number-3">7.7</span> Solitons/Davydov</h3>
<div class="outline-text-3" id="text-7-7">


</div>

</div>

<div id="outline-container-7-8" class="outline-3">
<h3 id="sec-7-8"><span class="section-number-3">7.8</span> Coherent Excitations /Fröhlich</h3>
<div class="outline-text-3" id="text-7-8">


</div>

</div>

<div id="outline-container-7-9" class="outline-3">
<h3 id="sec-7-9"><span class="section-number-3">7.9</span> Massless Bosons, Cytoskeletal Self-Focusing</h3>
<div class="outline-text-3" id="text-7-9">


</div>
</div>

</div>

<div id="outline-container-8" class="outline-2">
<h2 id="sec-8"><span class="section-number-2">8</span> Anesthesia: Another Side of Consciousness</h2>
<div class="outline-text-2" id="text-8">



</div>

<div id="outline-container-8-1" class="outline-3">
<h3 id="sec-8-1"><span class="section-number-3">8.1</span> Levels of Anesthesia/Consciousness</h3>
<div class="outline-text-3" id="text-8-1">


</div>

</div>

<div id="outline-container-8-2" class="outline-3">
<h3 id="sec-8-2"><span class="section-number-3">8.2</span> Memory. 151</h3>
<div class="outline-text-3" id="text-8-2">


</div>

</div>

<div id="outline-container-8-3" class="outline-3">
<h3 id="sec-8-3"><span class="section-number-3">8.3</span> Mechanisms of Anesthesia</h3>
<div class="outline-text-3" id="text-8-3">


</div>
</div>

</div>

<div id="outline-container-9" class="outline-2">
<h2 id="sec-9"><span class="section-number-2">9</span> Models of Cytoskeletal Computing</h2>
<div class="outline-text-2" id="text-9">



</div>

<div id="outline-container-9-1" class="outline-3">
<h3 id="sec-9-1"><span class="section-number-3">9.1</span> Energy and Information in Microtubules</h3>
<div class="outline-text-3" id="text-9-1">


</div>

</div>

<div id="outline-container-9-2" class="outline-3">
<h3 id="sec-9-2"><span class="section-number-3">9.2</span> Cytoskeletal Information Processing</h3>
<div class="outline-text-3" id="text-9-2">



</div>

<div id="outline-container-9-2-1" class="outline-4">
<h4 id="sec-9-2-1"><span class="section-number-4">9.2.1</span> MT Sensory Transduction/Atema</h4>
<div class="outline-text-4" id="text-9-2-1">


</div>

</div>

<div id="outline-container-9-2-2" class="outline-4">
<h4 id="sec-9-2-2"><span class="section-number-4">9.2.2</span> MT Mechano-lonic Transducers/Moran and Varela</h4>
<div class="outline-text-4" id="text-9-2-2">


</div>

</div>

<div id="outline-container-9-2-3" class="outline-4">
<h4 id="sec-9-2-3"><span class="section-number-4">9.2.3</span> Cytomolecular Computing/Conrad and Liberman</h4>
<div class="outline-text-4" id="text-9-2-3">


</div>

</div>

<div id="outline-container-9-2-4" class="outline-4">
<h4 id="sec-9-2-4"><span class="section-number-4">9.2.4</span> MT Signal Processing/DeBrabander</h4>
<div class="outline-text-4" id="text-9-2-4">


</div>

</div>

<div id="outline-container-9-2-5" class="outline-4">
<h4 id="sec-9-2-5"><span class="section-number-4">9.2.5</span> Cytoskeletal String Processors/Barnett</h4>
<div class="outline-text-4" id="text-9-2-5">


</div>

</div>

<div id="outline-container-9-2-6" class="outline-4">
<h4 id="sec-9-2-6"><span class="section-number-4">9.2.6</span> Microtubule "Gradions"/Roth, Pihlaja, Shigenaka</h4>
<div class="outline-text-4" id="text-9-2-6">


</div>

</div>

<div id="outline-container-9-2-7" class="outline-4">
<h4 id="sec-9-2-7"><span class="section-number-4">9.2.7</span> Gyroscopic Centrioles/Bornens</h4>
<div class="outline-text-4" id="text-9-2-7">


</div>

</div>

<div id="outline-container-9-2-8" class="outline-4">
<h4 id="sec-9-2-8"><span class="section-number-4">9.2.8</span> Centriole-MT Signaling/Albrecht-Buehler</h4>
<div class="outline-text-4" id="text-9-2-8">


</div>

</div>

<div id="outline-container-9-2-9" class="outline-4">
<h4 id="sec-9-2-9"><span class="section-number-4">9.2.9</span> Dynamic Tensegrity/Heidemann and Jarosch</h4>
<div class="outline-text-4" id="text-9-2-9">


</div>

</div>

<div id="outline-container-9-2-10" class="outline-4">
<h4 id="sec-9-2-10"><span class="section-number-4">9.2.10</span> Dynamic MT Probing/Kirschner and Mitchison</h4>
<div class="outline-text-4" id="text-9-2-10">


</div>

</div>

<div id="outline-container-9-2-11" class="outline-4">
<h4 id="sec-9-2-11"><span class="section-number-4">9.2.11</span> Sphere Packing Screw Symmetry/Koruga</h4>
<div class="outline-text-4" id="text-9-2-11">


</div>

</div>

<div id="outline-container-9-2-12" class="outline-4">
<h4 id="sec-9-2-12"><span class="section-number-4">9.2.12</span> Cytoskeletal Self-Focusing/Del Giudice</h4>
<div class="outline-text-4" id="text-9-2-12">


</div>

</div>

<div id="outline-container-9-2-13" class="outline-4">
<h4 id="sec-9-2-13"><span class="section-number-4">9.2.13</span> MT Automata, Holography/Hameroff, Watt, Smith</h4>
<div class="outline-text-4" id="text-9-2-13">


</div>
</div>

</div>

<div id="outline-container-9-3" class="outline-3">
<h3 id="sec-9-3"><span class="section-number-3">9.3</span> The Cytoskeletal Connection</h3>
<div class="outline-text-3" id="text-9-3">


</div>
</div>

</div>

<div id="outline-container-10" class="outline-2">
<h2 id="sec-10"><span class="section-number-2">10</span> Viruses/Ambiguous Life Forms</h2>
<div class="outline-text-2" id="text-10">



</div>

<div id="outline-container-10-1" class="outline-3">
<h3 id="sec-10-1"><span class="section-number-3">10.1</span> What Is the Essence of Living Matter?</h3>
<div class="outline-text-3" id="text-10-1">


</div>

</div>

<div id="outline-container-10-2" class="outline-3">
<h3 id="sec-10-2"><span class="section-number-3">10.2</span> Virus (Mis)Behavior</h3>
<div class="outline-text-3" id="text-10-2">


</div>

</div>

<div id="outline-container-10-3" class="outline-3">
<h3 id="sec-10-3"><span class="section-number-3">10.3</span> Virus Structure and Collective Oscillations</h3>
<div class="outline-text-3" id="text-10-3">


</div>

</div>

<div id="outline-container-10-4" class="outline-3">
<h3 id="sec-10-4"><span class="section-number-3">10.4</span> Nature and Origin of Viruses</h3>
<div class="outline-text-3" id="text-10-4">


</div>

</div>

<div id="outline-container-10-5" class="outline-3">
<h3 id="sec-10-5"><span class="section-number-3">10.5</span> Domesticated Viruses</h3>
<div class="outline-text-3" id="text-10-5">


</div>
</div>

</div>

<div id="outline-container-11" class="outline-2">
<h2 id="sec-11"><span class="section-number-2">11</span> NanoTechnology</h2>
<div class="outline-text-2" id="text-11">



</div>

<div id="outline-container-11-1" class="outline-3">
<h3 id="sec-11-1"><span class="section-number-3">11.1</span> Early NanoTechnologists</h3>
<div class="outline-text-3" id="text-11-1">


</div>

</div>

<div id="outline-container-11-2" class="outline-3">
<h3 id="sec-11-2"><span class="section-number-3">11.2</span> Scanning Tunneling Microscopes (STMs)</h3>
<div class="outline-text-3" id="text-11-2">


</div>

</div>

<div id="outline-container-11-3" class="outline-3">
<h3 id="sec-11-3"><span class="section-number-3">11.3</span> STM/Feynman Machines (FMs)</h3>
<div class="outline-text-3" id="text-11-3">


</div>

</div>

<div id="outline-container-11-4" class="outline-3">
<h3 id="sec-11-4"><span class="section-number-3">11.4</span> Micro/Nano STM Contest</h3>
<div class="outline-text-3" id="text-11-4">


</div>

</div>

<div id="outline-container-11-5" class="outline-3">
<h3 id="sec-11-5"><span class="section-number-3">11.5</span> STM/FMs and Molecular Computing</h3>
<div class="outline-text-3" id="text-11-5">


</div>

</div>

<div id="outline-container-11-6" class="outline-3">
<h3 id="sec-11-6"><span class="section-number-3">11.6</span> STM/FMs and Biomedical Applications</h3>
<div class="outline-text-3" id="text-11-6">


</div>

</div>

<div id="outline-container-11-7" class="outline-3">
<h3 id="sec-11-7"><span class="section-number-3">11.7</span> Replicating Automata</h3>
<div class="outline-text-3" id="text-11-7">


</div>
</div>

</div>

<div id="outline-container-12" class="outline-2">
<h2 id="sec-12"><span class="section-number-2">12</span> The Future of Consciousness</h2>
<div class="outline-text-2" id="text-12">


</div>

</div>

<div id="outline-container-13" class="outline-2">
<h2 id="sec-13"><span class="section-number-2">13</span> Bibliography</h2>
<div class="outline-text-2" id="text-13">



</div>

<div id="outline-container-13-1" class="outline-3">
<h3 id="sec-13-1"><span class="section-number-3">13.1</span> STM References</h3>
<div class="outline-text-3" id="text-13-1">


</div>

</div>

<div id="outline-container-13-2" class="outline-3">
<h3 id="sec-13-2"><span class="section-number-3">13.2</span> Near-Field Scanning Optical Microscopes</h3>
<div class="outline-text-3" id="text-13-2">


</div>

</div>

<div id="outline-container-13-3" class="outline-3">
<h3 id="sec-13-3"><span class="section-number-3">13.3</span> Other STM-Related Instruments</h3>
<div class="outline-text-3" id="text-13-3">


</div>

</div>

<div id="outline-container-13-4" class="outline-3">
<h3 id="sec-13-4"><span class="section-number-3">13.4</span> Replicating Systems References</h3>
<div class="outline-text-3" id="text-13-4">


</div>

</div>

<div id="outline-container-13-5" class="outline-3">
<h3 id="sec-13-5"><span class="section-number-3">13.5</span> Collective Computing References</h3>
<div class="outline-text-3" id="text-13-5">


</div>

</div>

<div id="outline-container-13-6" class="outline-3">
<h3 id="sec-13-6"><span class="section-number-3">13.6</span> Quantum Computing References</h3>
<div class="outline-text-3" id="text-13-6">


</div>
</div>
</div>
</div>

<div id="postamble">
<p class="date">Date: 2013-02-27 01:14:34 GMT</p>
<p class="author">Author: Txe Llenne</p>
<p class="creator">Org version 7.8.11 with Emacs version 24</p>
<a href="http://validator.w3.org/check?uri=referer">Validate XHTML 1.0</a>

</div>
</body>
</html>
